{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "5G6XtkjrlsVn",
        "IMKpwpxp_Mdi",
        "eviAKF7o5f98",
        "wU4sjKgds3pb"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neetushibu/IontheFold-Team6/blob/main/IonTheFold003.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ESM2 ABPS (trained) - Worse performance than ProteinMPNN"
      ],
      "metadata": {
        "id": "5G6XtkjrlsVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Complete Enhanced ProteinMPNN with Working Training - Single File Solution\"\"\"\n",
        "\n",
        "#@title Cell 1: Install Dependencies\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"Install required packages\"\"\"\n",
        "    core_packages = ['biopython', 'matplotlib', 'pandas', 'scipy', 'fair-esm']\n",
        "\n",
        "    for package in core_packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "            print(f\"✅ Installed {package}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Failed to install {package}: {e}\")\n",
        "\n",
        "    try:\n",
        "        subprocess.check_call(['apt-get', 'update', '-qq'])\n",
        "        subprocess.check_call(['apt-get', 'install', '-y', '-qq', 'apbs'])\n",
        "        print(\"✅ APBS installed\")\n",
        "    except:\n",
        "        print(\"⚠️ APBS install failed, using fallback\")\n",
        "\n",
        "install_packages()\n",
        "\n",
        "#@title Cell 2: Import Libraries\n",
        "import json, time, os, sys, glob, subprocess, warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "if not os.path.isdir(\"ProteinMPNN\"):\n",
        "    os.system(\"git clone -q https://github.com/dauparas/ProteinMPNN.git\")\n",
        "sys.path.append('/content/ProteinMPNN')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import copy\n",
        "import random\n",
        "from scipy import stats\n",
        "from collections import defaultdict, Counter\n",
        "import re\n",
        "\n",
        "try:\n",
        "    from Bio import PDB\n",
        "    from Bio.PDB import PDBParser\n",
        "    from scipy.spatial.distance import cdist\n",
        "    BIO_AVAILABLE = True\n",
        "    print(\"✅ Bio/PDB imports successful\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Bio imports failed: {e}\")\n",
        "    BIO_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import esm\n",
        "    ESM_AVAILABLE = True\n",
        "    print(\"✅ ESM-2 library imported successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ ESM-2 library not available: {e}\")\n",
        "    ESM_AVAILABLE = False\n",
        "\n",
        "from protein_mpnn_utils import (\n",
        "    loss_nll, loss_smoothed, gather_edges, gather_nodes,\n",
        "    gather_nodes_t, cat_neighbors_nodes, _scores, _S_to_seq,\n",
        "    tied_featurize, parse_PDB, StructureDataset,\n",
        "    StructureDatasetPDB, ProteinMPNN\n",
        ")\n",
        "\n",
        "print(\"✅ All libraries imported successfully!\")\n",
        "\n",
        "#@title Cell 3: APBS Electrostatic Handler\n",
        "class APBSElectrostaticHandler:\n",
        "    \"\"\"Handles APBS electrostatic potential calculations\"\"\"\n",
        "\n",
        "    def __init__(self, use_simplified=True):\n",
        "        self.use_simplified = use_simplified\n",
        "        self.apbs_available = self._check_apbs_availability()\n",
        "        self.electrostatic_cache = {}\n",
        "\n",
        "    def _check_apbs_availability(self):\n",
        "        \"\"\"Check if APBS is available\"\"\"\n",
        "        try:\n",
        "            result = subprocess.run(['apbs', '--version'],\n",
        "                                  capture_output=True, text=True, timeout=10)\n",
        "            if result.returncode == 0:\n",
        "                print(\"✅ APBS found and working!\")\n",
        "                return True\n",
        "        except:\n",
        "            pass\n",
        "        print(\"⚠️ APBS not available, using simplified calculation\")\n",
        "        return False\n",
        "\n",
        "    def calculate_simplified_electrostatics(self, pdb_path, chain_ids):\n",
        "        \"\"\"Simplified electrostatic calculation\"\"\"\n",
        "        if not BIO_AVAILABLE:\n",
        "            print(\"⚠️ BioPython not available, using dummy features\")\n",
        "            return np.array([0.0]), [{'chain': 'A', 'resnum': 1, 'resname': 'ALA', 'charge': 0, 'position': np.array([0,0,0])}]\n",
        "\n",
        "        try:\n",
        "            parser = PDBParser(QUIET=True)\n",
        "            structure = parser.get_structure('protein', pdb_path)\n",
        "\n",
        "            charge_map = {\n",
        "                'ARG': +1, 'LYS': +1, 'HIS': +0.5,\n",
        "                'ASP': -1, 'GLU': -1,\n",
        "                'SER': 0, 'THR': 0, 'ASN': 0, 'GLN': 0,\n",
        "                'CYS': 0, 'TYR': 0, 'TRP': 0,\n",
        "                'ALA': 0, 'VAL': 0, 'ILE': 0, 'LEU': 0, 'MET': 0,\n",
        "                'PHE': 0, 'PRO': 0, 'GLY': 0\n",
        "            }\n",
        "\n",
        "            all_positions = []\n",
        "            all_charges = []\n",
        "            residue_info = []\n",
        "\n",
        "            for model in structure:\n",
        "                for chain in model:\n",
        "                    if chain.id in chain_ids:\n",
        "                        for residue in chain:\n",
        "                            if residue.get_id()[0] == ' ':\n",
        "                                resname = residue.get_resname()\n",
        "                                charge = charge_map.get(resname, 0)\n",
        "\n",
        "                                if 'CA' in residue:\n",
        "                                    ca_atom = residue['CA']\n",
        "                                    pos = ca_atom.get_coord()\n",
        "                                    all_positions.append(pos)\n",
        "                                    all_charges.append(charge)\n",
        "                                    residue_info.append({\n",
        "                                        'chain': chain.id,\n",
        "                                        'resnum': residue.get_id()[1],\n",
        "                                        'resname': resname,\n",
        "                                        'charge': charge,\n",
        "                                        'position': pos\n",
        "                                    })\n",
        "\n",
        "            if not all_positions:\n",
        "                return None, None\n",
        "\n",
        "            positions = np.array(all_positions)\n",
        "            charges = np.array(all_charges)\n",
        "\n",
        "            potentials = []\n",
        "            for i, pos in enumerate(positions):\n",
        "                potential = 0.0\n",
        "                for j, other_pos in enumerate(positions):\n",
        "                    if i != j:\n",
        "                        distance = np.linalg.norm(pos - other_pos)\n",
        "                        if distance > 0.1:\n",
        "                            potential += charges[j] / distance\n",
        "                potentials.append(potential)\n",
        "\n",
        "            potentials = np.array(potentials)\n",
        "\n",
        "            if len(potentials) > 1:\n",
        "                potentials = (potentials - np.mean(potentials)) / (np.std(potentials) + 1e-8)\n",
        "\n",
        "            print(f\"✅ Calculated electrostatic potentials for {len(potentials)} residues\")\n",
        "            return potentials, residue_info\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Electrostatics calculation failed: {e}\")\n",
        "            return None, None\n",
        "\n",
        "    def get_electrostatic_features(self, pdb_path, chain_ids, sequence_length):\n",
        "        \"\"\"Get electrostatic features tensor\"\"\"\n",
        "        cache_key = f\"{pdb_path}_{'-'.join(sorted(chain_ids))}\"\n",
        "\n",
        "        if cache_key in self.electrostatic_cache:\n",
        "            potentials, residue_info = self.electrostatic_cache[cache_key]\n",
        "        else:\n",
        "            potentials, residue_info = self.calculate_simplified_electrostatics(pdb_path, chain_ids)\n",
        "            self.electrostatic_cache[cache_key] = (potentials, residue_info)\n",
        "\n",
        "        if potentials is None:\n",
        "            return torch.zeros(sequence_length, 4)\n",
        "\n",
        "        features = []\n",
        "        charges = np.array([info['charge'] for info in residue_info])\n",
        "        positions = np.array([info['position'] for info in residue_info])\n",
        "\n",
        "        for i in range(len(potentials)):\n",
        "            potential = potentials[i]\n",
        "            charge = charges[i]\n",
        "\n",
        "            charged_indices = np.where(np.abs(charges) > 0)[0]\n",
        "            if len(charged_indices) > 0:\n",
        "                if i in charged_indices:\n",
        "                    other_charged = charged_indices[charged_indices != i]\n",
        "                    if len(other_charged) > 0:\n",
        "                        distances = np.linalg.norm(positions[other_charged] - positions[i], axis=1)\n",
        "                        min_charge_dist = np.min(distances)\n",
        "                    else:\n",
        "                        min_charge_dist = 100.0\n",
        "                else:\n",
        "                    distances = np.linalg.norm(positions[charged_indices] - positions[i], axis=1)\n",
        "                    min_charge_dist = np.min(distances)\n",
        "            else:\n",
        "                min_charge_dist = 100.0\n",
        "\n",
        "            local_distances = np.linalg.norm(positions - positions[i], axis=1)\n",
        "            local_mask = local_distances < 10.0\n",
        "            local_charge_density = np.sum(np.abs(charges[local_mask]))\n",
        "\n",
        "            features.append([potential, charge, min_charge_dist, local_charge_density])\n",
        "\n",
        "        features = np.array(features)\n",
        "\n",
        "        if len(features) < sequence_length:\n",
        "            padding = np.zeros((sequence_length - len(features), 4))\n",
        "            features = np.vstack([features, padding])\n",
        "        elif len(features) > sequence_length:\n",
        "            features = features[:sequence_length]\n",
        "\n",
        "        for col in range(features.shape[1]):\n",
        "            col_data = features[:, col]\n",
        "            if np.std(col_data) > 1e-8:\n",
        "                features[:, col] = (col_data - np.mean(col_data)) / np.std(col_data)\n",
        "\n",
        "        return torch.tensor(features, dtype=torch.float32)\n",
        "\n",
        "#@title Cell 4: Enhanced ESM-2 Handler\n",
        "class EnhancedESM2Handler:\n",
        "    \"\"\"Enhanced ESM-2 handler with APBS integration\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.esm2_model = None\n",
        "        self.alphabet = None\n",
        "        self.available = False\n",
        "        self.device = torch.device(\"cpu\")\n",
        "        self.apbs_handler = APBSElectrostaticHandler()\n",
        "\n",
        "    def load_esm2(self):\n",
        "        \"\"\"Load ESM-2 model\"\"\"\n",
        "        if not ESM_AVAILABLE:\n",
        "            print(\"⚠️ ESM-2 not available\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            print(\"🔥 Loading ESM-2 model...\")\n",
        "            self.esm2_model, self.alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "            self.esm2_model = self.esm2_model.to(self.device)\n",
        "            self.esm2_model.eval()\n",
        "\n",
        "            if self._test_esm2():\n",
        "                self.available = True\n",
        "                print(\"✅ ESM-2 loaded successfully!\")\n",
        "                return True\n",
        "            else:\n",
        "                print(\"⚠️ ESM-2 test failed\")\n",
        "                return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load ESM-2: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _test_esm2(self):\n",
        "        \"\"\"Test ESM-2\"\"\"\n",
        "        try:\n",
        "            test_seq = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "            tokens = self.alphabet.encode(test_seq)\n",
        "            batch_tokens = torch.tensor([tokens]).to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                results = self.esm2_model(batch_tokens, repr_layers=[33])\n",
        "                embeddings = results[\"representations\"][33]\n",
        "\n",
        "            seq_embeddings = embeddings[0, 1:-1, :]\n",
        "            print(f\"✅ ESM-2 test passed: {seq_embeddings.shape}\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ ESM-2 test failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_enhanced_embeddings(self, sequences_batch, pdb_path, chain_ids, target_device=None):\n",
        "        \"\"\"Generate ESM-2 + APBS enhanced embeddings\"\"\"\n",
        "        if not self.available:\n",
        "            batch_size = len(sequences_batch)\n",
        "            seq_len = max(len(seq) for seq in sequences_batch) if sequences_batch else 100\n",
        "            device = target_device if target_device else self.device\n",
        "            return torch.zeros(batch_size, seq_len, 1284, device=device)\n",
        "\n",
        "        try:\n",
        "            amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "            batch_embeddings = []\n",
        "            max_seq_len = max(len(seq) for seq in sequences_batch) if sequences_batch else 100\n",
        "\n",
        "            electrostatic_features = self.apbs_handler.get_electrostatic_features(\n",
        "                pdb_path, chain_ids, max_seq_len\n",
        "            )\n",
        "\n",
        "            for seq_indices in sequences_batch:\n",
        "                seq_str = \"\"\n",
        "                if isinstance(seq_indices, torch.Tensor):\n",
        "                    indices = seq_indices.cpu().numpy()\n",
        "                else:\n",
        "                    indices = seq_indices\n",
        "\n",
        "                for idx in indices:\n",
        "                    if isinstance(idx, (int, np.integer)) and 0 <= idx < len(amino_acids):\n",
        "                        seq_str += amino_acids[int(idx)]\n",
        "                    else:\n",
        "                        seq_str += \"A\"\n",
        "\n",
        "                if len(seq_str) > 500:\n",
        "                    seq_str = seq_str[:500]\n",
        "\n",
        "                tokens = self.alphabet.encode(seq_str)\n",
        "                batch_tokens = torch.tensor([tokens], device=self.device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    results = self.esm2_model(batch_tokens, repr_layers=[33])\n",
        "                    embeddings = results[\"representations\"][33]\n",
        "                    seq_embeddings = embeddings[0, 1:-1, :]\n",
        "\n",
        "                batch_embeddings.append(seq_embeddings)\n",
        "\n",
        "            if not batch_embeddings:\n",
        "                device = target_device if target_device else self.device\n",
        "                return torch.zeros(1, max_seq_len, 1284, device=device)\n",
        "\n",
        "            max_len = max(emb.shape[0] for emb in batch_embeddings)\n",
        "            padded_embeddings = []\n",
        "\n",
        "            for emb in batch_embeddings:\n",
        "                if emb.shape[0] < max_len:\n",
        "                    padding = torch.zeros(max_len - emb.shape[0], 1280, device=self.device)\n",
        "                    padded_emb = torch.cat([emb, padding], dim=0)\n",
        "                else:\n",
        "                    padded_emb = emb[:max_len]\n",
        "                padded_embeddings.append(padded_emb)\n",
        "\n",
        "            esm2_result = torch.stack(padded_embeddings)\n",
        "\n",
        "            if electrostatic_features.shape[0] != max_len:\n",
        "                if electrostatic_features.shape[0] < max_len:\n",
        "                    padding = torch.zeros(max_len - electrostatic_features.shape[0], 4)\n",
        "                    electrostatic_features = torch.cat([electrostatic_features, padding], dim=0)\n",
        "                else:\n",
        "                    electrostatic_features = electrostatic_features[:max_len]\n",
        "\n",
        "            batch_size = esm2_result.shape[0]\n",
        "            electrostatic_batch = electrostatic_features.unsqueeze(0).repeat(batch_size, 1, 1)\n",
        "            electrostatic_batch = electrostatic_batch.to(esm2_result.device)\n",
        "\n",
        "            enhanced_embeddings = torch.cat([esm2_result, electrostatic_batch], dim=-1)\n",
        "\n",
        "            if target_device and target_device != self.device:\n",
        "                enhanced_embeddings = enhanced_embeddings.to(target_device)\n",
        "\n",
        "            print(f\"✅ Enhanced embeddings: {enhanced_embeddings.shape}\")\n",
        "            return enhanced_embeddings\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Enhanced embedding failed: {e}\")\n",
        "            batch_size = len(sequences_batch) if sequences_batch else 1\n",
        "            device = target_device if target_device else self.device\n",
        "            return torch.zeros(batch_size, 100, 1284, device=device)\n",
        "\n",
        "#@title Cell 5: Safe ProteinMPNN Base Classes\n",
        "class SafeProteinMPNN(ProteinMPNN):\n",
        "    \"\"\"Safe wrapper that fixes tensor dtype issues\"\"\"\n",
        "\n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn,\n",
        "                use_input_decoding_order=False, decoding_order=None):\n",
        "        residue_idx = residue_idx.long()\n",
        "        S = S.long()\n",
        "\n",
        "        if isinstance(chain_encoding_all, torch.Tensor):\n",
        "            chain_encoding_all = chain_encoding_all.long()\n",
        "\n",
        "        return super().forward(X, S, mask, chain_M, residue_idx, chain_encoding_all, randn,\n",
        "                             use_input_decoding_order, decoding_order)\n",
        "\n",
        "class UltraSafeEnhancedProteinMPNN(SafeProteinMPNN):\n",
        "    \"\"\"Ultra-safe enhanced version with electrostatic features\"\"\"\n",
        "\n",
        "    def __init__(self, enhanced_esm2_handler, pdb_path=None, chain_ids=None, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.enhanced_esm2_handler = enhanced_esm2_handler\n",
        "        self.pdb_path = pdb_path\n",
        "        self.chain_ids = chain_ids or []\n",
        "        self.use_enhanced_features = enhanced_esm2_handler.available\n",
        "        self.enhancement_weight = nn.Parameter(torch.tensor(0.1))\n",
        "\n",
        "        print(f\"✅ Ultra-Safe Enhanced ProteinMPNN initialized\")\n",
        "\n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn,\n",
        "                use_input_decoding_order=False, decoding_order=None):\n",
        "\n",
        "        log_probs = super().forward(X, S, mask, chain_M, residue_idx, chain_encoding_all, randn,\n",
        "                                   use_input_decoding_order, decoding_order)\n",
        "\n",
        "        if self.use_enhanced_features and self.pdb_path is not None:\n",
        "            try:\n",
        "                seq_len = S.shape[1]\n",
        "                electrostatic_features = self.enhanced_esm2_handler.apbs_handler.get_electrostatic_features(\n",
        "                    self.pdb_path, self.chain_ids, seq_len\n",
        "                )\n",
        "\n",
        "                if electrostatic_features.shape[0] == seq_len:\n",
        "                    electrostatic_features = electrostatic_features.to(log_probs.device)\n",
        "                    potential = electrostatic_features[:, 0]\n",
        "\n",
        "                    aa_bias = torch.zeros_like(log_probs)\n",
        "\n",
        "                    for i in range(seq_len):\n",
        "                        pot_val = potential[i].item()\n",
        "                        if abs(pot_val) > 0.5:\n",
        "                            for aa_idx in [3, 4, 11, 15]:\n",
        "                                aa_bias[0, i, aa_idx] += pot_val * 0.05\n",
        "\n",
        "                    enhancement = torch.sigmoid(self.enhancement_weight)\n",
        "                    log_probs = log_probs + enhancement * aa_bias\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Enhancement failed: {e}\")\n",
        "\n",
        "        return log_probs\n",
        "\n",
        "#@title Cell 6: Trainable Enhanced Model\n",
        "class TrainableUltraSafeEnhancedProteinMPNN(UltraSafeEnhancedProteinMPNN):\n",
        "    \"\"\"Trainable version with learnable parameters\"\"\"\n",
        "\n",
        "    def __init__(self, enhanced_esm2_handler, pdb_path=None, chain_ids=None, *args, **kwargs):\n",
        "        super().__init__(enhanced_esm2_handler, pdb_path, chain_ids, *args, **kwargs)\n",
        "\n",
        "        # Higher initial enhancement weight\n",
        "        self.enhancement_weight = nn.Parameter(torch.tensor(0.3))\n",
        "\n",
        "        # Learnable bias for charged residues\n",
        "        charged_bias = torch.zeros(21)\n",
        "        charged_bias[[3, 4, 8, 11, 15]] = 0.2  # D, E, H, K, R\n",
        "        self.charged_bias = nn.Parameter(charged_bias)\n",
        "\n",
        "        print(f\"✅ Trainable Enhanced ProteinMPNN initialized with 30% integration\")\n",
        "\n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn,\n",
        "                use_input_decoding_order=False, decoding_order=None):\n",
        "\n",
        "        log_probs = SafeProteinMPNN.forward(self, X, S, mask, chain_M, residue_idx,\n",
        "                                           chain_encoding_all, randn, use_input_decoding_order,\n",
        "                                           decoding_order)\n",
        "\n",
        "        if self.use_enhanced_features and self.pdb_path is not None:\n",
        "            try:\n",
        "                seq_len = S.shape[1]\n",
        "                electrostatic_features = self.enhanced_esm2_handler.apbs_handler.get_electrostatic_features(\n",
        "                    self.pdb_path, self.chain_ids, seq_len\n",
        "                )\n",
        "\n",
        "                if electrostatic_features.shape[0] == seq_len:\n",
        "                    electrostatic_features = electrostatic_features.to(log_probs.device)\n",
        "                    potential = electrostatic_features[:, 0]\n",
        "                    charge = electrostatic_features[:, 1]\n",
        "\n",
        "                    aa_bias = torch.zeros_like(log_probs)\n",
        "\n",
        "                    for i in range(seq_len):\n",
        "                        pot_val = potential[i].item()\n",
        "                        charge_val = charge[i].item()\n",
        "\n",
        "                        if abs(pot_val) > 0.3:\n",
        "                            for aa_idx in [3, 4, 11, 15]:\n",
        "                                aa_bias[0, i, aa_idx] += pot_val * 0.1\n",
        "\n",
        "                        aa_bias[0, i] += self.charged_bias\n",
        "\n",
        "                    enhancement = torch.sigmoid(self.enhancement_weight)\n",
        "                    enhanced_log_probs = log_probs + enhancement * aa_bias\n",
        "\n",
        "                    return enhanced_log_probs\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Enhancement failed: {e}\")\n",
        "\n",
        "        return log_probs\n",
        "\n",
        "class ChargedResidueLoss(nn.Module):\n",
        "    \"\"\"Loss function focused on charged residue accuracy\"\"\"\n",
        "\n",
        "    def __init__(self, charged_weight=3.0):\n",
        "        super().__init__()\n",
        "        self.charged_weight = charged_weight\n",
        "        self.charged_indices = torch.tensor([3, 4, 8, 11, 15])\n",
        "\n",
        "    def forward(self, log_probs, S_target, mask):\n",
        "        flat_log_probs = log_probs.view(-1, log_probs.size(-1))\n",
        "        flat_targets = S_target.view(-1)\n",
        "        flat_mask = mask.view(-1)\n",
        "\n",
        "        nll_loss = F.nll_loss(flat_log_probs, flat_targets, reduction='none')\n",
        "\n",
        "        charged_mask = torch.zeros_like(flat_targets, dtype=torch.bool)\n",
        "        for idx in self.charged_indices.to(flat_targets.device):\n",
        "            charged_mask |= (flat_targets == idx)\n",
        "\n",
        "        loss_weights = torch.where(\n",
        "            charged_mask,\n",
        "            torch.tensor(self.charged_weight, device=flat_targets.device),\n",
        "            torch.tensor(1.0, device=flat_targets.device)\n",
        "        )\n",
        "\n",
        "        weighted_loss = nll_loss * loss_weights * flat_mask\n",
        "        return weighted_loss.sum() / flat_mask.sum()\n",
        "\n",
        "#@title Cell 7: Device Setup and Model Loading\n",
        "def get_safe_device():\n",
        "    \"\"\"Get safe device\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            test_tensor = torch.tensor([1.0], device='cuda')\n",
        "            test_result = test_tensor + 1\n",
        "            return torch.device(\"cuda:0\")\n",
        "        except:\n",
        "            print(\"⚠️ CUDA test failed, using CPU\")\n",
        "            return torch.device(\"cpu\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "device = get_safe_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize handlers\n",
        "enhanced_esm2_handler = EnhancedESM2Handler()\n",
        "esm2_loaded = enhanced_esm2_handler.load_esm2()\n",
        "\n",
        "# Load models\n",
        "model_name = \"v_48_020\"\n",
        "backbone_noise = 0.00\n",
        "path_to_model_weights = '/content/ProteinMPNN/vanilla_model_weights'\n",
        "hidden_dim = 128\n",
        "num_layers = 3\n",
        "\n",
        "model_folder_path = path_to_model_weights\n",
        "if model_folder_path[-1] != '/':\n",
        "    model_folder_path = model_folder_path + '/'\n",
        "checkpoint_path = model_folder_path + f'{model_name}.pt'\n",
        "\n",
        "standard_model = None\n",
        "enhanced_model = None\n",
        "\n",
        "try:\n",
        "    print(\"🔥 Loading ProteinMPNN checkpoint...\")\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "    print('Number of edges:', checkpoint['num_edges'])\n",
        "\n",
        "    # Standard model\n",
        "    standard_model = ProteinMPNN(\n",
        "        num_letters=21,\n",
        "        node_features=hidden_dim,\n",
        "        edge_features=hidden_dim,\n",
        "        hidden_dim=hidden_dim,\n",
        "        num_encoder_layers=num_layers,\n",
        "        num_decoder_layers=num_layers,\n",
        "        augment_eps=backbone_noise,\n",
        "        k_neighbors=checkpoint['num_edges']\n",
        "    )\n",
        "\n",
        "    standard_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    standard_model = standard_model.to(device)\n",
        "    standard_model.eval()\n",
        "    print(\"✅ Standard ProteinMPNN loaded!\")\n",
        "\n",
        "    # Enhanced model\n",
        "    if esm2_loaded:\n",
        "        enhanced_model = TrainableUltraSafeEnhancedProteinMPNN(\n",
        "            enhanced_esm2_handler=enhanced_esm2_handler,\n",
        "            pdb_path=None,\n",
        "            chain_ids=None,\n",
        "            num_letters=21,\n",
        "            node_features=hidden_dim,\n",
        "            edge_features=hidden_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            augment_eps=backbone_noise,\n",
        "            k_neighbors=checkpoint['num_edges']\n",
        "        )\n",
        "\n",
        "        enhanced_model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "        enhanced_model = enhanced_model.to(device)\n",
        "        enhanced_model.eval()\n",
        "        print(\"✅ Trainable Enhanced ProteinMPNN loaded!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading models: {e}\")\n",
        "\n",
        "#@title Cell 8: Helper Functions\n",
        "def get_pdb_file(pdb_code, dest_dir=\".\", overwrite=False, allow_upload=True):\n",
        "    \"\"\"Download PDB file\"\"\"\n",
        "    import os, urllib.request, gzip, shutil\n",
        "    from urllib.error import HTTPError, URLError\n",
        "\n",
        "    code = (pdb_code or \"\").strip()\n",
        "    if not code:\n",
        "        if not allow_upload:\n",
        "            raise ValueError(\"pdb_code is empty and uploads are disabled.\")\n",
        "        return None\n",
        "\n",
        "    code_l = code.lower()\n",
        "    code_u = code.upper()\n",
        "    out_path = os.path.join(dest_dir, f\"{code_u}.pdb\")\n",
        "\n",
        "    if os.path.exists(out_path) and not overwrite:\n",
        "        return out_path\n",
        "\n",
        "    try:\n",
        "        url1 = f\"https://files.rcsb.org/download/{code_l}.pdb\"\n",
        "        urllib.request.urlretrieve(url1, out_path)\n",
        "        print(f\"✅ Downloaded {code_u}\")\n",
        "        return out_path\n",
        "    except (HTTPError, URLError):\n",
        "        try:\n",
        "            subdir = code_l[1:3]\n",
        "            url2 = f\"https://files.rcsb.org/pub/pdb/data/structures/divided/pdb/{subdir}/pdb{code_l}.ent.gz\"\n",
        "            gz_path = os.path.join(dest_dir, f\"pdb{code_l}.ent.gz\")\n",
        "\n",
        "            urllib.request.urlretrieve(url2, gz_path)\n",
        "            with gzip.open(gz_path, \"rb\") as f_in, open(out_path, \"wb\") as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "            os.remove(gz_path)\n",
        "\n",
        "            print(f\"✅ Downloaded and decompressed {code_u}\")\n",
        "            return out_path\n",
        "        except Exception as e2:\n",
        "            if os.path.exists(gz_path):\n",
        "                try: os.remove(gz_path)\n",
        "                except: pass\n",
        "            print(f\"❌ Could not download {code_u}: {e2}\")\n",
        "            return None\n",
        "\n",
        "def calculate_enhanced_metrics(native_seq, designed_seqs, scores, model_type=\"Standard\"):\n",
        "    \"\"\"Calculate enhanced metrics\"\"\"\n",
        "    metrics = {\n",
        "        'sequence_recovery': [],\n",
        "        'identity': [],\n",
        "        'score': [],\n",
        "        'length': [],\n",
        "        'charged_residue_recovery': [],\n",
        "        'model_type': []\n",
        "    }\n",
        "\n",
        "    native_clean = native_seq.replace('/', '').replace('X', '')\n",
        "    charged_residues = set('DEKR')\n",
        "\n",
        "    for designed_seq, score in zip(designed_seqs, scores):\n",
        "        designed_clean = designed_seq.replace('/', '').replace('X', '')\n",
        "        length = min(len(native_clean), len(designed_clean))\n",
        "        if length == 0:\n",
        "            continue\n",
        "\n",
        "        identical = sum(1 for a, b in zip(native_clean[:length], designed_clean[:length]) if a == b)\n",
        "        identity = (identical / length) * 100\n",
        "\n",
        "        metrics['sequence_recovery'].append(identity)\n",
        "        metrics['identity'].append(identity)\n",
        "        metrics['score'].append(float(score))\n",
        "        metrics['length'].append(length)\n",
        "        metrics['model_type'].append(model_type)\n",
        "\n",
        "        native_charged_pos = [i for i, aa in enumerate(native_clean[:length]) if aa in charged_residues]\n",
        "        if native_charged_pos:\n",
        "            charged_recovery = sum(1 for pos in native_charged_pos\n",
        "                                 if pos < len(designed_clean) and designed_clean[pos] in charged_residues)\n",
        "            charged_recovery_rate = (charged_recovery / len(native_charged_pos)) * 100\n",
        "        else:\n",
        "            charged_recovery_rate = 0\n",
        "        metrics['charged_residue_recovery'].append(charged_recovery_rate)\n",
        "\n",
        "    return pd.DataFrame(metrics)\n",
        "\n",
        "#@title Cell 9: Enhanced Processing Function\n",
        "def enhanced_process_protein_for_training(pdb_code, model, num_sequences=1, temperature=0.1):\n",
        "    \"\"\"Modified processing function for training\"\"\"\n",
        "\n",
        "    try:\n",
        "        pdb_path = get_pdb_file(pdb_code)\n",
        "        if pdb_path is None:\n",
        "            return None\n",
        "\n",
        "        # Default chain configuration\n",
        "        designed_chains = ['A']\n",
        "        fixed_chains = ['B'] if pdb_code != '5MKN' else ['B', 'C', 'D']\n",
        "\n",
        "        chain_list = list(set(designed_chains + fixed_chains))\n",
        "\n",
        "        # Set model paths\n",
        "        model.pdb_path = pdb_path\n",
        "        model.chain_ids = chain_list\n",
        "\n",
        "        pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "        dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=20000)\n",
        "        chain_id_dict = {pdb_dict_list[0]['name']: (designed_chains, fixed_chains)}\n",
        "\n",
        "        for ix, protein in enumerate(dataset_valid):\n",
        "            batch_clones = [copy.deepcopy(protein)]\n",
        "\n",
        "            features = tied_featurize(\n",
        "                batch_clones, device, chain_id_dict, None, None, None, None, None\n",
        "            )\n",
        "\n",
        "            (X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list,\n",
        "             visible_list_list, masked_list_list, masked_chain_length_list_list,\n",
        "             chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask,\n",
        "             tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all,\n",
        "             bias_by_res_all, tied_beta) = features\n",
        "\n",
        "            randn_1 = torch.randn(chain_M.shape, device=device)\n",
        "\n",
        "            # Forward pass with loss calculation\n",
        "            log_probs = model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "\n",
        "            # Calculate training loss\n",
        "            mask_for_loss = mask * chain_M * chain_M_pos\n",
        "\n",
        "            loss_fn = ChargedResidueLoss(charged_weight=3.0)\n",
        "            loss = loss_fn(log_probs, S, mask_for_loss)\n",
        "\n",
        "            # Calculate recovery for monitoring\n",
        "            sample_dict = model.sample(\n",
        "                X, randn_1, S, chain_M, chain_encoding_all, residue_idx,\n",
        "                mask=mask, temperature=temperature, omit_AAs_np=np.zeros(21),\n",
        "                bias_AAs_np=np.zeros(21), chain_M_pos=chain_M_pos,\n",
        "                omit_AA_mask=omit_AA_mask, pssm_coef=pssm_coef,\n",
        "                pssm_bias=pssm_bias, pssm_multi=0.0,\n",
        "                pssm_log_odds_flag=False,\n",
        "                pssm_log_odds_mask=(pssm_log_odds_all > 0.0).float(),\n",
        "                pssm_bias_flag=False, bias_by_res=bias_by_res_all\n",
        "            )\n",
        "\n",
        "            S_sample = sample_dict[\"S\"]\n",
        "            seq_recovery_rate = torch.sum(\n",
        "                torch.sum(F.one_hot(S[0], 21) * F.one_hot(S_sample[0], 21), axis=-1) * mask_for_loss[0]\n",
        "            ) / torch.sum(mask_for_loss[0])\n",
        "\n",
        "            return {\n",
        "                'loss': loss,\n",
        "                'recovery': seq_recovery_rate.item(),\n",
        "                'pdb_code': pdb_code\n",
        "            }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Training processing failed for {pdb_code}: {e}\")\n",
        "        return None\n",
        "\n",
        "#@title Cell 10: Training Function\n",
        "def train_enhanced_model_on_dataset(csv_path, num_epochs=15, learning_rate=1e-4):\n",
        "    \"\"\"Train the enhanced model using existing processing pipeline\"\"\"\n",
        "\n",
        "    # Load dataset\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if 'total_protein_charge' not in df.columns:\n",
        "            if 'net_protein_charge' in df.columns:\n",
        "                df['total_protein_charge'] = df['net_protein_charge']\n",
        "            else:\n",
        "                print(\"❌ No charge column found in CSV\")\n",
        "                return None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Filter for charged proteins and exclude benchmark set\n",
        "    benchmark_set = {'3JAY', '3JB0', '5A1A', '5FTJ', '5FTK', '5K12', '5L35', '5MDO',\n",
        "                     '5MF4', '5MFM', '5MH6', '5MHF', '5MIW', '5MJY', '5MK1', '5MK3',\n",
        "                     '5MKM', '5MLD', '5MNS', '5MNV', '5MQZ', '5MR0', '5MUX', '5MY0', '5MY2'}\n",
        "\n",
        "    train_df = df[~df['pdb_id'].isin(benchmark_set)]\n",
        "    train_df = train_df[abs(train_df['total_protein_charge']) >= 10].sample(min(50, len(train_df)))\n",
        "\n",
        "    print(f\"🔥 Training on {len(train_df)} proteins\")\n",
        "\n",
        "    if enhanced_model is None:\n",
        "        print(\"❌ enhanced_model not found. Run setup first.\")\n",
        "        return None\n",
        "\n",
        "    # Put model in training mode\n",
        "    enhanced_model.train()\n",
        "\n",
        "    # Setup training\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': [enhanced_model.enhancement_weight], 'lr': learning_rate * 5},\n",
        "        {'params': [enhanced_model.charged_bias], 'lr': learning_rate}\n",
        "    ], weight_decay=1e-5)\n",
        "\n",
        "    training_history = []\n",
        "\n",
        "    print(\"🚀 Starting training...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_losses = []\n",
        "        epoch_recoveries = []\n",
        "\n",
        "        # Sample proteins for this epoch\n",
        "        epoch_proteins = train_df.sample(min(10, len(train_df)))\n",
        "\n",
        "        for idx, row in epoch_proteins.iterrows():\n",
        "            pdb_code = row['pdb_id']\n",
        "\n",
        "            try:\n",
        "                result = enhanced_process_protein_for_training(\n",
        "                    pdb_code,\n",
        "                    enhanced_model,\n",
        "                    num_sequences=1,\n",
        "                    temperature=0.1\n",
        "                )\n",
        "\n",
        "                if result and 'loss' in result:\n",
        "                    loss = result['loss']\n",
        "                    recovery = result['recovery']\n",
        "\n",
        "                    # Backprop\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(enhanced_model.parameters(), 1.0)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    epoch_losses.append(loss.item())\n",
        "                    epoch_recoveries.append(recovery)\n",
        "\n",
        "                    if len(epoch_losses) % 3 == 0:\n",
        "                        print(f\"  Epoch {epoch}, Protein {len(epoch_losses)}: Loss={loss.item():.4f}, Recovery={recovery:.3f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Failed on {pdb_code}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if epoch_losses:\n",
        "            avg_loss = np.mean(epoch_losses)\n",
        "            avg_recovery = np.mean(epoch_recoveries)\n",
        "            enhancement_weight = torch.sigmoid(enhanced_model.enhancement_weight).item()\n",
        "\n",
        "            training_history.append({\n",
        "                'epoch': epoch,\n",
        "                'loss': avg_loss,\n",
        "                'recovery': avg_recovery,\n",
        "                'enhancement_weight': enhancement_weight,\n",
        "                'proteins_processed': len(epoch_losses)\n",
        "            })\n",
        "\n",
        "            print(f\"📊 Epoch {epoch}: Loss={avg_loss:.4f}, Recovery={avg_recovery:.3f}, Weight={enhancement_weight:.3f}\")\n",
        "        else:\n",
        "            print(f\"⚠️ Epoch {epoch}: No successful training examples\")\n",
        "\n",
        "    print(\"✅ Training completed!\")\n",
        "\n",
        "    # Put model back in eval mode\n",
        "    enhanced_model.eval()\n",
        "\n",
        "    return training_history\n",
        "\n",
        "# Define protein configurations\n",
        "design_config = {\n",
        "    '3JAY': {'designed_chains': ['B'], 'fixed_chains': ['A', 'C', 'D', 'E']},\n",
        "    '3JB0': {'designed_chains': ['B'], 'fixed_chains': ['A', 'C', 'D', 'E']},\n",
        "    '5A1A': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "    '5FTJ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "    '5FTK': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "    '5K12': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "    '5L35': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G']},\n",
        "    '5MDO': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "    '5MF4': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "    '5MFM': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "    '5MH6': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "    '5MHF': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "    '5MIW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "    '5MJY': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "    '5MK1': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "    '5MK3': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "    '5MKM': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "    '5MLD': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "    '5MNS': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "    '5MNV': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']},\n",
        "    '5MQZ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "    '5MR0': {'designed_chains': ['F'], 'fixed_chains': ['A', 'B', 'C', 'D', 'E']},\n",
        "    '5MUX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "    '5MY0': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "    '5MY2': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']}\n",
        "}\n",
        "\n",
        "print(\"✅ All systems ready!\")\n",
        "\n",
        "# Usage:\n",
        "training_history = train_enhanced_model_on_dataset('charged_proteins.csv', num_epochs=15)\n",
        "# 2. Your enhanced_model will be updated with learned parameters\n",
        "# 3. Test with your original benchmarking functions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "GQCsZOySlviL",
        "outputId": "a6ccebfe-d74d-41b8-f3cd-a539e38f8f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Installed biopython\n",
            "✅ Installed matplotlib\n",
            "✅ Installed pandas\n",
            "✅ Installed scipy\n",
            "✅ Installed fair-esm\n",
            "✅ APBS installed\n",
            "✅ Bio/PDB imports successful\n",
            "✅ ESM-2 library imported successfully!\n",
            "✅ All libraries imported successfully!\n",
            "Using device: cuda:0\n",
            "⚠️ APBS not available, using simplified calculation\n",
            "🔥 Loading ESM-2 model...\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n",
            "✅ ESM-2 test passed: torch.Size([18, 1280])\n",
            "✅ ESM-2 loaded successfully!\n",
            "🔥 Loading ProteinMPNN checkpoint...\n",
            "Number of edges: 48\n",
            "✅ Standard ProteinMPNN loaded!\n",
            "✅ Ultra-Safe Enhanced ProteinMPNN initialized\n",
            "✅ Trainable Enhanced ProteinMPNN initialized with 30% integration\n",
            "✅ Trainable Enhanced ProteinMPNN loaded!\n",
            "✅ All systems ready!\n",
            "🔥 Training on 50 proteins\n",
            "🚀 Starting training...\n",
            "✅ Calculated electrostatic potentials for 1640 residues\n",
            "✅ Calculated electrostatic potentials for 342 residues\n",
            "✅ Calculated electrostatic potentials for 865 residues\n",
            "  Epoch 0, Protein 3: Loss=2.7461, Recovery=0.449\n",
            "✅ Calculated electrostatic potentials for 860 residues\n",
            "✅ Calculated electrostatic potentials for 189 residues\n",
            "Training processing failed for 6ET5: 'seq_chain_A'\n",
            "✅ Calculated electrostatic potentials for 853 residues\n",
            "  Epoch 0, Protein 6: Loss=2.3223, Recovery=0.506\n",
            "✅ Calculated electrostatic potentials for 1700 residues\n",
            "✅ Calculated electrostatic potentials for 1472 residues\n",
            "✅ Calculated electrostatic potentials for 886 residues\n",
            "  Epoch 0, Protein 9: Loss=2.2081, Recovery=0.467\n",
            "📊 Epoch 0: Loss=2.4815, Recovery=0.442, Weight=0.576\n",
            "✅ Calculated electrostatic potentials for 946 residues\n",
            "  Epoch 1, Protein 3: Loss=2.1286, Recovery=0.492\n",
            "✅ Calculated electrostatic potentials for 871 residues\n",
            "✅ Calculated electrostatic potentials for 787 residues\n",
            "✅ Calculated electrostatic potentials for 189 residues\n",
            "  Epoch 1, Protein 6: Loss=2.1370, Recovery=0.480\n",
            "✅ Calculated electrostatic potentials for 925 residues\n",
            "✅ Calculated electrostatic potentials for 656 residues\n",
            "✅ Calculated electrostatic potentials for 1232 residues\n",
            "  Epoch 1, Protein 9: Loss=2.2604, Recovery=0.511\n",
            "✅ Calculated electrostatic potentials for 1656 residues\n",
            "📊 Epoch 1: Loss=2.3007, Recovery=0.492, Weight=0.577\n",
            "✅ Calculated electrostatic potentials for 1701 residues\n",
            "✅ Calculated electrostatic potentials for 412 residues\n",
            "  Epoch 2, Protein 3: Loss=2.6783, Recovery=0.425\n",
            "✅ Calculated electrostatic potentials for 622 residues\n",
            "✅ Calculated electrostatic potentials for 1698 residues\n",
            "  Epoch 2, Protein 6: Loss=2.4486, Recovery=0.484\n",
            "✅ Calculated electrostatic potentials for 872 residues\n",
            "✅ Calculated electrostatic potentials for 1420 residues\n",
            "  Epoch 2, Protein 9: Loss=2.0856, Recovery=0.461\n",
            "✅ Calculated electrostatic potentials for 857 residues\n",
            "📊 Epoch 2: Loss=2.4391, Recovery=0.458, Weight=0.578\n",
            "✅ Calculated electrostatic potentials for 872 residues\n",
            "✅ Calculated electrostatic potentials for 871 residues\n",
            "✅ Calculated electrostatic potentials for 427 residues\n",
            "  Epoch 3, Protein 3: Loss=2.4003, Recovery=0.490\n",
            "✅ Calculated electrostatic potentials for 330 residues\n",
            "Training processing failed for 6ET5: 'seq_chain_A'\n",
            "✅ Calculated electrostatic potentials for 946 residues\n",
            "  Epoch 3, Protein 6: Loss=2.6429, Recovery=0.364\n",
            "✅ Calculated electrostatic potentials for 872 residues\n",
            "  Epoch 3, Protein 9: Loss=2.3412, Recovery=0.508\n",
            "📊 Epoch 3: Loss=2.3968, Recovery=0.481, Weight=0.579\n",
            "✅ Calculated electrostatic potentials for 1700 residues\n",
            "✅ Calculated electrostatic potentials for 872 residues\n",
            "  Epoch 4, Protein 3: Loss=1.9556, Recovery=0.490\n",
            "✅ Calculated electrostatic potentials for 348 residues\n",
            "  Epoch 4, Protein 6: Loss=2.4877, Recovery=0.431\n",
            "  Epoch 4, Protein 9: Loss=2.3842, Recovery=0.486\n",
            "✅ Calculated electrostatic potentials for 1228 residues\n",
            "📊 Epoch 4: Loss=2.4561, Recovery=0.442, Weight=0.580\n",
            "✅ Calculated electrostatic potentials for 868 residues\n",
            "✅ Calculated electrostatic potentials for 656 residues\n",
            "  Epoch 5, Protein 3: Loss=2.3926, Recovery=0.485\n",
            "  Epoch 5, Protein 6: Loss=2.5700, Recovery=0.400\n",
            "✅ Calculated electrostatic potentials for 189 residues\n",
            "  Epoch 5, Protein 9: Loss=2.0881, Recovery=0.480\n",
            "📊 Epoch 5: Loss=2.3755, Recovery=0.472, Weight=0.581\n",
            "✅ Calculated electrostatic potentials for 924 residues\n",
            "  Epoch 6, Protein 3: Loss=2.4522, Recovery=0.472\n",
            "✅ Calculated electrostatic potentials for 872 residues\n",
            "✅ Calculated electrostatic potentials for 656 residues\n",
            "  Epoch 6, Protein 6: Loss=2.4042, Recovery=0.473\n",
            "  Epoch 6, Protein 9: Loss=2.3525, Recovery=0.481\n",
            "📊 Epoch 6: Loss=2.3890, Recovery=0.488, Weight=0.583\n",
            "  Epoch 7, Protein 3: Loss=2.2958, Recovery=0.489\n",
            "  Epoch 7, Protein 6: Loss=2.2936, Recovery=0.488\n",
            "✅ Calculated electrostatic potentials for 189 residues\n",
            "  Epoch 7, Protein 9: Loss=2.3572, Recovery=0.491\n",
            "✅ Calculated electrostatic potentials for 1081 residues\n",
            "📊 Epoch 7: Loss=2.3487, Recovery=0.477, Weight=0.584\n",
            "✅ Calculated electrostatic potentials for 924 residues\n",
            "  Epoch 8, Protein 3: Loss=2.1122, Recovery=0.506\n",
            "  Epoch 8, Protein 6: Loss=2.5848, Recovery=0.388\n",
            "  Epoch 8, Protein 9: Loss=2.3015, Recovery=0.494\n",
            "📊 Epoch 8: Loss=2.3462, Recovery=0.481, Weight=0.585\n",
            "Training processing failed for 6ET5: 'seq_chain_A'\n",
            "  Epoch 9, Protein 3: Loss=2.3168, Recovery=0.485\n",
            "  Epoch 9, Protein 6: Loss=2.4063, Recovery=0.423\n",
            "✅ Calculated electrostatic potentials for 934 residues\n",
            "✅ Calculated electrostatic potentials for 6860 residues\n",
            "  Epoch 9, Protein 9: Loss=2.1831, Recovery=0.504\n",
            "📊 Epoch 9: Loss=2.1918, Recovery=0.494, Weight=0.586\n",
            "  Epoch 10, Protein 3: Loss=2.3813, Recovery=0.463\n",
            "  Epoch 10, Protein 6: Loss=2.3019, Recovery=0.492\n",
            "  Epoch 10, Protein 9: Loss=2.2212, Recovery=0.530\n",
            "📊 Epoch 10: Loss=2.4671, Recovery=0.462, Weight=0.587\n",
            "  Epoch 11, Protein 3: Loss=2.6061, Recovery=0.383\n",
            "✅ Calculated electrostatic potentials for 481 residues\n",
            "  Epoch 11, Protein 6: Loss=2.1546, Recovery=0.562\n",
            "  Epoch 11, Protein 9: Loss=2.5350, Recovery=0.454\n",
            "📊 Epoch 11: Loss=2.3236, Recovery=0.481, Weight=0.589\n",
            "  Epoch 12, Protein 3: Loss=2.3331, Recovery=0.488\n",
            "✅ Calculated electrostatic potentials for 857 residues\n",
            "  Epoch 12, Protein 6: Loss=2.2033, Recovery=0.455\n",
            "  Epoch 12, Protein 9: Loss=2.4943, Recovery=0.437\n",
            "✅ Calculated electrostatic potentials for 189 residues\n",
            "📊 Epoch 12: Loss=2.3809, Recovery=0.465, Weight=0.590\n",
            "Training processing failed for 6ET5: 'seq_chain_A'\n",
            "  Epoch 13, Protein 3: Loss=2.5848, Recovery=0.402\n",
            "  Epoch 13, Protein 6: Loss=2.3682, Recovery=0.476\n",
            "  Epoch 13, Protein 9: Loss=2.1044, Recovery=0.498\n",
            "📊 Epoch 13: Loss=2.2635, Recovery=0.478, Weight=0.591\n",
            "  Epoch 14, Protein 3: Loss=2.1364, Recovery=0.480\n",
            "Training processing failed for 6ET5: 'seq_chain_A'\n",
            "  Epoch 14, Protein 6: Loss=2.6662, Recovery=0.384\n",
            "  Epoch 14, Protein 9: Loss=2.6580, Recovery=0.425\n",
            "📊 Epoch 14: Loss=2.4238, Recovery=0.443, Weight=0.592\n",
            "✅ Training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "a6241a8b",
        "outputId": "d92a35ca-db15-4f47-941b-9493de56fa3f"
      },
      "source": [
        "#@title Cell 11: Run Multi-Protein Test (Complete)\n",
        "\n",
        "def test_subset_first():\n",
        "    \"\"\"Test subset first\"\"\"\n",
        "    #test_proteins = ['9VIC', '9IR2', '9CDF']\n",
        "\n",
        "    test_proteins =['3JAY', # 5 chains, 919 charged residues\n",
        "             '3JB0', # 5 chains, 919 charged residues\n",
        "             '5A1A', # 4 chains, 984 charged residues\n",
        "             '5FTJ', # 6 chains, 1326 charged residues\n",
        "             '5FTK', # 6 chains, 1326 charged residues\n",
        "             '5K12', # 6 chains, 474 charged residues\n",
        "             '5L35', # 7 chains, 511 charged residues\n",
        "             '5MDO', # 6 chains, 468 charged residues\n",
        "             '5MDR', # 12 chains, 468 charged residues\n",
        "             '5MF4', # 6 chains, 566 charged residues\n",
        "             '5MFM', # 8 chains, 362 charged residues\n",
        "             '5MH6', # 4 chains, 350 charged residues\n",
        "             '5MHF', # 8 chains, 626 charged residues\n",
        "             '5MIW', # 6 chains, 342 charged residues\n",
        "             '5MJY', # 6 chains, 396 charged residues\n",
        "             '5MK1', # 8 chains, 393 charged residues\n",
        "             '5MK3', # 8 chains, 395 charged residues\n",
        "             '5MKM', # 6 chains, 442 charged residues\n",
        "             '5MKN', # 28 chains, 595 charged residues\n",
        "             '5MLD', # 8 chains, 584 charged residues\n",
        "             '5MNS', # 6 chains, 671 charged residues\n",
        "             '5MNV', # 9 chains, 977 charged residues\n",
        "             '5MQZ', # 6 chains, 469 charged residues\n",
        "             '5MR0', # 6 chains, 474 charged residues\n",
        "             '5MUX', # 6 chains, 822 charged residues\n",
        "             '5MX5', # 14 chains, 873 charged residues\n",
        "             '5MY0', # 4 chains, 722 charged residues\n",
        "             '5MY2', # 4 chains, 723 charged residues\n",
        "             '5MZ2', # 16 chains, 1125 charged residues\n",
        "             '5MZ5', # 4 chains, 532 charged residues\n",
        "             ]\n",
        "\n",
        "    print(f\"🧪 Testing subset: {test_proteins}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    subset_results = {}\n",
        "\n",
        "    for pdb_code in test_proteins:\n",
        "        if pdb_code in design_config:\n",
        "            config = design_config[pdb_code]\n",
        "            print(f\"\\n🧬 Processing {pdb_code}...\")\n",
        "\n",
        "            result = enhanced_process_protein(\n",
        "                pdb_code,\n",
        "                config['designed_chains'],\n",
        "                config['fixed_chains'],\n",
        "                num_sequences=num_seqs,\n",
        "                temperature=float(sampling_temp)\n",
        "            )\n",
        "\n",
        "            if result is not None:\n",
        "                subset_results[pdb_code] = result\n",
        "                std_count = len(result['standard']['sequences'])\n",
        "                enh_count = len(result['enhanced']['sequences']) if 'enhanced' in result else 0\n",
        "                print(f\"✅ {pdb_code}: Standard={std_count}, Enhanced={enh_count}\")\n",
        "            else:\n",
        "                print(f\"❌ {pdb_code}: Failed\")\n",
        "\n",
        "        if (list(design_config.keys()).index(pdb_code) + 1) % 3 == 0:\n",
        "            print(f\"\\n📊 Progress: {list(design_config.keys()).index(pdb_code) + 1}/{len(pdb_codes)} proteins completed\")\n",
        "\n",
        "\n",
        "    return subset_results\n",
        "\n",
        "def run_full_dataset():\n",
        "    \"\"\"Run complete dataset\"\"\"\n",
        "    print(\"🚀 Running full dataset...\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    all_results = {}\n",
        "\n",
        "    for i, pdb_code in enumerate(pdb_codes):\n",
        "        if pdb_code in design_config:\n",
        "            config = design_config[pdb_code]\n",
        "            print(f\"\\n🧬 Processing {pdb_code} ({i+1}/{len(pdb_codes)})...\")\n",
        "\n",
        "            result = enhanced_process_protein(\n",
        "                pdb_code,\n",
        "                config['designed_chains'],\n",
        "                config['fixed_chains'],\n",
        "                num_sequences=num_seqs,\n",
        "                temperature=float(sampling_temp)\n",
        "            )\n",
        "\n",
        "            if result is not None:\n",
        "                all_results[pdb_code] = result\n",
        "                std_count = len(result['standard']['sequences'])\n",
        "                enh_count = len(result['enhanced']['sequences']) if 'enhanced' in result else 0\n",
        "\n",
        "                if 'enhanced' in result and result['enhanced']['sequences']:\n",
        "                    std_recovery = np.mean(result['standard']['recovery_rates'])\n",
        "                    enh_recovery = np.mean(result['enhanced']['recovery_rates'])\n",
        "                    improvement = enh_recovery - std_recovery\n",
        "\n",
        "                    print(f\"✅ {pdb_code}: Std={std_count}, Enh={enh_count}\")\n",
        "                    print(f\"   Recovery: {std_recovery:.3f} → {enh_recovery:.3f} ({improvement:+.3f})\")\n",
        "                else:\n",
        "                    print(f\"✅ {pdb_code}: Standard={std_count}, Enhanced=Failed\")\n",
        "            else:\n",
        "                print(f\"❌ {pdb_code}: Complete failure\")\n",
        "\n",
        "        if (i + 1) % 3 == 0:\n",
        "            print(f\"\\n📊 Progress: {i+1}/{len(pdb_codes)} proteins completed\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# Start testing\n",
        "print(\"🔬 Starting multi-protein enhanced test...\")\n",
        "print(\"🧪 Testing subset first...\")\n",
        "all_enhanced_results = test_subset_first()\n",
        "\n",
        "if len(all_enhanced_results) > 0:\n",
        "    success_rate = len(all_enhanced_results) / len(design_config) # Calculate success rate based on subset size\n",
        "    print(f\"\\n📊 Subset success rate: {success_rate:.1%}\")\n",
        "\n",
        "    # Update the condition to check if any enhanced model results are present\n",
        "    if any('enhanced' in result and result['enhanced']['sequences'] for result in all_enhanced_results.values()):\n",
        "        print(\"✅ Subset successful! Running full dataset...\")\n",
        "        full_results = run_full_dataset()\n",
        "        all_enhanced_results.update(full_results)\n",
        "        print(f\"\\n🎯 Complete test: {len(all_enhanced_results)}/{len(pdb_codes)} proteins processed\")\n",
        "    else:\n",
        "        print(\"⚠️ Subset had issues. Check logs before full run.\")\n",
        "else:\n",
        "    print(\"❌ Subset failed. Debug required.\")\n",
        "\n",
        "print(f\"\\n📈 FINAL: {len(all_enhanced_results)} proteins processed\")\n",
        "\n",
        "#@title Cell 12: Comprehensive Analysis (Complete)\n",
        "\n",
        "def analyze_single_protein(pdb_code, results):\n",
        "    \"\"\"Analyze single protein results\"\"\"\n",
        "    print(f\"\\n📈 RESULTS FOR {pdb_code}:\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    improvements = {}\n",
        "\n",
        "    # Standard results\n",
        "    if results['standard']['sequences']:\n",
        "        std_recovery = np.mean(results['standard']['recovery_rates'])\n",
        "        std_score = np.mean(results['standard']['scores'])\n",
        "        print(f\"📊 Standard: Recovery={std_recovery:.3f}, Score={std_score:.4f}\")\n",
        "\n",
        "    # Enhanced results\n",
        "    if 'enhanced' in results and results['enhanced']['sequences']:\n",
        "        enh_recovery = np.mean(results['enhanced']['recovery_rates'])\n",
        "        enh_score = np.mean(results['enhanced']['scores'])\n",
        "        print(f\"🚀 Enhanced: Recovery={enh_recovery:.3f}, Score={enh_score:.4f}\")\n",
        "\n",
        "        if results['standard']['sequences']:\n",
        "            recovery_improvement = enh_recovery - std_recovery\n",
        "            score_improvement = enh_score - std_score\n",
        "\n",
        "            print(f\"🎯 Improvements:\")\n",
        "            print(f\"   Recovery: {recovery_improvement:+.3f} ({recovery_improvement*100:+.1f}%)\")\n",
        "            print(f\"   Score: {score_improvement:+.4f}\")\n",
        "\n",
        "            improvements = {\n",
        "                'recovery': recovery_improvement,\n",
        "                'score': score_improvement,\n",
        "                'enhanced_working': True\n",
        "            }\n",
        "\n",
        "            # Detailed metrics\n",
        "            try:\n",
        "                standard_metrics = calculate_enhanced_metrics(\n",
        "                    results['standard']['native_sequence'],\n",
        "                    results['standard']['sequences'],\n",
        "                    results['standard']['scores'],\n",
        "                    \"Standard\"\n",
        "                )\n",
        "\n",
        "                enhanced_metrics = calculate_enhanced_metrics(\n",
        "                    results['enhanced']['native_sequence'],\n",
        "                    results['enhanced']['sequences'],\n",
        "                    results['enhanced']['scores'],\n",
        "                    \"Enhanced\"\n",
        "                )\n",
        "\n",
        "                charged_improvement = np.mean(enhanced_metrics['charged_residue_recovery']) - np.mean(standard_metrics['charged_residue_recovery'])\n",
        "                electrostatic_improvement = np.mean(enhanced_metrics['electrostatic_score']) - np.mean(standard_metrics['electrostatic_score'])\n",
        "\n",
        "                print(f\"   Charged Recovery: {charged_improvement:+.1f}%\")\n",
        "                print(f\"   Electrostatic Score: {electrostatic_improvement:+.3f}\")\n",
        "\n",
        "                improvements.update({\n",
        "                    'charged_recovery': charged_improvement,\n",
        "                    'electrostatic_score': electrostatic_improvement\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   ⚠️ Detailed metrics failed: {e}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"❌ Enhanced: Failed\")\n",
        "        improvements = {'enhanced_working': False}\n",
        "\n",
        "    return improvements\n",
        "\n",
        "def create_summary_table(all_results):\n",
        "    \"\"\"Create summary table\"\"\"\n",
        "    print(f\"\\n📊 SUMMARY TABLE ({len(all_results)} proteins):\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"{'PDB':<6} {'Std Rec':<8} {'Enh Rec':<8} {'Rec Δ':<8} {'Status':<12}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    summary_stats = {\n",
        "        'total_proteins': len(all_results),\n",
        "        'enhanced_working': 0,\n",
        "        'improved_recovery': 0,\n",
        "        'improved_charged': 0,\n",
        "        'recovery_improvements': [],\n",
        "        'charged_improvements': []\n",
        "    }\n",
        "\n",
        "    for pdb_code, results in all_results.items():\n",
        "        improvements = analyze_single_protein(pdb_code, results)\n",
        "\n",
        "        if improvements.get('enhanced_working', False):\n",
        "            summary_stats['enhanced_working'] += 1\n",
        "\n",
        "            std_recovery = np.mean(results['standard']['recovery_rates'])\n",
        "            enh_recovery = np.mean(results['enhanced']['recovery_rates'])\n",
        "            recovery_delta = improvements.get('recovery', 0)\n",
        "\n",
        "            summary_stats['recovery_improvements'].append(recovery_delta)\n",
        "\n",
        "            if recovery_delta > 0:\n",
        "                summary_stats['improved_recovery'] += 1\n",
        "\n",
        "            if 'charged_recovery' in improvements:\n",
        "                charged_delta = improvements['charged_recovery']\n",
        "                summary_stats['charged_improvements'].append(charged_delta)\n",
        "                if charged_delta > 0:\n",
        "                    summary_stats['improved_charged'] += 1\n",
        "\n",
        "            status = \"✅ Working\"\n",
        "            if recovery_delta > 0.01:\n",
        "                status = \"🚀 Improved\"\n",
        "            elif recovery_delta < -0.01:\n",
        "                status = \"⚠️ Worse\"\n",
        "\n",
        "            print(f\"{pdb_code:<6} {std_recovery:.3f}   {enh_recovery:.3f}   {recovery_delta:+.3f}   {status}\")\n",
        "        else:\n",
        "            std_recovery = np.mean(results['standard']['recovery_rates']) if results['standard']['sequences'] else 0\n",
        "            print(f\"{pdb_code:<6} {std_recovery:.3f}   Failed   N/A      ❌ Failed\")\n",
        "\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    # Statistics\n",
        "    print(f\"\\n📊 OVERALL STATISTICS:\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Total proteins: {summary_stats['total_proteins']}\")\n",
        "    print(f\"Enhanced working: {summary_stats['enhanced_working']}/{summary_stats['total_proteins']} ({summary_stats['enhanced_working']/summary_stats['total_proteins']*100:.1f}%)\")\n",
        "\n",
        "    if summary_stats['recovery_improvements']:\n",
        "        avg_improvement = np.mean(summary_stats['recovery_improvements'])\n",
        "        print(f\"Average recovery improvement: {avg_improvement:+.3f} ({avg_improvement*100:+.1f}%)\")\n",
        "        print(f\"Proteins with improved recovery: {summary_stats['improved_recovery']}/{summary_stats['enhanced_working']}\")\n",
        "\n",
        "    if summary_stats['charged_improvements']:\n",
        "        avg_charged = np.mean(summary_stats['charged_improvements'])\n",
        "        print(f\"Average charged improvement: {avg_charged:+.1f}%\")\n",
        "        print(f\"Proteins with improved charged recovery: {summary_stats['improved_charged']}/{len(summary_stats['charged_improvements'])}\")\n",
        "\n",
        "    # Assessment\n",
        "    success_metrics = []\n",
        "    if summary_stats['enhanced_working'] >= summary_stats['total_proteins'] * 0.7:\n",
        "        success_metrics.append(\"Model stability\")\n",
        "    if summary_stats['recovery_improvements'] and np.mean(summary_stats['recovery_improvements']) > 0:\n",
        "        success_metrics.append(\"Recovery improvement\")\n",
        "    if summary_stats['charged_improvements'] and np.mean(summary_stats['charged_improvements']) > 0:\n",
        "        success_metrics.append(\"Charged residue improvement\")\n",
        "\n",
        "    print(f\"\\n🏆 ASSESSMENT:\")\n",
        "    print(\"=\"*30)\n",
        "    if len(success_metrics) >= 2:\n",
        "        print(\"✅ SUCCESS: Enhanced ProteinMPNN working well!\")\n",
        "        print(\"🚀 Ready for production and scaling\")\n",
        "    elif len(success_metrics) == 1:\n",
        "        print(\"⚠️ PARTIAL SUCCESS: Some improvements\")\n",
        "        print(\"🔧 Consider tuning and optimization\")\n",
        "    else:\n",
        "        print(\"❌ NEEDS IMPROVEMENT: No clear benefits\")\n",
        "        print(\"🔧 Debug integration and features\")\n",
        "\n",
        "    return summary_stats\n",
        "\n",
        "def create_visualization(all_results):\n",
        "    \"\"\"Create visualization\"\"\"\n",
        "    if not all_results:\n",
        "        return\n",
        "\n",
        "    pdb_codes = list(all_results.keys())\n",
        "    std_recoveries = []\n",
        "    enh_recoveries = []\n",
        "\n",
        "    for pdb_code in pdb_codes:\n",
        "        results = all_results[pdb_code]\n",
        "        if results['standard']['sequences']:\n",
        "            std_recoveries.append(np.mean(results['standard']['recovery_rates']))\n",
        "        else:\n",
        "            std_recoveries.append(0)\n",
        "\n",
        "        if 'enhanced' in results and results['enhanced']['sequences']:\n",
        "            enh_recoveries.append(np.mean(results['enhanced']['recovery_rates']))\n",
        "        else:\n",
        "            enh_recoveries.append(0)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    fig.suptitle(f'Enhanced ProteinMPNN Results - {len(all_results)} Proteins', fontsize=16)\n",
        "\n",
        "    # Recovery comparison\n",
        "    x_pos = np.arange(len(pdb_codes))\n",
        "    width = 0.35\n",
        "\n",
        "    ax1.bar(x_pos - width/2, std_recoveries, width, label='Standard', alpha=0.7, color='blue')\n",
        "    ax1.bar(x_pos + width/2, enh_recoveries, width, label='Enhanced', alpha=0.7, color='orange')\n",
        "    ax1.set_xlabel('Protein')\n",
        "    ax1.set_ylabel('Recovery Rate')\n",
        "    ax1.set_title('Recovery Comparison')\n",
        "    ax1.legend()\n",
        "    ax1.set_xticks(x_pos)\n",
        "    ax1.set_xticklabels(pdb_codes, rotation=45)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Improvements\n",
        "    improvements = [enh - std for enh, std in zip(enh_recoveries, std_recoveries)]\n",
        "    colors = ['green' if x > 0 else 'red' for x in improvements]\n",
        "\n",
        "    ax2.bar(range(len(improvements)), improvements, color=colors, alpha=0.7)\n",
        "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "    ax2.set_xlabel('Protein')\n",
        "    ax2.set_ylabel('Recovery Improvement')\n",
        "    ax2.set_title('Improvements per Protein')\n",
        "    ax2.set_xticks(range(len(improvements)))\n",
        "    ax2.set_xticklabels(pdb_codes, rotation=45)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Main analysis\n",
        "if len(all_enhanced_results) == 0:\n",
        "    print(\"❌ No results to analyze\")\n",
        "else:\n",
        "    print(f\"📊 Analyzing {len(all_enhanced_results)} proteins...\")\n",
        "\n",
        "    summary_stats = create_summary_table(all_enhanced_results)\n",
        "\n",
        "    try:\n",
        "        create_visualization(all_enhanced_results)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Visualization failed: {e}\")\n",
        "\n",
        "    print(f\"\\n🚀 RECOMMENDATIONS:\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    if summary_stats['enhanced_working'] >= summary_stats['total_proteins'] * 0.7:\n",
        "        print(\"✅ Model stable - ready for scaling\")\n",
        "\n",
        "        if summary_stats['recovery_improvements'] and np.mean(summary_stats['recovery_improvements']) > 0:\n",
        "            print(\"🎯 Next steps:\")\n",
        "            print(\"   - Scale to 500-1000 charged complexes\")\n",
        "            print(\"   - Add GAN discriminator\")\n",
        "            print(\"   - Implement electrostatic post-processing\")\n",
        "        else:\n",
        "            print(\"🔧 Optimization needed:\")\n",
        "            print(\"   - Tune integration parameters\")\n",
        "            print(\"   - Add electrostatic loss function\")\n",
        "    else:\n",
        "        print(\"🔧 Debug required:\")\n",
        "        print(\"   - Fix tensor compatibility\")\n",
        "        print(\"   - Simplify integration\")\n",
        "        print(\"   - Test components separately\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎉 MULTI-PROTEIN ENHANCED PROTEINMPNN COMPLETE!\")\n",
        "print(\"=\"*60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔬 Starting multi-protein enhanced test...\n",
            "🧪 Testing subset first...\n",
            "🧪 Testing subset: ['3JAY', '3JB0', '5A1A', '5FTJ', '5FTK', '5K12', '5L35', '5MDO', '5MDR', '5MF4', '5MFM', '5MH6', '5MHF', '5MIW', '5MJY', '5MK1', '5MK3', '5MKM', '5MKN', '5MLD', '5MNS', '5MNV', '5MQZ', '5MR0', '5MUX', '5MX5', '5MY0', '5MY2', '5MZ2', '5MZ5']\n",
            "========================================\n",
            "\n",
            "🧬 Processing 3JAY...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 3JAY\n",
            "============================================================\n",
            "✔ Using existing file: ./3JAY.pdb\n",
            "Chain configuration: {'3JAY': (['B'], ['A', 'C', 'D', 'E'])}\n",
            "Length of chain A: 1057\n",
            "Length of chain E: 292\n",
            "Length of chain D: 292\n",
            "Length of chain C: 1260\n",
            "Length of chain B: 1199\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.6951\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.428, Score=0.8803\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.422, Score=0.8652\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.414, Score=0.8689\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.413, Score=0.8721\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 4083 residues\n",
            "✅ enhanced native score: 1.6599\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.421, Score=0.8171\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.405, Score=0.8477\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.420, Score=0.8283\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.429, Score=0.8293\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 3JAY: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 3JB0...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 3JB0\n",
            "============================================================\n",
            "✔ Using existing file: ./3JB0.pdb\n",
            "Chain configuration: {'3JB0': (['B'], ['A', 'C', 'D', 'E'])}\n",
            "Length of chain A: 1057\n",
            "Length of chain E: 292\n",
            "Length of chain D: 292\n",
            "Length of chain C: 1260\n",
            "Length of chain B: 1199\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.6388\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.450, Score=0.8543\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.444, Score=0.8617\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.456, Score=0.8539\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.442, Score=0.8710\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 4082 residues\n",
            "✅ enhanced native score: 1.5925\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.455, Score=0.8147\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.446, Score=0.8111\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.434, Score=0.8171\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.444, Score=0.8166\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 3JB0: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5A1A...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5A1A\n",
            "============================================================\n",
            "✔ Using existing file: ./5A1A.pdb\n",
            "Chain configuration: {'5A1A': (['A'], ['B', 'C', 'D'])}\n",
            "Length of chain D: 1022\n",
            "Length of chain C: 1022\n",
            "Length of chain B: 1022\n",
            "Length of chain A: 1022\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.5031\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.483, Score=0.8225\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.489, Score=0.8126\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.480, Score=0.8090\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.487, Score=0.8058\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 4088 residues\n",
            "✅ enhanced native score: 1.4597\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.483, Score=0.7740\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.484, Score=0.7877\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.500, Score=0.7784\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.481, Score=0.7925\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5A1A: Standard=4, Enhanced=4\n",
            "\n",
            "📊 Progress: 3/30 proteins completed\n",
            "\n",
            "🧬 Processing 5FTJ...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5FTJ\n",
            "============================================================\n",
            "✔ Using existing file: ./5FTJ.pdb\n",
            "Chain configuration: {'5FTJ': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "Length of chain F: 743\n",
            "Length of chain A: 743\n",
            "Length of chain E: 743\n",
            "Length of chain D: 743\n",
            "Length of chain C: 743\n",
            "Length of chain B: 743\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.6204\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.484, Score=0.8672\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.450, Score=0.8775\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.454, Score=0.8822\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.470, Score=0.8704\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 4338 residues\n",
            "✅ enhanced native score: 1.5802\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.490, Score=0.8417\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.458, Score=0.8501\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.467, Score=0.8335\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.459, Score=0.8456\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5FTJ: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5FTK...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5FTK\n",
            "============================================================\n",
            "✔ Using existing file: ./5FTK.pdb\n",
            "Chain configuration: {'5FTK': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "Length of chain F: 743\n",
            "Length of chain A: 743\n",
            "Length of chain E: 743\n",
            "Length of chain D: 743\n",
            "Length of chain C: 743\n",
            "Length of chain B: 743\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.5480\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.477, Score=0.8641\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.467, Score=0.8588\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.474, Score=0.8727\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.467, Score=0.8587\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 4338 residues\n",
            "✅ enhanced native score: 1.5098\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.470, Score=0.8386\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.458, Score=0.8579\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.466, Score=0.8237\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.495, Score=0.8380\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5FTK: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5K12...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5K12\n",
            "============================================================\n",
            "✔ Using existing file: ./5K12.pdb\n",
            "Chain configuration: {'5K12': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "Length of chain F: 437\n",
            "Length of chain A: 437\n",
            "Length of chain E: 437\n",
            "Length of chain D: 437\n",
            "Length of chain C: 437\n",
            "Length of chain B: 437\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.4657\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.483, Score=0.8091\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.497, Score=0.7924\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.486, Score=0.8018\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.507, Score=0.8004\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 1764 residues\n",
            "✅ enhanced native score: 1.4399\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.503, Score=0.7771\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.507, Score=0.7512\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.493, Score=0.7503\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.483, Score=0.7497\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5K12: Standard=4, Enhanced=4\n",
            "\n",
            "📊 Progress: 6/30 proteins completed\n",
            "\n",
            "🧬 Processing 5L35...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5L35\n",
            "============================================================\n",
            "✔ Using existing file: ./5L35.pdb\n",
            "Chain configuration: {'5L35': (['A'], ['B', 'C', 'D', 'E', 'F', 'G'])}\n",
            "Length of chain F: 422\n",
            "Length of chain A: 422\n",
            "Length of chain G: 422\n",
            "Length of chain E: 422\n",
            "Length of chain D: 422\n",
            "Length of chain C: 422\n",
            "Length of chain B: 422\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.5001\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.502, Score=0.8425\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.493, Score=0.8328\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.498, Score=0.8307\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.502, Score=0.8478\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 2954 residues\n",
            "✅ enhanced native score: 1.4592\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.505, Score=0.8019\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.514, Score=0.8101\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.519, Score=0.8061\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.507, Score=0.8034\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5L35: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MDO...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MDO\n",
            "============================================================\n",
            "✔ Using existing file: ./5MDO.pdb\n",
            "Chain configuration: {'5MDO': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "Length of chain F: 341\n",
            "Length of chain A: 341\n",
            "Length of chain E: 341\n",
            "Length of chain D: 341\n",
            "Length of chain C: 341\n",
            "Length of chain B: 341\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.3567\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.525, Score=0.7924\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.525, Score=0.7881\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.516, Score=0.7813\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.513, Score=0.7846\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 1992 residues\n",
            "✅ enhanced native score: 1.3199\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.504, Score=0.7427\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.522, Score=0.7348\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.525, Score=0.7592\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.519, Score=0.7579\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MDO: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MDR...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MDR\n",
            "============================================================\n",
            "✔ Using existing file: ./5MDR.pdb\n",
            "Chain configuration: {'5MDR': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "Length of chain F: 341\n",
            "Length of chain A: 341\n",
            "Length of chain E: 341\n",
            "Length of chain D: 341\n",
            "Length of chain C: 341\n",
            "Length of chain B: 341\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.3648\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.531, Score=0.7867\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.531, Score=0.7798\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.540, Score=0.7794\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.499, Score=0.8007\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 1992 residues\n",
            "✅ enhanced native score: 1.3114\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.522, Score=0.7610\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.516, Score=0.7635\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.510, Score=0.7495\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.531, Score=0.7544\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MDR: Standard=4, Enhanced=4\n",
            "\n",
            "📊 Progress: 9/30 proteins completed\n",
            "\n",
            "🧬 Processing 5MF4...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MF4\n",
            "============================================================\n",
            "✔ Using existing file: ./5MF4.pdb\n",
            "Chain configuration: {'5MF4': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "Length of chain F: 380\n",
            "Length of chain A: 437\n",
            "Length of chain E: 137\n",
            "Length of chain D: 440\n",
            "Length of chain C: 440\n",
            "Length of chain B: 440\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.6497\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.416, Score=0.8164\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.446, Score=0.7984\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.446, Score=0.7994\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.444, Score=0.7970\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 2175 residues\n",
            "✅ enhanced native score: 1.6146\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.439, Score=0.7644\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.451, Score=0.7713\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.441, Score=0.7816\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.434, Score=0.7575\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MF4: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MFM...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MFM\n",
            "============================================================\n",
            "✔ Using existing file: ./5MFM.pdb\n",
            "Chain configuration: {'5MFM': (['A'], ['B', 'C', 'D', 'E', 'F', 'G', 'H'])}\n",
            "Length of chain F: 342\n",
            "Length of chain A: 343\n",
            "❌ Complete failure: 'seq_chain_G'\n",
            "❌ 5MFM: Failed\n",
            "\n",
            "🧬 Processing 5MH6...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MH6\n",
            "============================================================\n",
            "✔ Using existing file: ./5MH6.pdb\n",
            "Chain configuration: {'5MH6': (['A'], ['B', 'C', 'D'])}\n",
            "Length of chain D: 308\n",
            "Length of chain C: 308\n",
            "Length of chain B: 306\n",
            "Length of chain A: 306\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.0409\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.634, Score=0.6047\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.647, Score=0.5893\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.654, Score=0.6015\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.650, Score=0.6120\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 1228 residues\n",
            "✅ enhanced native score: 1.0445\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.627, Score=0.5773\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.641, Score=0.5924\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.621, Score=0.5767\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.631, Score=0.5904\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MH6: Standard=4, Enhanced=4\n",
            "\n",
            "📊 Progress: 12/30 proteins completed\n",
            "\n",
            "🧬 Processing 5MHF...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MHF\n",
            "============================================================\n",
            "✔ Using existing file: ./5MHF.pdb\n",
            "Chain configuration: {'5MHF': (['A'], ['B', 'C', 'D'])}\n",
            "Length of chain D: 782\n",
            "Length of chain C: 782\n",
            "Length of chain B: 778\n",
            "Length of chain A: 778\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.3335\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.545, Score=0.7695\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.543, Score=0.7678\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.537, Score=0.7577\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.524, Score=0.7793\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 2972 residues\n",
            "✅ enhanced native score: 1.3040\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.541, Score=0.7361\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.538, Score=0.7302\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.556, Score=0.7262\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.546, Score=0.7316\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MHF: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MIW...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MIW\n",
            "============================================================\n",
            "✔ Using existing file: ./5MIW.pdb\n",
            "Chain configuration: {'5MIW': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "Length of chain F: 252\n",
            "Length of chain A: 252\n",
            "Length of chain E: 251\n",
            "Length of chain D: 251\n",
            "Length of chain C: 251\n",
            "Length of chain B: 252\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.0753\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.639, Score=0.5861\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.615, Score=0.5743\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.627, Score=0.5790\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.635, Score=0.5947\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 1509 residues\n",
            "✅ enhanced native score: 1.0566\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.603, Score=0.5487\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.639, Score=0.5552\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.611, Score=0.5613\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.611, Score=0.5594\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MIW: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MJY...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MJY\n",
            "============================================================\n",
            "✔ Using existing file: ./5MJY.pdb\n",
            "Chain configuration: {'5MJY': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "Length of chain F: 20\n",
            "Length of chain A: 358\n",
            "Length of chain E: 20\n",
            "Length of chain D: 358\n",
            "Length of chain C: 360\n",
            "Length of chain B: 361\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.5701\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.475, Score=0.8352\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.453, Score=0.8282\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.439, Score=0.8371\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.472, Score=0.8261\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 1477 residues\n",
            "✅ enhanced native score: 1.5630\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.464, Score=0.7995\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.492, Score=0.7711\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.486, Score=0.7745\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.461, Score=0.7841\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MJY: Standard=4, Enhanced=4\n",
            "\n",
            "📊 Progress: 15/30 proteins completed\n",
            "\n",
            "🧬 Processing 5MK1...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MK1\n",
            "============================================================\n",
            "✔ Using existing file: ./5MK1.pdb\n",
            "Chain configuration: {'5MK1': (['A'], ['B', 'C', 'D', 'E', 'F', 'G', 'H'])}\n",
            "Length of chain F: 11\n",
            "Length of chain A: 358\n",
            "❌ Complete failure: 'seq_chain_G'\n",
            "❌ 5MK1: Failed\n",
            "\n",
            "🧬 Processing 5MK3...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MK3\n",
            "============================================================\n",
            "✔ Using existing file: ./5MK3.pdb\n",
            "Chain configuration: {'5MK3': (['A'], ['B', 'C', 'D', 'E', 'F', 'G', 'H'])}\n",
            "Length of chain F: 11\n",
            "Length of chain A: 361\n",
            "Length of chain G: 10\n",
            "Length of chain E: 11\n",
            "Length of chain D: 361\n",
            "Length of chain H: 11\n",
            "Length of chain C: 361\n",
            "Length of chain B: 361\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.5949\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.468, Score=0.8039\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.471, Score=0.7940\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.463, Score=0.7978\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.449, Score=0.7996\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 1487 residues\n",
            "✅ enhanced native score: 1.5548\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.463, Score=0.7662\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.463, Score=0.7439\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.474, Score=0.7662\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.454, Score=0.7605\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MK3: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MKM...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MKM\n",
            "============================================================\n",
            "✔ Using existing file: ./5MKM.pdb\n",
            "Chain configuration: {'5MKM': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "Length of chain F: 275\n",
            "Length of chain A: 278\n",
            "Length of chain E: 277\n",
            "Length of chain D: 277\n",
            "Length of chain C: 275\n",
            "Length of chain B: 278\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 0.9112\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.712, Score=0.5582\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.709, Score=0.5568\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.680, Score=0.5557\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.716, Score=0.5598\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 1660 residues\n",
            "✅ enhanced native score: 0.8721\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.701, Score=0.5392\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.673, Score=0.5497\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.694, Score=0.5287\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.698, Score=0.5202\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MKM: Standard=4, Enhanced=4\n",
            "\n",
            "📊 Progress: 18/30 proteins completed\n",
            "\n",
            "🧬 Processing 5MKN...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MKN\n",
            "============================================================\n",
            "✔ Using existing file: ./5MKN.pdb\n",
            "Chain configuration: {'5MKN': (['A'], ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'd'])}\n",
            "Length of chain d: 72\n",
            "Length of chain A: 71\n",
            "Length of chain D: 71\n",
            "Length of chain W: 71\n",
            "Length of chain G: 71\n",
            "Length of chain Q: 71\n",
            "Length of chain T: 71\n",
            "Length of chain X: 71\n",
            "Length of chain R: 71\n",
            "Length of chain U: 71\n",
            "Length of chain L: 71\n",
            "Length of chain N: 71\n",
            "Length of chain J: 71\n",
            "Length of chain Z: 71\n",
            "Length of chain C: 71\n",
            "Length of chain a: 71\n",
            "Length of chain F: 71\n",
            "Length of chain I: 71\n",
            "Length of chain b: 71\n",
            "Length of chain M: 71\n",
            "Length of chain K: 71\n",
            "Length of chain P: 71\n",
            "Length of chain O: 71\n",
            "Length of chain E: 71\n",
            "Length of chain V: 71\n",
            "Length of chain Y: 71\n",
            "Length of chain H: 71\n",
            "Length of chain B: 71\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.2767\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.535, Score=0.6420\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.563, Score=0.6394\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.577, Score=0.6155\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.592, Score=0.6185\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 1962 residues\n",
            "✅ enhanced native score: 1.1992\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.563, Score=0.6311\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.577, Score=0.6733\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.563, Score=0.5851\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.563, Score=0.6054\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MKN: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MLD...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MLD\n",
            "============================================================\n",
            "✔ Using existing file: ./5MLD.pdb\n",
            "Chain configuration: {'5MLD': (['A'], ['B', 'C', 'D', 'E', 'F', 'G', 'H'])}\n",
            "Length of chain F: 252\n",
            "Length of chain A: 252\n",
            "Length of chain G: 252\n",
            "Length of chain E: 252\n",
            "Length of chain D: 252\n",
            "Length of chain H: 252\n",
            "Length of chain C: 252\n",
            "Length of chain B: 252\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 0.8813\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.675, Score=0.5324\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.714, Score=0.5380\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.687, Score=0.5554\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.694, Score=0.5523\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 2016 residues\n",
            "✅ enhanced native score: 0.8353\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.690, Score=0.5164\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.702, Score=0.4904\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.698, Score=0.5019\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.694, Score=0.5098\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MLD: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MNS...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MNS\n",
            "============================================================\n",
            "✔ Using existing file: ./5MNS.pdb\n",
            "Chain configuration: {'5MNS': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "Length of chain F: 395\n",
            "Length of chain A: 395\n",
            "Length of chain E: 395\n",
            "Length of chain D: 395\n",
            "Length of chain C: 395\n",
            "Length of chain B: 395\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.4672\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.486, Score=0.8007\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.491, Score=0.7959\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.489, Score=0.7970\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.501, Score=0.7789\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 2368 residues\n",
            "✅ enhanced native score: 1.4228\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.494, Score=0.7446\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.501, Score=0.7651\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.489, Score=0.7506\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.471, Score=0.7556\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MNS: Standard=4, Enhanced=4\n",
            "\n",
            "📊 Progress: 21/30 proteins completed\n",
            "\n",
            "🧬 Processing 5MNV...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MNV\n",
            "============================================================\n",
            "✔ Using existing file: ./5MNV.pdb\n",
            "Chain configuration: {'5MNV': (['A'], ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'])}\n",
            "Length of chain F: 395\n",
            "Length of chain I: 378\n",
            "Length of chain A: 397\n",
            "Length of chain G: 395\n",
            "Length of chain E: 395\n",
            "Length of chain D: 394\n",
            "Length of chain H: 395\n",
            "Length of chain C: 396\n",
            "Length of chain B: 394\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.5276\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.506, Score=0.7789\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.461, Score=0.8295\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.479, Score=0.8097\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.474, Score=0.7920\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 3427 residues\n",
            "✅ enhanced native score: 1.4780\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.474, Score=0.7759\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.481, Score=0.7585\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.496, Score=0.7446\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.499, Score=0.7841\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MNV: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MQZ...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MQZ\n",
            "============================================================\n",
            "✔ Using existing file: ./5MQZ.pdb\n",
            "Chain configuration: {'5MQZ': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "Length of chain F: 290\n",
            "Length of chain A: 290\n",
            "Length of chain E: 290\n",
            "Length of chain D: 290\n",
            "Length of chain C: 290\n",
            "Length of chain B: 290\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.0824\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.626, Score=0.6139\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.636, Score=0.6234\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.636, Score=0.6163\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.640, Score=0.6054\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 1717 residues\n",
            "✅ enhanced native score: 1.0511\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.626, Score=0.5611\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.640, Score=0.5806\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.629, Score=0.5610\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.629, Score=0.5577\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MQZ: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MR0...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MR0\n",
            "============================================================\n",
            "✔ Using existing file: ./5MR0.pdb\n",
            "Chain configuration: {'5MR0': (['F'], ['A', 'B', 'C', 'D', 'E'])}\n",
            "Length of chain F: 290\n",
            "Length of chain A: 290\n",
            "Length of chain E: 290\n",
            "Length of chain D: 290\n",
            "Length of chain C: 290\n",
            "Length of chain B: 290\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.0807\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.629, Score=0.6237\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.615, Score=0.6403\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.640, Score=0.6261\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.650, Score=0.6192\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 1722 residues\n",
            "✅ enhanced native score: 1.0263\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.657, Score=0.5790\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.633, Score=0.5802\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.661, Score=0.5985\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.657, Score=0.5871\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MR0: Standard=4, Enhanced=4\n",
            "\n",
            "📊 Progress: 24/30 proteins completed\n",
            "\n",
            "🧬 Processing 5MUX...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MUX\n",
            "============================================================\n",
            "✔ Using existing file: ./5MUX.pdb\n",
            "Chain configuration: {'5MUX': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "Length of chain F: 468\n",
            "Length of chain A: 469\n",
            "Length of chain E: 472\n",
            "Length of chain D: 471\n",
            "Length of chain C: 472\n",
            "Length of chain B: 472\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.2974\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.548, Score=0.7096\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.559, Score=0.7167\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.554, Score=0.7372\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.542, Score=0.7179\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 2824 residues\n",
            "✅ enhanced native score: 1.2554\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.546, Score=0.6834\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.550, Score=0.6895\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.557, Score=0.6857\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.537, Score=0.6926\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MUX: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MX5...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MX5\n",
            "============================================================\n",
            "✔ Using existing file: ./5MX5.pdb\n",
            "Chain configuration: {'5MX5': (['A'], ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N'])}\n",
            "Length of chain F: 245\n",
            "Length of chain I: 235\n",
            "Length of chain L: 239\n",
            "Length of chain N: 237\n",
            "Length of chain J: 236\n",
            "Length of chain M: 240\n",
            "Length of chain A: 239\n",
            "Length of chain G: 240\n",
            "Length of chain K: 238\n",
            "Length of chain E: 239\n",
            "Length of chain D: 240\n",
            "Length of chain H: 237\n",
            "Length of chain C: 238\n",
            "Length of chain B: 237\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.4561\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.490, Score=0.8613\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.500, Score=0.9317\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.495, Score=0.9150\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.495, Score=0.9234\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 2929 residues\n",
            "✅ enhanced native score: 1.4419\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.490, Score=0.8816\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.471, Score=0.8787\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.490, Score=0.8634\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.481, Score=0.8616\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MX5: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MY0...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MY0\n",
            "============================================================\n",
            "✔ Using existing file: ./5MY0.pdb\n",
            "Chain configuration: {'5MY0': (['A'], ['B', 'C', 'D'])}\n",
            "Length of chain D: 852\n",
            "Length of chain C: 852\n",
            "Length of chain B: 852\n",
            "Length of chain A: 852\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.2596\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.563, Score=0.6964\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.551, Score=0.6705\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.570, Score=0.6799\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.573, Score=0.6819\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 3398 residues\n",
            "✅ enhanced native score: 1.2062\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.569, Score=0.6349\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.558, Score=0.6453\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.561, Score=0.6459\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.575, Score=0.6390\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MY0: Standard=4, Enhanced=4\n",
            "\n",
            "📊 Progress: 27/30 proteins completed\n",
            "\n",
            "🧬 Processing 5MY2...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MY2\n",
            "============================================================\n",
            "✔ Using existing file: ./5MY2.pdb\n",
            "Chain configuration: {'5MY2': (['A'], ['B', 'C', 'D'])}\n",
            "Length of chain D: 852\n",
            "Length of chain C: 852\n",
            "Length of chain B: 852\n",
            "Length of chain A: 852\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.2748\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.561, Score=0.6943\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.568, Score=0.6796\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.562, Score=0.6794\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.566, Score=0.6779\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 3396 residues\n",
            "✅ enhanced native score: 1.2317\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.541, Score=0.6546\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.562, Score=0.6471\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.574, Score=0.6451\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.545, Score=0.6617\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MY2: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MZ2...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MZ2\n",
            "============================================================\n",
            "✔ Using existing file: ./5MZ2.pdb\n",
            "Chain configuration: {'5MZ2': (['A'], ['C', 'H', 'F', 'D', 'B', 'E', 'G', 'I', 'O', 'L', 'N', 'M', 'P', 'J', 'K'])}\n",
            "Length of chain F: 481\n",
            "Length of chain I: 139\n",
            "Length of chain L: 139\n",
            "Length of chain N: 139\n",
            "Length of chain J: 139\n",
            "Length of chain M: 139\n",
            "Length of chain A: 481\n",
            "Length of chain G: 481\n",
            "Length of chain K: 139\n",
            "Length of chain P: 139\n",
            "Length of chain O: 139\n",
            "Length of chain E: 481\n",
            "Length of chain D: 482\n",
            "Length of chain H: 481\n",
            "Length of chain C: 480\n",
            "Length of chain B: 480\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.3996\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.550, Score=0.6668\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.541, Score=0.6783\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.526, Score=0.6862\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.543, Score=0.6859\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 4895 residues\n",
            "✅ enhanced native score: 1.3527\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.541, Score=0.6529\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.541, Score=0.6400\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.541, Score=0.6428\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.535, Score=0.6429\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MZ2: Standard=4, Enhanced=4\n",
            "\n",
            "🧬 Processing 5MZ5...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 5MZ5\n",
            "============================================================\n",
            "✔ Using existing file: ./5MZ5.pdb\n",
            "Chain configuration: {'5MZ5': (['A'], ['B', 'C', 'D'])}\n",
            "Length of chain D: 480\n",
            "Length of chain C: 481\n",
            "Length of chain B: 480\n",
            "Length of chain A: 481\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.2324\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.588, Score=0.6721\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.588, Score=0.6866\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.580, Score=0.6848\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.595, Score=0.6860\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ Calculated electrostatic potentials for 1922 residues\n",
            "✅ enhanced native score: 1.1608\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.582, Score=0.6437\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ enhanced seq 2: Recovery=0.584, Score=0.6477\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ enhanced seq 3: Recovery=0.580, Score=0.6344\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ enhanced seq 4: Recovery=0.565, Score=0.6556\n",
            "✅ enhanced completed: 4 sequences\n",
            "✅ 5MZ5: Standard=4, Enhanced=4\n",
            "\n",
            "📊 Progress: 30/30 proteins completed\n",
            "\n",
            "📊 Subset success rate: 93.3%\n",
            "✅ Subset successful! Running full dataset...\n",
            "🚀 Running full dataset...\n",
            "==================================================\n",
            "\n",
            "🧬 Processing 3JAY (1/30)...\n",
            "\n",
            "============================================================\n",
            "ENHANCED Processing 3JAY\n",
            "============================================================\n",
            "✔ Using existing file: ./3JAY.pdb\n",
            "Chain configuration: {'3JAY': (['B'], ['A', 'C', 'D', 'E'])}\n",
            "Length of chain A: 1057\n",
            "Length of chain E: 292\n",
            "Length of chain D: 292\n",
            "Length of chain C: 1260\n",
            "Length of chain B: 1199\n",
            "\n",
            "🔄 Processing with standard model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating standard native score...\n",
            "✅ standard native score: 1.6988\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ standard seq 1: Recovery=0.411, Score=0.8654\n",
            "🔄 Generating sequence 2/4...\n",
            "✅ standard seq 2: Recovery=0.422, Score=0.8781\n",
            "🔄 Generating sequence 3/4...\n",
            "✅ standard seq 3: Recovery=0.421, Score=0.8653\n",
            "🔄 Generating sequence 4/4...\n",
            "✅ standard seq 4: Recovery=0.420, Score=0.8682\n",
            "✅ standard completed: 4 sequences\n",
            "\n",
            "🔄 Processing with enhanced model...\n",
            "🔄 Featurizing...\n",
            "🔄 Calculating enhanced native score...\n",
            "✅ enhanced native score: 1.6637\n",
            "🔄 Generating sequence 1/4...\n",
            "✅ enhanced seq 1: Recovery=0.416, Score=0.8231\n",
            "🔄 Generating sequence 2/4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Enhanced ProteinMPNN v2: Multi-Objective Learning with Structural Features\n",
        "Complete rewrite addressing training failures from v1\n",
        "\"\"\"\n",
        "\n",
        "#@title Cell 1: Install Dependencies\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"Install required packages\"\"\"\n",
        "    core_packages = ['biopython', 'matplotlib', 'pandas', 'scipy', 'scikit-learn']\n",
        "\n",
        "    for package in core_packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "            print(f\"✅ Installed {package}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Failed to install {package}: {e}\")\n",
        "\n",
        "install_packages()\n",
        "\n",
        "#@title Cell 2: Import Libraries\n",
        "import json, time, os, sys, glob, subprocess, warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "if not os.path.isdir(\"ProteinMPNN\"):\n",
        "    os.system(\"git clone -q https://github.com/dauparas/ProteinMPNN.git\")\n",
        "sys.path.append('/content/ProteinMPNN')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import copy\n",
        "import random\n",
        "from scipy import stats\n",
        "from collections import defaultdict, Counter\n",
        "import re\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "try:\n",
        "    from Bio import PDB\n",
        "    from Bio.PDB import PDBParser\n",
        "    from scipy.spatial.distance import cdist\n",
        "    BIO_AVAILABLE = True\n",
        "    print(\"✅ Bio/PDB imports successful\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Bio imports failed: {e}\")\n",
        "    BIO_AVAILABLE = False\n",
        "\n",
        "from protein_mpnn_utils import (\n",
        "    loss_nll, loss_smoothed, gather_edges, gather_nodes,\n",
        "    gather_nodes_t, cat_neighbors_nodes, _scores, _S_to_seq,\n",
        "    tied_featurize, parse_PDB, StructureDataset,\n",
        "    StructureDatasetPDB, ProteinMPNN\n",
        ")\n",
        "\n",
        "print(\"✅ All libraries imported successfully!\")\n",
        "\n",
        "#@title Cell 3: Structural Environment Calculator\n",
        "class StructuralEnvironmentCalculator:\n",
        "    \"\"\"Calculate meaningful structural environment features\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.feature_cache = {}\n",
        "\n",
        "        # Amino acid properties\n",
        "        self.charge_map = {\n",
        "            'ARG': +1, 'LYS': +1, 'HIS': +0.5,  # Positive\n",
        "            'ASP': -1, 'GLU': -1,                # Negative\n",
        "            'SER': 0, 'THR': 0, 'ASN': 0, 'GLN': 0, 'CYS': 0, 'TYR': 0, 'TRP': 0,  # Polar\n",
        "            'ALA': 0, 'VAL': 0, 'ILE': 0, 'LEU': 0, 'MET': 0, 'PHE': 0, 'PRO': 0, 'GLY': 0  # Nonpolar\n",
        "        }\n",
        "\n",
        "        self.hydrophobicity_map = {\n",
        "            'ILE': 4.5, 'VAL': 4.2, 'LEU': 3.8, 'PHE': 2.8, 'CYS': 2.5, 'MET': 1.9,\n",
        "            'ALA': 1.8, 'GLY': -0.4, 'THR': -0.7, 'SER': -0.8, 'TRP': -0.9,\n",
        "            'TYR': -1.3, 'PRO': -1.6, 'HIS': -3.2, 'GLU': -3.5, 'GLN': -3.5,\n",
        "            'ASP': -3.5, 'ASN': -3.5, 'LYS': -3.9, 'ARG': -4.5\n",
        "        }\n",
        "\n",
        "        self.volume_map = {\n",
        "            'GLY': 60.1, 'ALA': 88.6, 'SER': 89.0, 'CYS': 108.5, 'ASP': 111.1,\n",
        "            'PRO': 112.7, 'ASN': 114.1, 'THR': 116.1, 'GLU': 138.4, 'VAL': 140.0,\n",
        "            'GLN': 143.8, 'HIS': 153.2, 'MET': 162.9, 'ILE': 166.7, 'LEU': 166.7,\n",
        "            'LYS': 168.6, 'ARG': 173.4, 'PHE': 189.9, 'TYR': 193.6, 'TRP': 227.8\n",
        "        }\n",
        "\n",
        "    def calculate_structural_features(self, pdb_path, chain_ids):\n",
        "        \"\"\"Calculate comprehensive structural environment features\"\"\"\n",
        "\n",
        "        cache_key = f\"{pdb_path}_{'-'.join(sorted(chain_ids))}\"\n",
        "        if cache_key in self.feature_cache:\n",
        "            return self.feature_cache[cache_key]\n",
        "\n",
        "        if not BIO_AVAILABLE:\n",
        "            print(\"⚠️ BioPython not available, using dummy features\")\n",
        "            dummy_features = np.zeros((100, 12))  # 12 features\n",
        "            dummy_info = [{'chain': 'A', 'resnum': i, 'resname': 'ALA'} for i in range(100)]\n",
        "            return dummy_features, dummy_info\n",
        "\n",
        "        try:\n",
        "            parser = PDBParser(QUIET=True)\n",
        "            structure = parser.get_structure('protein', pdb_path)\n",
        "\n",
        "            residue_info = []\n",
        "            positions = []\n",
        "\n",
        "            # Extract residue information\n",
        "            for model in structure:\n",
        "                for chain in model:\n",
        "                    if chain.id in chain_ids:\n",
        "                        for residue in chain:\n",
        "                            if residue.get_id()[0] == ' ' and 'CA' in residue:\n",
        "                                resname = residue.get_resname()\n",
        "                                ca_pos = residue['CA'].get_coord()\n",
        "\n",
        "                                residue_info.append({\n",
        "                                    'chain': chain.id,\n",
        "                                    'resnum': residue.get_id()[1],\n",
        "                                    'resname': resname,\n",
        "                                    'position': ca_pos\n",
        "                                })\n",
        "                                positions.append(ca_pos)\n",
        "\n",
        "            if not residue_info:\n",
        "                return None, None\n",
        "\n",
        "            positions = np.array(positions)\n",
        "            n_residues = len(residue_info)\n",
        "\n",
        "            # Calculate distance matrix\n",
        "            dist_matrix = cdist(positions, positions)\n",
        "\n",
        "            features = []\n",
        "\n",
        "            for i, res_info in enumerate(residue_info):\n",
        "                resname = res_info['resname']\n",
        "\n",
        "                # Basic properties\n",
        "                charge = self.charge_map.get(resname, 0)\n",
        "                hydrophobicity = self.hydrophobicity_map.get(resname, 0)\n",
        "                volume = self.volume_map.get(resname, 100)\n",
        "\n",
        "                # Local environment (within 10Å)\n",
        "                local_mask = (dist_matrix[i] < 10.0) & (dist_matrix[i] > 0.1)\n",
        "                local_residues = [residue_info[j] for j in range(n_residues) if local_mask[j]]\n",
        "\n",
        "                # Count local properties\n",
        "                local_positive = sum(1 for r in local_residues if self.charge_map.get(r['resname'], 0) > 0)\n",
        "                local_negative = sum(1 for r in local_residues if self.charge_map.get(r['resname'], 0) < 0)\n",
        "                local_polar = sum(1 for r in local_residues if r['resname'] in ['SER', 'THR', 'ASN', 'GLN', 'TYR', 'CYS'])\n",
        "                local_hydrophobic = sum(1 for r in local_residues if r['resname'] in ['ALA', 'VAL', 'ILE', 'LEU', 'MET', 'PHE', 'PRO'])\n",
        "\n",
        "                # Average local hydrophobicity\n",
        "                local_hydrophobic_avg = np.mean([self.hydrophobicity_map.get(r['resname'], 0) for r in local_residues]) if local_residues else 0\n",
        "\n",
        "                # Secondary structure approximation (simple distance-based)\n",
        "                # Count neighbors within 6Å (roughly secondary structure contacts)\n",
        "                ss_contacts = np.sum((dist_matrix[i] < 6.0) & (dist_matrix[i] > 0.1))\n",
        "\n",
        "                # Solvent accessibility approximation (neighbors within 8Å)\n",
        "                accessibility = 1.0 / (1.0 + np.sum((dist_matrix[i] < 8.0) & (dist_matrix[i] > 0.1)))\n",
        "\n",
        "                # Electrostatic environment\n",
        "                electrostatic_potential = 0.0\n",
        "                for j, other_res in enumerate(residue_info):\n",
        "                    if i != j and dist_matrix[i, j] > 0.1:\n",
        "                        other_charge = self.charge_map.get(other_res['resname'], 0)\n",
        "                        if other_charge != 0:\n",
        "                            electrostatic_potential += other_charge / max(dist_matrix[i, j], 1.0)\n",
        "\n",
        "                # Compile features vector\n",
        "                feature_vector = [\n",
        "                    charge,                    # 0: Residue charge\n",
        "                    hydrophobicity,           # 1: Hydrophobicity\n",
        "                    volume / 200.0,           # 2: Normalized volume\n",
        "                    local_positive,           # 3: Local positive count\n",
        "                    local_negative,           # 4: Local negative count\n",
        "                    local_polar,              # 5: Local polar count\n",
        "                    local_hydrophobic,        # 6: Local hydrophobic count\n",
        "                    local_hydrophobic_avg,    # 7: Average local hydrophobicity\n",
        "                    ss_contacts / 20.0,       # 8: Normalized secondary structure contacts\n",
        "                    accessibility,            # 9: Solvent accessibility approximation\n",
        "                    electrostatic_potential,  # 10: Electrostatic potential\n",
        "                    len(local_residues) / 30.0  # 11: Normalized local density\n",
        "                ]\n",
        "\n",
        "                features.append(feature_vector)\n",
        "\n",
        "            features = np.array(features)\n",
        "\n",
        "            # Normalize features\n",
        "            scaler = StandardScaler()\n",
        "            features = scaler.fit_transform(features)\n",
        "\n",
        "            print(f\"✅ Calculated structural features for {len(features)} residues\")\n",
        "\n",
        "            result = (features, residue_info)\n",
        "            self.feature_cache[cache_key] = result\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Structural features calculation failed: {e}\")\n",
        "            return None, None\n",
        "\n",
        "    def get_structural_tensor(self, pdb_path, chain_ids, sequence_length):\n",
        "        \"\"\"Get structural features as tensor\"\"\"\n",
        "\n",
        "        features, residue_info = self.calculate_structural_features(pdb_path, chain_ids)\n",
        "\n",
        "        if features is None:\n",
        "            return torch.zeros(sequence_length, 12)\n",
        "\n",
        "        # Pad or truncate to match sequence length\n",
        "        if len(features) < sequence_length:\n",
        "            padding = np.zeros((sequence_length - len(features), 12))\n",
        "            features = np.vstack([features, padding])\n",
        "        elif len(features) > sequence_length:\n",
        "            features = features[:sequence_length]\n",
        "\n",
        "        return torch.tensor(features, dtype=torch.float32)\n",
        "\n",
        "#@title Cell 4: Multi-Objective Loss Functions\n",
        "class MultiObjectiveLoss(nn.Module):\n",
        "    \"\"\"Multi-objective loss function for enhanced training\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 base_weight=1.0,\n",
        "                 charged_weight=3.0,\n",
        "                 conservation_weight=1.5,\n",
        "                 diversity_weight=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.base_weight = base_weight\n",
        "        self.charged_weight = charged_weight\n",
        "        self.conservation_weight = conservation_weight\n",
        "        self.diversity_weight = diversity_weight\n",
        "\n",
        "        # Charged residue indices in ProteinMPNN alphabet\n",
        "        self.charged_indices = torch.tensor([3, 4, 8, 11, 15])  # D, E, H, K, R\n",
        "        self.positive_indices = torch.tensor([8, 11, 15])       # H, K, R\n",
        "        self.negative_indices = torch.tensor([3, 4])            # D, E\n",
        "\n",
        "    def forward(self, log_probs, S_target, mask, structural_features=None):\n",
        "        \"\"\"Calculate multi-objective loss\"\"\"\n",
        "\n",
        "        batch_size, seq_len, vocab_size = log_probs.shape\n",
        "\n",
        "        # Flatten tensors\n",
        "        flat_log_probs = log_probs.view(-1, vocab_size)\n",
        "        flat_targets = S_target.view(-1)\n",
        "        flat_mask = mask.view(-1)\n",
        "\n",
        "        # Base cross-entropy loss\n",
        "        base_loss = F.nll_loss(flat_log_probs, flat_targets, reduction='none')\n",
        "        base_loss = (base_loss * flat_mask).sum() / flat_mask.sum()\n",
        "\n",
        "        # Charged residue accuracy loss\n",
        "        charged_loss = self._charged_residue_loss(flat_log_probs, flat_targets, flat_mask)\n",
        "\n",
        "        # Charge conservation loss\n",
        "        conservation_loss = self._charge_conservation_loss(log_probs, S_target, mask)\n",
        "\n",
        "        # Optional diversity loss\n",
        "        diversity_loss = self._diversity_loss(log_probs, mask)\n",
        "\n",
        "        # Combine losses\n",
        "        total_loss = (self.base_weight * base_loss +\n",
        "                     self.charged_weight * charged_loss +\n",
        "                     self.conservation_weight * conservation_loss +\n",
        "                     self.diversity_weight * diversity_loss)\n",
        "\n",
        "        return {\n",
        "            'total_loss': total_loss,\n",
        "            'base_loss': base_loss,\n",
        "            'charged_loss': charged_loss,\n",
        "            'conservation_loss': conservation_loss,\n",
        "            'diversity_loss': diversity_loss\n",
        "        }\n",
        "\n",
        "    def _charged_residue_loss(self, flat_log_probs, flat_targets, flat_mask):\n",
        "        \"\"\"Focus on charged residue accuracy\"\"\"\n",
        "\n",
        "        # Identify charged residue positions\n",
        "        charged_mask = torch.zeros_like(flat_targets, dtype=torch.bool)\n",
        "        for idx in self.charged_indices.to(flat_targets.device):\n",
        "            charged_mask |= (flat_targets == idx)\n",
        "\n",
        "        if charged_mask.sum() == 0:\n",
        "            return torch.tensor(0.0, device=flat_targets.device)\n",
        "\n",
        "        # Calculate loss only for charged positions\n",
        "        charged_loss = F.nll_loss(flat_log_probs, flat_targets, reduction='none')\n",
        "        charged_loss = charged_loss * charged_mask.float() * flat_mask\n",
        "\n",
        "        return charged_loss.sum() / (charged_mask.float() * flat_mask).sum()\n",
        "\n",
        "    def _charge_conservation_loss(self, log_probs, S_target, mask):\n",
        "        \"\"\"Penalize charge imbalance\"\"\"\n",
        "\n",
        "        batch_size, seq_len = S_target.shape\n",
        "\n",
        "        # Calculate target charges\n",
        "        target_charges = torch.zeros_like(S_target, dtype=torch.float)\n",
        "        for idx in self.positive_indices.to(S_target.device):\n",
        "            target_charges += (S_target == idx).float()\n",
        "        for idx in self.negative_indices.to(S_target.device):\n",
        "            target_charges -= (S_target == idx).float()\n",
        "\n",
        "        # Calculate predicted charges using soft assignment\n",
        "        probs = F.softmax(log_probs, dim=-1)\n",
        "        pred_charges = torch.zeros_like(probs[:,:,0])\n",
        "\n",
        "        for idx in self.positive_indices.to(S_target.device):\n",
        "            pred_charges += probs[:,:,idx]\n",
        "        for idx in self.negative_indices.to(S_target.device):\n",
        "            pred_charges -= probs[:,:,idx]\n",
        "\n",
        "        # Calculate charge difference per sequence\n",
        "        target_total_charge = (target_charges * mask).sum(dim=1)\n",
        "        pred_total_charge = (pred_charges * mask).sum(dim=1)\n",
        "\n",
        "        charge_diff = torch.abs(target_total_charge - pred_total_charge)\n",
        "\n",
        "        return charge_diff.mean()\n",
        "\n",
        "    def _diversity_loss(self, log_probs, mask):\n",
        "        \"\"\"Encourage diversity in predictions\"\"\"\n",
        "\n",
        "        probs = F.softmax(log_probs, dim=-1)\n",
        "\n",
        "        # Calculate entropy (higher entropy = more diversity)\n",
        "        entropy = -torch.sum(probs * log_probs, dim=-1)\n",
        "        masked_entropy = (entropy * mask).sum() / mask.sum()\n",
        "\n",
        "        # Return negative entropy as loss (minimize negative entropy = maximize entropy)\n",
        "        return -masked_entropy * 0.1  # Small weight\n",
        "\n",
        "#@title Cell 5: Enhanced ProteinMPNN Architecture\n",
        "class StructurallyEnhancedProteinMPNN(ProteinMPNN):\n",
        "    \"\"\"Enhanced ProteinMPNN with structural environment integration\"\"\"\n",
        "\n",
        "    def __init__(self, structural_calculator, pdb_path=None, chain_ids=None, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.structural_calculator = structural_calculator\n",
        "        self.pdb_path = pdb_path\n",
        "        self.chain_ids = chain_ids or []\n",
        "\n",
        "        # Structural feature integration\n",
        "        self.structural_projection = nn.Linear(12, self.hidden_dim // 2)\n",
        "        self.integration_layer = nn.MultiheadAttention(\n",
        "            embed_dim=self.hidden_dim,\n",
        "            num_heads=8,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Enhanced output layer with structural bias\n",
        "        self.structural_bias = nn.Linear(12, 21)  # Direct bias for each amino acid\n",
        "\n",
        "        # Learnable integration weights\n",
        "        self.structure_weight = nn.Parameter(torch.tensor(0.2))\n",
        "        self.bias_weight = nn.Parameter(torch.tensor(0.1))\n",
        "\n",
        "        # Multi-objective loss\n",
        "        self.loss_fn = MultiObjectiveLoss(\n",
        "            base_weight=1.0,\n",
        "            charged_weight=2.0,\n",
        "            conservation_weight=1.0,\n",
        "            diversity_weight=0.3\n",
        "        )\n",
        "\n",
        "        print(f\"✅ Structurally Enhanced ProteinMPNN initialized\")\n",
        "\n",
        "    def get_structural_enhancement(self, S, mask):\n",
        "        \"\"\"Get structural enhancement features\"\"\"\n",
        "\n",
        "        if self.pdb_path is None:\n",
        "            return None, None\n",
        "\n",
        "        try:\n",
        "            seq_len = S.shape[1]\n",
        "            structural_features = self.structural_calculator.get_structural_tensor(\n",
        "                self.pdb_path, self.chain_ids, seq_len\n",
        "            ).to(S.device)\n",
        "\n",
        "            # Project structural features\n",
        "            structural_proj = self.structural_projection(structural_features)  # [seq_len, hidden_dim//2]\n",
        "\n",
        "            # Create bias for amino acids\n",
        "            structural_bias = self.structural_bias(structural_features)  # [seq_len, 21]\n",
        "\n",
        "            return structural_proj, structural_bias\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Structural enhancement failed: {e}\")\n",
        "            return None, None\n",
        "\n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn,\n",
        "                use_input_decoding_order=False, decoding_order=None):\n",
        "        \"\"\"Enhanced forward pass with structural integration\"\"\"\n",
        "\n",
        "        # Fix tensor dtypes\n",
        "        residue_idx = residue_idx.long()\n",
        "        S = S.long()\n",
        "\n",
        "        try:\n",
        "            device = X.device\n",
        "\n",
        "            # Get structural enhancements\n",
        "            structural_proj, structural_bias = self.get_structural_enhancement(S, mask)\n",
        "\n",
        "            # Standard ProteinMPNN forward pass with modifications\n",
        "            E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "            E_idx = E_idx.long()\n",
        "\n",
        "            h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device, dtype=E.dtype)\n",
        "            h_E = self.W_e(E)\n",
        "\n",
        "            # Enhanced encoder with structural integration\n",
        "            for i, layer in enumerate(self.encoder_layers):\n",
        "                h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "                h_V = layer(h_V, h_EV, mask)\n",
        "\n",
        "                # Integrate structural features in middle layers\n",
        "                if (structural_proj is not None and\n",
        "                    i == len(self.encoder_layers) // 2):\n",
        "\n",
        "                    # Expand structural features for batch\n",
        "                    batch_size = h_V.shape[0]\n",
        "                    structural_batch = structural_proj.unsqueeze(0).repeat(batch_size, 1, 1)\n",
        "\n",
        "                    # Concatenate with node features\n",
        "                    h_V_expanded = torch.cat([\n",
        "                        h_V,\n",
        "                        structural_batch[:, :h_V.shape[1], :]\n",
        "                    ], dim=-1)\n",
        "\n",
        "                    # Apply attention-based integration\n",
        "                    enhanced_h_V, attention_weights = self.integration_layer(\n",
        "                        h_V_expanded, h_V_expanded, h_V_expanded\n",
        "                    )\n",
        "\n",
        "                    # Project back to original dimension\n",
        "                    if enhanced_h_V.shape[-1] != h_V.shape[-1]:\n",
        "                        projection = nn.Linear(enhanced_h_V.shape[-1], h_V.shape[-1]).to(device)\n",
        "                        enhanced_h_V = projection(enhanced_h_V)\n",
        "\n",
        "                    # Weighted integration\n",
        "                    structure_w = torch.sigmoid(self.structure_weight)\n",
        "                    h_V = structure_w * enhanced_h_V + (1 - structure_w) * h_V\n",
        "                    h_V = h_V * mask.unsqueeze(-1)\n",
        "\n",
        "            # Standard decoder\n",
        "            h_S = self.W_s(S)\n",
        "\n",
        "            for layer in self.decoder_layers:\n",
        "                h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "                h_EXV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "                h_S = layer(h_S, h_EXV, mask)\n",
        "\n",
        "            # Output with structural bias\n",
        "            logits = self.W_out(h_S)\n",
        "\n",
        "            # Apply structural bias\n",
        "            if structural_bias is not None:\n",
        "                bias_weight = torch.sigmoid(self.bias_weight)\n",
        "                structural_bias_batch = structural_bias.unsqueeze(0).repeat(logits.shape[0], 1, 1)\n",
        "                logits = logits + bias_weight * structural_bias_batch[:, :logits.shape[1], :]\n",
        "\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "\n",
        "            return log_probs\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Enhanced forward failed, using fallback: {e}\")\n",
        "            # Fallback to standard ProteinMPNN\n",
        "            return super().forward(X, S, mask, chain_M, residue_idx, chain_encoding_all, randn,\n",
        "                                 use_input_decoding_order, decoding_order)\n",
        "\n",
        "    def calculate_enhanced_loss(self, log_probs, S_target, mask, structural_features=None):\n",
        "        \"\"\"Calculate multi-objective loss\"\"\"\n",
        "        return self.loss_fn(log_probs, S_target, mask, structural_features)\n",
        "\n",
        "#@title Cell 6: Device Setup and Model Loading\n",
        "def get_safe_device():\n",
        "    \"\"\"Get safe device\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            test_tensor = torch.tensor([1.0], device='cuda')\n",
        "            test_result = test_tensor + 1\n",
        "            return torch.device(\"cuda:0\")\n",
        "        except:\n",
        "            print(\"⚠️ CUDA test failed, using CPU\")\n",
        "            return torch.device(\"cpu\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "device = get_safe_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize structural calculator\n",
        "structural_calculator = StructuralEnvironmentCalculator()\n",
        "\n",
        "# Load models\n",
        "model_name = \"v_48_020\"\n",
        "backbone_noise = 0.00\n",
        "path_to_model_weights = '/content/ProteinMPNN/vanilla_model_weights'\n",
        "hidden_dim = 128\n",
        "num_layers = 3\n",
        "\n",
        "model_folder_path = path_to_model_weights\n",
        "if model_folder_path[-1] != '/':\n",
        "    model_folder_path = model_folder_path + '/'\n",
        "checkpoint_path = model_folder_path + f'{model_name}.pt'\n",
        "\n",
        "standard_model = None\n",
        "enhanced_model = None\n",
        "\n",
        "try:\n",
        "    print(\"🔥 Loading ProteinMPNN checkpoint...\")\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "    print('Number of edges:', checkpoint['num_edges'])\n",
        "\n",
        "    # Standard model\n",
        "    standard_model = ProteinMPNN(\n",
        "        num_letters=21,\n",
        "        node_features=hidden_dim,\n",
        "        edge_features=hidden_dim,\n",
        "        hidden_dim=hidden_dim,\n",
        "        num_encoder_layers=num_layers,\n",
        "        num_decoder_layers=num_layers,\n",
        "        augment_eps=backbone_noise,\n",
        "        k_neighbors=checkpoint['num_edges']\n",
        "    )\n",
        "\n",
        "    standard_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    standard_model = standard_model.to(device)\n",
        "    standard_model.eval()\n",
        "    print(\"✅ Standard ProteinMPNN loaded!\")\n",
        "\n",
        "    # Enhanced model\n",
        "    enhanced_model = StructurallyEnhancedProteinMPNN(\n",
        "        structural_calculator=structural_calculator,\n",
        "        pdb_path=None,\n",
        "        chain_ids=None,\n",
        "        num_letters=21,\n",
        "        node_features=hidden_dim,\n",
        "        edge_features=hidden_dim,\n",
        "        hidden_dim=hidden_dim,\n",
        "        num_encoder_layers=num_layers,\n",
        "        num_decoder_layers=num_layers,\n",
        "        augment_eps=backbone_noise,\n",
        "        k_neighbors=checkpoint['num_edges']\n",
        "    )\n",
        "\n",
        "    enhanced_model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "    enhanced_model = enhanced_model.to(device)\n",
        "    enhanced_model.eval()\n",
        "    print(\"✅ Enhanced ProteinMPNN v2 loaded!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading models: {e}\")\n",
        "\n",
        "#@title Cell 7: Helper Functions\n",
        "def get_pdb_file(pdb_code, dest_dir=\".\", overwrite=False):\n",
        "    \"\"\"Download PDB file with improved error handling\"\"\"\n",
        "    import os, urllib.request, gzip, shutil\n",
        "    from urllib.error import HTTPError, URLError\n",
        "\n",
        "    code = (pdb_code or \"\").strip()\n",
        "    if not code:\n",
        "        return None\n",
        "\n",
        "    code_l = code.lower()\n",
        "    code_u = code.upper()\n",
        "    out_path = os.path.join(dest_dir, f\"{code_u}.pdb\")\n",
        "\n",
        "    if os.path.exists(out_path) and not overwrite:\n",
        "        return out_path\n",
        "\n",
        "    try:\n",
        "        url1 = f\"https://files.rcsb.org/download/{code_l}.pdb\"\n",
        "        urllib.request.urlretrieve(url1, out_path)\n",
        "        print(f\"✅ Downloaded {code_u}\")\n",
        "        return out_path\n",
        "    except (HTTPError, URLError):\n",
        "        try:\n",
        "            subdir = code_l[1:3]\n",
        "            url2 = f\"https://files.rcsb.org/pub/pdb/data/structures/divided/pdb/{subdir}/pdb{code_l}.ent.gz\"\n",
        "            gz_path = os.path.join(dest_dir, f\"pdb{code_l}.ent.gz\")\n",
        "\n",
        "            urllib.request.urlretrieve(url2, gz_path)\n",
        "            with gzip.open(gz_path, \"rb\") as f_in, open(out_path, \"wb\") as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "            os.remove(gz_path)\n",
        "\n",
        "            print(f\"✅ Downloaded and decompressed {code_u}\")\n",
        "            return out_path\n",
        "        except Exception:\n",
        "            if os.path.exists(gz_path):\n",
        "                try: os.remove(gz_path)\n",
        "                except: pass\n",
        "            print(f\"❌ Could not download {code_u}\")\n",
        "            return None\n",
        "\n",
        "def calculate_enhanced_metrics(native_seq, designed_seqs, scores, model_type=\"Standard\"):\n",
        "    \"\"\"Calculate comprehensive metrics\"\"\"\n",
        "    metrics = {\n",
        "        'sequence_recovery': [],\n",
        "        'identity': [],\n",
        "        'score': [],\n",
        "        'length': [],\n",
        "        'charged_residue_recovery': [],\n",
        "        'positive_recovery': [],\n",
        "        'negative_recovery': [],\n",
        "        'charge_conservation': [],\n",
        "        'model_type': []\n",
        "    }\n",
        "\n",
        "    native_clean = native_seq.replace('/', '').replace('X', '')\n",
        "    charged_residues = set('DEKR')\n",
        "    positive_residues = set('KRH')\n",
        "    negative_residues = set('DE')\n",
        "\n",
        "    for designed_seq, score in zip(designed_seqs, scores):\n",
        "        designed_clean = designed_seq.replace('/', '').replace('X', '')\n",
        "        length = min(len(native_clean), len(designed_clean))\n",
        "        if length == 0:\n",
        "            continue\n",
        "\n",
        "        # Basic recovery\n",
        "        identical = sum(1 for a, b in zip(native_clean[:length], designed_clean[:length]) if a == b)\n",
        "        identity = (identical / length) * 100\n",
        "\n",
        "        metrics['sequence_recovery'].append(identity)\n",
        "        metrics['identity'].append(identity)\n",
        "        metrics['score'].append(float(score))\n",
        "        metrics['length'].append(length)\n",
        "        metrics['model_type'].append(model_type)\n",
        "\n",
        "        # Charged residue recovery\n",
        "        native_charged_pos = [i for i, aa in enumerate(native_clean[:length]) if aa in charged_residues]\n",
        "        if native_charged_pos:\n",
        "            charged_recovery = sum(1 for pos in native_charged_pos\n",
        "                                 if pos < len(designed_clean) and designed_clean[pos] in charged_residues)\n",
        "            charged_recovery_rate = (charged_recovery / len(native_charged_pos)) * 100\n",
        "        else:\n",
        "            charged_recovery_rate = 0\n",
        "        metrics['charged_residue_recovery'].append(charged_recovery_rate)\n",
        "\n",
        "        # Positive residue recovery\n",
        "        native_positive_pos = [i for i, aa in enumerate(native_clean[:length]) if aa in positive_residues]\n",
        "        if native_positive_pos:\n",
        "            positive_recovery = sum(1 for pos in native_positive_pos\n",
        "                                  if pos < len(designed_clean) and designed_clean[pos] in positive_residues)\n",
        "            positive_recovery_rate = (positive_recovery / len(native_positive_pos)) * 100\n",
        "        else:\n",
        "            positive_recovery_rate = 0\n",
        "        metrics['positive_recovery'].append(positive_recovery_rate)\n",
        "\n",
        "        # Negative residue recovery\n",
        "        native_negative_pos = [i for i, aa in enumerate(native_clean[:length]) if aa in negative_residues]\n",
        "        if native_negative_pos:\n",
        "            negative_recovery = sum(1 for pos in native_negative_pos\n",
        "                                  if pos < len(designed_clean) and designed_clean[pos] in negative_residues)\n",
        "            negative_recovery_rate = (negative_recovery / len(native_negative_pos)) * 100\n",
        "        else:\n",
        "            negative_recovery_rate = 0\n",
        "        metrics['negative_recovery'].append(negative_recovery_rate)\n",
        "\n",
        "        # Charge conservation\n",
        "        native_charge = sum(1 if aa in 'KRH' else -1 if aa in 'DE' else 0 for aa in native_clean[:length])\n",
        "        designed_charge = sum(1 if aa in 'KRH' else -1 if aa in 'DE' else 0 for aa in designed_clean[:length])\n",
        "        charge_conservation = 1.0 - abs(native_charge - designed_charge) / max(abs(native_charge) + 1, 1)\n",
        "        metrics['charge_conservation'].append(charge_conservation)\n",
        "\n",
        "    return pd.DataFrame(metrics)\n",
        "\n",
        "#@title Cell 8: Enhanced Processing Function\n",
        "def enhanced_process_protein(pdb_code, designed_chains, fixed_chains, num_sequences=4, temperature=0.1):\n",
        "    \"\"\"Enhanced protein processing function with comprehensive metrics\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ENHANCED Processing {pdb_code}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    results = {\n",
        "        'pdb_code': pdb_code,\n",
        "        'standard': {'sequences': [], 'scores': [], 'recovery_rates': [], 'native_score': 0, 'native_sequence': ''},\n",
        "        'enhanced': {'sequences': [], 'scores': [], 'recovery_rates': [], 'native_score': 0, 'native_sequence': ''}\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        pdb_path = get_pdb_file(pdb_code)\n",
        "        if pdb_path is None:\n",
        "            return None\n",
        "\n",
        "        chain_list = list(set(designed_chains + fixed_chains))\n",
        "        pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "        dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=20000)\n",
        "        chain_id_dict = {pdb_dict_list[0]['name']: (designed_chains, fixed_chains)}\n",
        "\n",
        "        print(f\"Chain configuration: {chain_id_dict}\")\n",
        "\n",
        "        # Test models\n",
        "        models_to_test = []\n",
        "        if standard_model is not None:\n",
        "            models_to_test.append(('standard', standard_model))\n",
        "        if enhanced_model is not None:\n",
        "            enhanced_model.pdb_path = pdb_path\n",
        "            enhanced_model.chain_ids = chain_list\n",
        "            models_to_test.append(('enhanced', enhanced_model))\n",
        "\n",
        "        for model_name, model in models_to_test:\n",
        "            print(f\"\\n🔥 Processing with {model_name} model...\")\n",
        "\n",
        "            try:\n",
        "                for ix, protein in enumerate(dataset_valid):\n",
        "                    batch_clones = [copy.deepcopy(protein)]\n",
        "\n",
        "                    features = tied_featurize(\n",
        "                        batch_clones, device, chain_id_dict, None, None, None, None, None\n",
        "                    )\n",
        "\n",
        "                    (X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list,\n",
        "                     visible_list_list, masked_list_list, masked_chain_length_list_list,\n",
        "                     chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask,\n",
        "                     tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all,\n",
        "                     bias_by_res_all, tied_beta) = features\n",
        "\n",
        "                    # Native scoring\n",
        "                    print(f\"🔥 Calculating {model_name} native score...\")\n",
        "                    randn_1 = torch.randn(chain_M.shape, device=device)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        log_probs = model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "                        mask_for_loss = mask*chain_M*chain_M_pos\n",
        "                        scores = _scores(S, log_probs, mask_for_loss)\n",
        "                        native_score = scores.cpu().data.numpy().mean()\n",
        "\n",
        "                    results[model_name]['native_score'] = float(native_score)\n",
        "                    print(f\"✅ {model_name} native score: {native_score:.4f}\")\n",
        "\n",
        "                    # Generate sequences\n",
        "                    for seq_num in range(num_sequences):\n",
        "                        print(f\"🔥 Generating sequence {seq_num+1}/{num_sequences}...\")\n",
        "\n",
        "                        randn_2 = torch.randn(chain_M.shape, device=device)\n",
        "\n",
        "                        with torch.no_grad():\n",
        "                            sample_dict = model.sample(\n",
        "                                X, randn_2, S, chain_M, chain_encoding_all, residue_idx,\n",
        "                                mask=mask, temperature=temperature, omit_AAs_np=np.zeros(21),\n",
        "                                bias_AAs_np=np.zeros(21), chain_M_pos=chain_M_pos,\n",
        "                                omit_AA_mask=omit_AA_mask, pssm_coef=pssm_coef,\n",
        "                                pssm_bias=pssm_bias, pssm_multi=0.0,\n",
        "                                pssm_log_odds_flag=False,\n",
        "                                pssm_log_odds_mask=(pssm_log_odds_all > 0.0).float(),\n",
        "                                pssm_bias_flag=False, bias_by_res=bias_by_res_all\n",
        "                            )\n",
        "\n",
        "                            S_sample = sample_dict[\"S\"]\n",
        "\n",
        "                            log_probs = model(X, S_sample, mask, chain_M*chain_M_pos, residue_idx,\n",
        "                                            chain_encoding_all, randn_2, use_input_decoding_order=True,\n",
        "                                            decoding_order=sample_dict[\"decoding_order\"])\n",
        "                            scores = _scores(S_sample, log_probs, mask_for_loss)\n",
        "                            score_value = scores.cpu().data.numpy()[0]\n",
        "\n",
        "                            # Recovery calculation\n",
        "                            seq_recovery_rate = torch.sum(\n",
        "                                torch.sum(F.one_hot(S[0], 21) * F.one_hot(S_sample[0], 21), axis=-1) *\n",
        "                                mask_for_loss[0]\n",
        "                            ) / torch.sum(mask_for_loss[0])\n",
        "\n",
        "                            # Convert sequences\n",
        "                            seq = _S_to_seq(S_sample[0], chain_M[0])\n",
        "                            native_seq = _S_to_seq(S[0], chain_M[0])\n",
        "\n",
        "                            if results[model_name]['native_sequence'] == '':\n",
        "                                results[model_name]['native_sequence'] = native_seq\n",
        "\n",
        "                            results[model_name]['sequences'].append(seq)\n",
        "                            results[model_name]['scores'].append(float(score_value))\n",
        "                            results[model_name]['recovery_rates'].append(float(seq_recovery_rate.detach().cpu().numpy()))\n",
        "\n",
        "                            print(f\"✅ {model_name} seq {seq_num+1}: Recovery={seq_recovery_rate:.3f}, Score={score_value:.4f}\")\n",
        "\n",
        "                    print(f\"✅ {model_name} completed: {len(results[model_name]['sequences'])} sequences\")\n",
        "                    break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ {model_name} failed: {e}\")\n",
        "                continue\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Complete failure: {e}\")\n",
        "        return None\n",
        "\n",
        "#@title Cell 9: Training Function for Enhanced Model\n",
        "def train_enhanced_model(csv_path=None, num_epochs=20, learning_rate=1e-4, batch_proteins=8):\n",
        "    \"\"\"Train the enhanced model with improved approach\"\"\"\n",
        "\n",
        "    print(f\"🔥 Starting Enhanced ProteinMPNN v2 Training\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if enhanced_model is None:\n",
        "        print(\"❌ enhanced_model not found. Run setup first.\")\n",
        "        return None\n",
        "\n",
        "    # Create synthetic training data if no CSV provided\n",
        "    training_proteins = [\n",
        "        '1A0O', '1A3N', '1A43', '1A4Y', '1A68', '1A6M', '1AAR', '1AB1',\n",
        "        '1ABE', '1ABO', '1ABS', '1AC0', '1ACB', '1ACF', '1ACI', '1ADB',\n",
        "        '1ADL', '1ADZ', '1AER', '1AFO', '1AG6', '1AGR', '1AH7', '1AI0',\n",
        "        '1AIE', '1AIG', '1AIL', '1AJ3', '1AJJ', '1AK4', '1AKE', '1AKI',\n",
        "        '1AL3', '1AM7', '1AMF', '1AMM', '1AN8', '1AO6', '1AOP', '1AOU',\n",
        "        '1APF', '1APY', '1AQB', '1AQH', '1AR5', '1ARB', '1AS0', '1AS5'\n",
        "    ]\n",
        "\n",
        "    print(f\"Training on {len(training_proteins)} proteins\")\n",
        "\n",
        "    # Put model in training mode\n",
        "    enhanced_model.train()\n",
        "\n",
        "    # Setup optimizer with different learning rates for different components\n",
        "    param_groups = [\n",
        "        {'params': [enhanced_model.structure_weight, enhanced_model.bias_weight], 'lr': learning_rate * 2},\n",
        "        {'params': enhanced_model.structural_projection.parameters(), 'lr': learning_rate},\n",
        "        {'params': enhanced_model.structural_bias.parameters(), 'lr': learning_rate},\n",
        "        {'params': enhanced_model.integration_layer.parameters(), 'lr': learning_rate * 0.5}\n",
        "    ]\n",
        "\n",
        "    optimizer = torch.optim.AdamW(param_groups, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "    training_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_losses = []\n",
        "        epoch_recoveries = []\n",
        "        epoch_charged_recoveries = []\n",
        "\n",
        "        # Sample proteins for this epoch\n",
        "        epoch_proteins = random.sample(training_proteins, min(batch_proteins, len(training_proteins)))\n",
        "\n",
        "        print(f\"\\n📚 Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"Training proteins: {epoch_proteins}\")\n",
        "\n",
        "        for protein_idx, pdb_code in enumerate(epoch_proteins):\n",
        "            try:\n",
        "                pdb_path = get_pdb_file(pdb_code)\n",
        "                if pdb_path is None:\n",
        "                    continue\n",
        "\n",
        "                # Set model paths\n",
        "                enhanced_model.pdb_path = pdb_path\n",
        "                enhanced_model.chain_ids = ['A']  # Default to chain A\n",
        "\n",
        "                # Simple chain configuration\n",
        "                designed_chains = ['A']\n",
        "                fixed_chains = []\n",
        "\n",
        "                chain_list = designed_chains + fixed_chains\n",
        "\n",
        "                pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "                if not pdb_dict_list:\n",
        "                    continue\n",
        "\n",
        "                dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=1000)\n",
        "                chain_id_dict = {pdb_dict_list[0]['name']: (designed_chains, fixed_chains)}\n",
        "\n",
        "                for ix, protein in enumerate(dataset_valid):\n",
        "                    batch_clones = [copy.deepcopy(protein)]\n",
        "\n",
        "                    features = tied_featurize(\n",
        "                        batch_clones, device, chain_id_dict, None, None, None, None, None\n",
        "                    )\n",
        "\n",
        "                    (X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list,\n",
        "                     visible_list_list, masked_list_list, masked_chain_length_list_list,\n",
        "                     chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask,\n",
        "                     tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all,\n",
        "                     bias_by_res_all, tied_beta) = features\n",
        "\n",
        "                    # Skip if sequence too long\n",
        "                    if S.shape[1] > 500:\n",
        "                        continue\n",
        "\n",
        "                    randn_1 = torch.randn(chain_M.shape, device=device)\n",
        "\n",
        "                    # Forward pass with enhanced loss\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    log_probs = enhanced_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "\n",
        "                    # Calculate multi-objective loss\n",
        "                    loss_dict = enhanced_model.calculate_enhanced_loss(\n",
        "                        log_probs, S, mask*chain_M*chain_M_pos\n",
        "                    )\n",
        "\n",
        "                    total_loss = loss_dict['total_loss']\n",
        "\n",
        "                    # Backpropagation\n",
        "                    total_loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(enhanced_model.parameters(), 1.0)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    # Calculate metrics\n",
        "                    with torch.no_grad():\n",
        "                        mask_for_loss = mask * chain_M * chain_M_pos\n",
        "                        seq_recovery = torch.sum(\n",
        "                            F.one_hot(S[0], 21).float() * F.softmax(log_probs[0], dim=-1)\n",
        "                        ).sum(dim=-1) * mask_for_loss[0]\n",
        "                        seq_recovery = seq_recovery.sum() / mask_for_loss[0].sum()\n",
        "\n",
        "                        # Charged residue recovery\n",
        "                        charged_positions = torch.zeros_like(S[0], dtype=torch.bool)\n",
        "                        for idx in [3, 4, 8, 11, 15]:  # D, E, H, K, R\n",
        "                            charged_positions |= (S[0] == idx)\n",
        "\n",
        "                        if charged_positions.sum() > 0:\n",
        "                            charged_recovery = torch.sum(\n",
        "                                F.one_hot(S[0], 21).float() * F.softmax(log_probs[0], dim=-1)\n",
        "                            ).sum(dim=-1) * charged_positions.float()\n",
        "                            charged_recovery = charged_recovery.sum() / charged_positions.sum()\n",
        "                        else:\n",
        "                            charged_recovery = torch.tensor(0.0)\n",
        "\n",
        "                    epoch_losses.append(total_loss.item())\n",
        "                    epoch_recoveries.append(seq_recovery.item())\n",
        "                    epoch_charged_recoveries.append(charged_recovery.item())\n",
        "\n",
        "                    if (protein_idx + 1) % 2 == 0:\n",
        "                        print(f\"  Protein {protein_idx+1}: Loss={total_loss.item():.4f}, \"\n",
        "                              f\"Recovery={seq_recovery.item():.3f}, \"\n",
        "                              f\"Charged={charged_recovery.item():.3f}\")\n",
        "\n",
        "                    break  # Only process first structure\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Failed on {pdb_code}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Epoch summary\n",
        "        if epoch_losses:\n",
        "            avg_loss = np.mean(epoch_losses)\n",
        "            avg_recovery = np.mean(epoch_recoveries)\n",
        "            avg_charged_recovery = np.mean(epoch_charged_recoveries)\n",
        "            structure_weight = torch.sigmoid(enhanced_model.structure_weight).item()\n",
        "            bias_weight = torch.sigmoid(enhanced_model.bias_weight).item()\n",
        "\n",
        "            training_history.append({\n",
        "                'epoch': epoch + 1,\n",
        "                'loss': avg_loss,\n",
        "                'recovery': avg_recovery,\n",
        "                'charged_recovery': avg_charged_recovery,\n",
        "                'structure_weight': structure_weight,\n",
        "                'bias_weight': bias_weight,\n",
        "                'proteins_processed': len(epoch_losses)\n",
        "            })\n",
        "\n",
        "            print(f\"📊 Epoch {epoch+1}: Loss={avg_loss:.4f}, \"\n",
        "                  f\"Recovery={avg_recovery:.3f}, \"\n",
        "                  f\"Charged={avg_charged_recovery:.3f}, \"\n",
        "                  f\"Weights=({structure_weight:.3f}, {bias_weight:.3f})\")\n",
        "        else:\n",
        "            print(f\"⚠️ Epoch {epoch+1}: No successful training examples\")\n",
        "\n",
        "    print(\"✅ Training completed!\")\n",
        "\n",
        "    # Put model back in eval mode\n",
        "    enhanced_model.eval()\n",
        "\n",
        "    # Plot training progress\n",
        "    if training_history:\n",
        "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "        epochs = [h['epoch'] for h in training_history]\n",
        "        losses = [h['loss'] for h in training_history]\n",
        "        recoveries = [h['recovery'] for h in training_history]\n",
        "        charged_recoveries = [h['charged_recovery'] for h in training_history]\n",
        "\n",
        "        ax1.plot(epochs, losses, 'b-', label='Loss')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.set_title('Training Loss')\n",
        "        ax1.grid(True)\n",
        "\n",
        "        ax2.plot(epochs, recoveries, 'g-', label='Overall Recovery')\n",
        "        ax2.plot(epochs, charged_recoveries, 'r-', label='Charged Recovery')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('Recovery Rate')\n",
        "        ax2.set_title('Recovery Rates')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        structure_weights = [h['structure_weight'] for h in training_history]\n",
        "        bias_weights = [h['bias_weight'] for h in training_history]\n",
        "\n",
        "        ax3.plot(epochs, structure_weights, 'purple', label='Structure Weight')\n",
        "        ax3.plot(epochs, bias_weights, 'orange', label='Bias Weight')\n",
        "        ax3.set_xlabel('Epoch')\n",
        "        ax3.set_ylabel('Weight')\n",
        "        ax3.set_title('Integration Weights')\n",
        "        ax3.legend()\n",
        "        ax3.grid(True)\n",
        "\n",
        "        proteins_processed = [h['proteins_processed'] for h in training_history]\n",
        "        ax4.bar(epochs, proteins_processed, alpha=0.7)\n",
        "        ax4.set_xlabel('Epoch')\n",
        "        ax4.set_ylabel('Proteins Processed')\n",
        "        ax4.set_title('Training Data per Epoch')\n",
        "        ax4.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return training_history\n",
        "\n",
        "#@title Cell 10: Comprehensive Benchmark Function\n",
        "def run_comprehensive_benchmark():\n",
        "    \"\"\"Run comprehensive benchmark comparing standard vs enhanced models\"\"\"\n",
        "\n",
        "    # Test proteins (benchmark set)\n",
        "    test_proteins = [\n",
        "        '3JAY', '3JB0', '5A1A', '5FTJ', '5FTK', '5K12', '5L35',\n",
        "        '5MDO', '5MF4', '5MFM', '5MH6', '5MHF', '5MIW', '5MJY',\n",
        "        '5MK1', '5MK3', '5MKM', '5MLD', '5MNS', '5MNV', '5MQZ',\n",
        "        '5MR0', '5MUX', '5MY0', '5MY2'\n",
        "    ]\n",
        "\n",
        "    # Design configurations\n",
        "    design_config = {\n",
        "        '3JAY': {'designed_chains': ['B'], 'fixed_chains': ['A', 'C', 'D', 'E']},\n",
        "        '3JB0': {'designed_chains': ['B'], 'fixed_chains': ['A', 'C', 'D', 'E']},\n",
        "        '5A1A': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "        '5FTJ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "        '5FTK': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "        '5K12': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "        '5L35': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G']},\n",
        "        '5MDO': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "        '5MF4': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "        '5MFM': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "        '5MH6': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "        '5MHF': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "        '5MIW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "        '5MJY': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "        '5MK1': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "        '5MK3': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "        '5MKM': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "        '5MLD': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "        '5MNS': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "        '5MNV': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']},\n",
        "        '5MQZ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "        '5MR0': {'designed_chains': ['F'], 'fixed_chains': ['A', 'B', 'C', 'D', 'E']},\n",
        "        '5MUX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "        '5MY0': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "        '5MY2': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']}\n",
        "    }\n",
        "\n",
        "    print(\"🧪 Running Comprehensive Enhanced ProteinMPNN Benchmark\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if enhanced_model is not None:\n",
        "        enhanced_model.eval()\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for i, pdb_code in enumerate(test_proteins):\n",
        "        print(f\"\\n🧬 Testing {pdb_code} ({i+1}/{len(test_proteins)})...\")\n",
        "\n",
        "        if pdb_code in design_config:\n",
        "            config = design_config[pdb_code]\n",
        "\n",
        "            try:\n",
        "                result = enhanced_process_protein(\n",
        "                    pdb_code,\n",
        "                    config['designed_chains'],\n",
        "                    config['fixed_chains'],\n",
        "                    num_sequences=4,\n",
        "                    temperature=0.1\n",
        "                )\n",
        "\n",
        "                if result is not None:\n",
        "                    results[pdb_code] = result\n",
        "\n",
        "                    # Quick summary\n",
        "                    std_recovery = np.mean(result['standard']['recovery_rates']) if result['standard']['recovery_rates'] else 0\n",
        "                    enh_recovery = np.mean(result['enhanced']['recovery_rates']) if 'enhanced' in result and result['enhanced']['recovery_rates'] else 0\n",
        "\n",
        "                    print(f\"   Standard: {std_recovery:.3f}\")\n",
        "                    print(f\"   Enhanced: {enh_recovery:.3f}\")\n",
        "                    print(f\"   Delta: {enh_recovery - std_recovery:+.3f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   ❌ Failed: {e}\")\n",
        "\n",
        "        if (i + 1) % 5 == 0:\n",
        "            print(f\"\\n📊 Progress: {i+1}/{len(test_proteins)} completed\")\n",
        "\n",
        "    # Comprehensive analysis\n",
        "    print(f\"\\n📈 COMPREHENSIVE BENCHMARK ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not results:\n",
        "        print(\"❌ No results to analyze\")\n",
        "        return None\n",
        "\n",
        "    # Collect all metrics\n",
        "    all_metrics = []\n",
        "\n",
        "    for pdb_code, result in results.items():\n",
        "        if (result['standard']['recovery_rates'] and\n",
        "            'enhanced' in result and result['enhanced']['recovery_rates']):\n",
        "\n",
        "            # Standard metrics\n",
        "            std_metrics = calculate_enhanced_metrics(\n",
        "                result['standard']['native_sequence'],\n",
        "                result['standard']['sequences'],\n",
        "                result['standard']['scores'],\n",
        "                \"Standard\"\n",
        "            )\n",
        "\n",
        "            # Enhanced metrics\n",
        "            enh_metrics = calculate_enhanced_metrics(\n",
        "                result['enhanced']['native_sequence'],\n",
        "                result['enhanced']['sequences'],\n",
        "                result['enhanced']['scores'],\n",
        "                \"Enhanced\"\n",
        "            )\n",
        "\n",
        "            # Add PDB code\n",
        "            std_metrics['pdb_code'] = pdb_code\n",
        "            enh_metrics['pdb_code'] = pdb_code\n",
        "\n",
        "            all_metrics.extend([std_metrics, enh_metrics])\n",
        "\n",
        "    if not all_metrics:\n",
        "        print(\"❌ No valid metrics to analyze\")\n",
        "        return None\n",
        "\n",
        "    # Combine all metrics\n",
        "    combined_df = pd.concat(all_metrics, ignore_index=True)\n",
        "\n",
        "    # Statistical analysis\n",
        "    std_data = combined_df[combined_df['model_type'] == 'Standard']\n",
        "    enh_data = combined_df[combined_df['model_type'] == 'Enhanced']\n",
        "\n",
        "    if len(std_data) > 0 and len(enh_data) > 0:\n",
        "        metrics_to_compare = ['sequence_recovery', 'charged_residue_recovery',\n",
        "                            'positive_recovery', 'negative_recovery', 'charge_conservation']\n",
        "\n",
        "        print(f\"📊 STATISTICAL COMPARISON:\")\n",
        "        print(f\"   Proteins analyzed: {len(std_data)}\")\n",
        "\n",
        "        for metric in metrics_to_compare:\n",
        "            if metric in std_data.columns and metric in enh_data.columns:\n",
        "                std_mean = std_data[metric].mean()\n",
        "                enh_mean = enh_data[metric].mean()\n",
        "                improvement = enh_mean - std_mean\n",
        "\n",
        "                print(f\"   {metric}:\")\n",
        "                print(f\"     Standard: {std_mean:.3f} ± {std_data[metric].std():.3f}\")\n",
        "                print(f\"     Enhanced: {enh_mean:.3f} ± {enh_data[metric].std():.3f}\")\n",
        "                print(f\"     Improvement: {improvement:+.3f}\")\n",
        "\n",
        "                # Statistical significance test\n",
        "                if len(std_data) >= 5 and len(enh_data) >= 5:\n",
        "                    from scipy.stats import ttest_ind\n",
        "                    try:\n",
        "                        t_stat, p_value = ttest_ind(enh_data[metric], std_data[metric])\n",
        "                        significance = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n",
        "                        print(f\"     Significance: p={p_value:.4f} {significance}\")\n",
        "                    except:\n",
        "                        pass\n",
        "                print()\n",
        "\n",
        "    # Create comprehensive visualization\n",
        "    create_comprehensive_visualization(results, combined_df)\n",
        "\n",
        "    return results, combined_df\n",
        "\n",
        "def create_comprehensive_visualization(results, combined_df):\n",
        "    \"\"\"Create comprehensive visualization of benchmark results\"\"\"\n",
        "\n",
        "    if not results or combined_df.empty:\n",
        "        return\n",
        "\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "    # 1. Recovery comparison\n",
        "    ax1 = plt.subplot(3, 3, 1)\n",
        "    pdb_codes = list(results.keys())\n",
        "    std_recoveries = []\n",
        "    enh_recoveries = []\n",
        "\n",
        "    for pdb_code in pdb_codes:\n",
        "        result = results[pdb_code]\n",
        "        if (result['standard']['recovery_rates'] and\n",
        "            'enhanced' in result and result['enhanced']['recovery_rates']):\n",
        "            std_recoveries.append(np.mean(result['standard']['recovery_rates']))\n",
        "            enh_recoveries.append(np.mean(result['enhanced']['recovery_rates']))\n",
        "        else:\n",
        "            std_recoveries.append(0)\n",
        "            enh_recoveries.append(0)\n",
        "\n",
        "    x_pos = np.arange(len(pdb_codes))\n",
        "    width = 0.35\n",
        "\n",
        "    ax1.bar(x_pos - width/2, std_recoveries, width, label='Standard', alpha=0.7, color='blue')\n",
        "    ax1.bar(x_pos + width/2, enh_recoveries, width, label='Enhanced', alpha=0.7, color='orange')\n",
        "    ax1.set_xlabel('Protein')\n",
        "    ax1.set_ylabel('Recovery Rate')\n",
        "    ax1.set_title('Overall Recovery Comparison')\n",
        "    ax1.legend()\n",
        "    ax1.set_xticks(x_pos[::2])  # Show every other label to avoid crowding\n",
        "    ax1.set_xticklabels([pdb_codes[i] for i in range(0, len(pdb_codes), 2)], rotation=45)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Improvement distribution\n",
        "    ax2 = plt.subplot(3, 3, 2)\n",
        "    improvements = [enh - std for enh, std in zip(enh_recoveries, std_recoveries)]\n",
        "    colors = ['green' if x > 0.01 else 'red' if x < -0.01 else 'gray' for x in improvements]\n",
        "\n",
        "    ax2.bar(range(len(improvements)), improvements, color=colors, alpha=0.7)\n",
        "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
        "    ax2.set_xlabel('Protein Index')\n",
        "    ax2.set_ylabel('Recovery Improvement')\n",
        "    ax2.set_title('Recovery Improvements')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. Charged residue recovery\n",
        "    ax3 = plt.subplot(3, 3, 3)\n",
        "    if 'charged_residue_recovery' in combined_df.columns:\n",
        "        std_charged = combined_df[combined_df['model_type'] == 'Standard']['charged_residue_recovery']\n",
        "        enh_charged = combined_df[combined_df['model_type'] == 'Enhanced']['charged_residue_recovery']\n",
        "\n",
        "        ax3.boxplot([std_charged, enh_charged], labels=['Standard', 'Enhanced'])\n",
        "        ax3.set_ylabel('Charged Residue Recovery (%)')\n",
        "        ax3.set_title('Charged Residue Recovery')\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. Score distribution\n",
        "    ax4 = plt.subplot(3, 3, 4)\n",
        "    if 'score' in combined_df.columns:\n",
        "        std_scores = combined_df[combined_df['model_type'] == 'Standard']['score']\n",
        "        enh_scores = combined_df[combined_df['model_type'] == 'Enhanced']['score']\n",
        "\n",
        "        ax4.hist(std_scores, alpha=0.5, label='Standard', bins=20, color='blue')\n",
        "        ax4.hist(enh_scores, alpha=0.5, label='Enhanced', bins=20, color='orange')\n",
        "        ax4.set_xlabel('Score')\n",
        "        ax4.set_ylabel('Frequency')\n",
        "        ax4.set_title('Score Distribution')\n",
        "        ax4.legend()\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "\n",
        "    # 5. Charge conservation\n",
        "    ax5 = plt.subplot(3, 3, 5)\n",
        "    if 'charge_conservation' in combined_df.columns:\n",
        "        std_charge_cons = combined_df[combined_df['model_type'] == 'Standard']['charge_conservation']\n",
        "        enh_charge_cons = combined_df[combined_df['model_type'] == 'Enhanced']['charge_conservation']\n",
        "\n",
        "        ax5.boxplot([std_charge_cons, enh_charge_cons], labels=['Standard', 'Enhanced'])\n",
        "        ax5.set_ylabel('Charge Conservation')\n",
        "        ax5.set_title('Charge Conservation')\n",
        "        ax5.grid(True, alpha=0.3)\n",
        "\n",
        "    # 6. Positive vs Negative recovery\n",
        "    ax6 = plt.subplot(3, 3, 6)\n",
        "    if 'positive_recovery' in combined_df.columns and 'negative_recovery' in combined_df.columns:\n",
        "        enh_data = combined_df[combined_df['model_type'] == 'Enhanced']\n",
        "        ax6.scatter(enh_data['positive_recovery'], enh_data['negative_recovery'],\n",
        "                   alpha=0.7, color='orange', label='Enhanced')\n",
        "\n",
        "        std_data = combined_df[combined_df['model_type'] == 'Standard']\n",
        "        ax6.scatter(std_data['positive_recovery'], std_data['negative_recovery'],\n",
        "                   alpha=0.7, color='blue', label='Standard')\n",
        "\n",
        "        ax6.set_xlabel('Positive Residue Recovery (%)')\n",
        "        ax6.set_ylabel('Negative Residue Recovery (%)')\n",
        "        ax6.set_title('Positive vs Negative Recovery')\n",
        "        ax6.legend()\n",
        "        ax6.grid(True, alpha=0.3)\n",
        "\n",
        "    # 7. Overall improvement histogram\n",
        "    ax7 = plt.subplot(3, 3, 7)\n",
        "    ax7.hist(improvements, bins=15, alpha=0.7, color='purple', edgecolor='black')\n",
        "    ax7.axvline(x=0, color='red', linestyle='--', alpha=0.7, label='No improvement')\n",
        "    ax7.axvline(x=np.mean(improvements), color='green', linestyle='--', alpha=0.7,\n",
        "               label=f'Mean: {np.mean(improvements):.3f}')\n",
        "    ax7.set_xlabel('Recovery Improvement')\n",
        "    ax7.set_ylabel('Frequency')\n",
        "    ax7.set_title('Improvement Distribution')\n",
        "    ax7.legend()\n",
        "    ax7.grid(True, alpha=0.3)\n",
        "\n",
        "    # 8. Recovery vs Score correlation\n",
        "    ax8 = plt.subplot(3, 3, 8)\n",
        "    if 'score' in combined_df.columns:\n",
        "        enh_data = combined_df[combined_df['model_type'] == 'Enhanced']\n",
        "        std_data = combined_df[combined_df['model_type'] == 'Standard']\n",
        "\n",
        "        ax8.scatter(enh_data['score'], enh_data['sequence_recovery'],\n",
        "                   alpha=0.7, color='orange', label='Enhanced')\n",
        "        ax8.scatter(std_data['score'], std_data['sequence_recovery'],\n",
        "                   alpha=0.7, color='blue', label='Standard')\n",
        "\n",
        "        ax8.set_xlabel('Score')\n",
        "        ax8.set_ylabel('Recovery Rate')\n",
        "        ax8.set_title('Recovery vs Score')\n",
        "        ax8.legend()\n",
        "        ax8.grid(True, alpha=0.3)\n",
        "\n",
        "    # 9. Summary statistics\n",
        "    ax9 = plt.subplot(3, 3, 9)\n",
        "    ax9.axis('off')\n",
        "\n",
        "    # Calculate summary statistics\n",
        "    improved = sum(1 for x in improvements if x > 0.01)\n",
        "    worsened = sum(1 for x in improvements if x < -0.01)\n",
        "    neutral = len(improvements) - improved - worsened\n",
        "\n",
        "    summary_text = f\"\"\"\n",
        "BENCHMARK SUMMARY\n",
        "================\n",
        "Proteins tested: {len(results)}\n",
        "Mean improvement: {np.mean(improvements):.3f}\n",
        "Std improvement: {np.std(improvements):.3f}\n",
        "\n",
        "Performance breakdown:\n",
        "• Improved: {improved}/{len(improvements)} ({improved/len(improvements)*100:.1f}%)\n",
        "• Neutral: {neutral}/{len(improvements)} ({neutral/len(improvements)*100:.1f}%)\n",
        "• Worsened: {worsened}/{len(improvements)} ({worsened/len(improvements)*100:.1f}%)\n",
        "\n",
        "Best improvement: {max(improvements):.3f}\n",
        "Worst change: {min(improvements):.3f}\n",
        "\"\"\"\n",
        "\n",
        "    ax9.text(0.1, 0.9, summary_text, transform=ax9.transAxes, fontsize=12,\n",
        "            verticalalignment='top', fontfamily='monospace')\n",
        "\n",
        "    plt.suptitle('Enhanced ProteinMPNN v2: Comprehensive Benchmark Results', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "print(\"✅ Enhanced ProteinMPNN v2 Complete!\")\n",
        "print(\"\\nTo use:\")\n",
        "print(\"1. training_history = train_enhanced_model(num_epochs=20)\")\n",
        "print(\"2. results, metrics = run_comprehensive_benchmark()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "vG-Gx59G7c-p",
        "outputId": "ce768207-5f41-44b5-f246-f59daf823df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Installed biopython\n",
            "✅ Installed matplotlib\n",
            "✅ Installed pandas\n",
            "✅ Installed scipy\n",
            "✅ Installed scikit-learn\n",
            "✅ Bio/PDB imports successful\n",
            "✅ All libraries imported successfully!\n",
            "Using device: cuda:0\n",
            "🔥 Loading ProteinMPNN checkpoint...\n",
            "Number of edges: 48\n",
            "✅ Standard ProteinMPNN loaded!\n",
            "✅ Structurally Enhanced ProteinMPNN initialized\n",
            "✅ Enhanced ProteinMPNN v2 loaded!\n",
            "✅ Enhanced ProteinMPNN v2 Complete!\n",
            "\n",
            "To use:\n",
            "1. training_history = train_enhanced_model(num_epochs=20)\n",
            "2. results, metrics = run_comprehensive_benchmark()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Electrostatic Loss function Integration - Insignificant improvement"
      ],
      "metadata": {
        "id": "IMKpwpxp_Mdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Integration"
      ],
      "metadata": {
        "id": "eviAKF7o5f98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Enhanced ProteinMPNN with ESM-2 and APBS Integration\n",
        "Final Implementation with Electrostatic Loss and Perplexity\n",
        "\"\"\"\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def install_dependencies():\n",
        "    \"\"\"Install required packages\"\"\"\n",
        "    packages = ['biopython', 'matplotlib', 'pandas', 'scipy', 'fair-esm', 'tqdm']\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "            print(f\"✅ Installed {package}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Failed to install {package}: {e}\")\n",
        "\n",
        "    # Install APBS\n",
        "    try:\n",
        "        subprocess.check_call(['apt-get', 'update', '-qq'])\n",
        "        subprocess.check_call(['apt-get', 'install', '-y', '-qq', 'apbs'])\n",
        "        print(\"✅ APBS installed\")\n",
        "    except:\n",
        "        print(\"⚠️ APBS install failed, using fallback\")\n",
        "\n",
        "install_dependencies()\n",
        "\n",
        "# Clone ProteinMPNN if needed\n",
        "if not os.path.isdir(\"ProteinMPNN\"):\n",
        "    os.system(\"git clone -q https://github.com/dauparas/ProteinMPNN.git\")\n",
        "sys.path.append('/content/ProteinMPNN')\n",
        "\n",
        "import json, time, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import copy\n",
        "from scipy import stats\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "\n",
        "# Bio imports\n",
        "try:\n",
        "    from Bio import PDB\n",
        "    from Bio.PDB import PDBParser\n",
        "    from scipy.spatial.distance import cdist\n",
        "    BIO_AVAILABLE = True\n",
        "except:\n",
        "    BIO_AVAILABLE = False\n",
        "\n",
        "# ESM imports\n",
        "try:\n",
        "    import esm\n",
        "    ESM_AVAILABLE = True\n",
        "except:\n",
        "    ESM_AVAILABLE = False\n",
        "\n",
        "# ProteinMPNN imports\n",
        "from protein_mpnn_utils import (\n",
        "    loss_nll, loss_smoothed, gather_edges, gather_nodes,\n",
        "    gather_nodes_t, cat_neighbors_nodes, _scores, _S_to_seq,\n",
        "    tied_featurize, parse_PDB, StructureDataset,\n",
        "    StructureDatasetPDB, ProteinMPNN\n",
        ")\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ============================================================================\n",
        "# APBS Electrostatic Handler\n",
        "# ============================================================================\n",
        "\n",
        "class APBSElectrostaticHandler:\n",
        "    \"\"\"GPU-optimized APBS electrostatic calculations\"\"\"\n",
        "\n",
        "    def __init__(self, device='cuda'):\n",
        "        self.device = torch.device(device)\n",
        "        self.electrostatic_cache = {}\n",
        "        self.charge_map = {\n",
        "            'ARG': 1.0, 'LYS': 1.0, 'HIS': 0.5,  # Positive\n",
        "            'ASP': -1.0, 'GLU': -1.0,              # Negative\n",
        "            'SER': 0, 'THR': 0, 'ASN': 0, 'GLN': 0,  # Polar neutral\n",
        "            'CYS': 0, 'TYR': 0, 'TRP': 0,         # Special\n",
        "            'ALA': 0, 'VAL': 0, 'ILE': 0, 'LEU': 0, 'MET': 0,  # Hydrophobic\n",
        "            'PHE': 0, 'PRO': 0, 'GLY': 0          # Others\n",
        "        }\n",
        "\n",
        "    def calculate_electrostatics_gpu(self, positions, charges):\n",
        "        \"\"\"GPU-accelerated electrostatic calculation\"\"\"\n",
        "        positions = positions.to(self.device).float()\n",
        "        charges = charges.to(self.device).float()\n",
        "\n",
        "        # Compute pairwise distances on GPU\n",
        "        distances = torch.cdist(positions, positions, p=2)\n",
        "        distances = distances + torch.eye(len(positions), device=self.device) * 1e-6  # Avoid division by zero\n",
        "\n",
        "        # Calculate potentials (Coulomb's law)\n",
        "        potentials = torch.sum(charges.unsqueeze(0) / (distances + 1e-6), dim=1)\n",
        "\n",
        "        # Normalize\n",
        "        if potentials.std() > 1e-8:\n",
        "            potentials = (potentials - potentials.mean()) / potentials.std()\n",
        "\n",
        "        return potentials\n",
        "\n",
        "    def get_electrostatic_features(self, pdb_path, chain_ids, seq_len):\n",
        "        \"\"\"Extract comprehensive electrostatic features\"\"\"\n",
        "        cache_key = f\"{pdb_path}_{'-'.join(sorted(chain_ids))}\"\n",
        "\n",
        "        if cache_key in self.electrostatic_cache:\n",
        "            return self.electrostatic_cache[cache_key]\n",
        "\n",
        "        if not BIO_AVAILABLE:\n",
        "            return torch.zeros(seq_len, 8, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        try:\n",
        "            parser = PDBParser(QUIET=True)\n",
        "            structure = parser.get_structure('protein', pdb_path)\n",
        "\n",
        "            positions = []\n",
        "            charges = []\n",
        "            residue_info = []\n",
        "\n",
        "            for model in structure:\n",
        "                for chain in model:\n",
        "                    if chain.id in chain_ids:\n",
        "                        for residue in chain:\n",
        "                            if residue.get_id()[0] == ' ':  # Standard residue\n",
        "                                resname = residue.get_resname()\n",
        "                                charge = self.charge_map.get(resname, 0)\n",
        "\n",
        "                                if 'CA' in residue:\n",
        "                                    ca_pos = residue['CA'].get_coord()\n",
        "                                    positions.append(ca_pos)\n",
        "                                    charges.append(charge)\n",
        "                                    residue_info.append({\n",
        "                                        'chain': chain.id,\n",
        "                                        'resnum': residue.get_id()[1],\n",
        "                                        'resname': resname,\n",
        "                                        'charge': charge\n",
        "                                    })\n",
        "\n",
        "            if not positions:\n",
        "                return torch.zeros(seq_len, 8, device=self.device, dtype=torch.float32)\n",
        "\n",
        "            positions = torch.tensor(positions, dtype=torch.float32)\n",
        "            charges = torch.tensor(charges, dtype=torch.float32)\n",
        "\n",
        "            # Calculate electrostatic potential\n",
        "            potentials = self.calculate_electrostatics_gpu(positions, charges)\n",
        "\n",
        "            # Calculate comprehensive features\n",
        "            features = []\n",
        "            for i in range(len(positions)):\n",
        "                # Local environment features\n",
        "                local_mask = torch.norm(positions - positions[i], dim=1) < 10.0\n",
        "                local_charges = charges[local_mask]\n",
        "\n",
        "                # Feature calculations\n",
        "                potential = potentials[i].item()\n",
        "                charge = charges[i].item()\n",
        "                local_charge_density = torch.sum(torch.abs(local_charges)).item()\n",
        "                local_net_charge = torch.sum(local_charges).item()\n",
        "\n",
        "                # Distance to nearest opposite charge\n",
        "                if charge != 0:\n",
        "                    opposite_mask = charges * charge < 0\n",
        "                    if opposite_mask.any():\n",
        "                        opposite_dists = torch.norm(positions[opposite_mask] - positions[i], dim=1)\n",
        "                        min_opposite_dist = opposite_dists.min().item()\n",
        "                    else:\n",
        "                        min_opposite_dist = 50.0\n",
        "                else:\n",
        "                    charged_mask = torch.abs(charges) > 0\n",
        "                    if charged_mask.any():\n",
        "                        charged_dists = torch.norm(positions[charged_mask] - positions[i], dim=1)\n",
        "                        min_opposite_dist = charged_dists.min().item()\n",
        "                    else:\n",
        "                        min_opposite_dist = 50.0\n",
        "\n",
        "                # Electrostatic interaction strength\n",
        "                interaction_strength = potential * charge if charge != 0 else potential\n",
        "\n",
        "                # Local charge diversity\n",
        "                charge_std = torch.std(local_charges).item() if len(local_charges) > 1 else 0\n",
        "\n",
        "                # Hydrophobic vs charged environment ratio\n",
        "                hydrophobic_mask = torch.eq(charges[local_mask], 0)\n",
        "                hydrophobic_ratio = hydrophobic_mask.sum().item() / len(local_charges) if len(local_charges) > 0 else 0\n",
        "\n",
        "                feat = torch.tensor([\n",
        "                    potential,              # Electrostatic potential\n",
        "                    charge,                 # Residue charge\n",
        "                    local_charge_density,   # Local charge density\n",
        "                    min_opposite_dist,      # Distance to opposite charge\n",
        "                    interaction_strength,   # Electrostatic interaction\n",
        "                    local_net_charge,       # Net charge in neighborhood\n",
        "                    charge_std,             # Charge diversity\n",
        "                    hydrophobic_ratio       # Hydrophobic environment\n",
        "                ], dtype=torch.float32)\n",
        "                features.append(feat)\n",
        "\n",
        "            features = torch.stack(features).to(self.device)\n",
        "\n",
        "            # Normalize features\n",
        "            for i in range(features.shape[1]):\n",
        "                col_data = features[:, i]\n",
        "                if col_data.std() > 1e-8:\n",
        "                    features[:, i] = (col_data - col_data.mean()) / col_data.std()\n",
        "\n",
        "            # Pad/truncate to sequence length\n",
        "            if len(features) < seq_len:\n",
        "                padding = torch.zeros(seq_len - len(features), 8, device=self.device, dtype=torch.float32)\n",
        "                features = torch.cat([features, padding], dim=0)\n",
        "            elif len(features) > seq_len:\n",
        "                features = features[:seq_len]\n",
        "\n",
        "            self.electrostatic_cache[cache_key] = features\n",
        "            return features\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Electrostatic calculation failed: {e}\")\n",
        "            return torch.zeros(seq_len, 8, device=self.device, dtype=torch.float32)\n",
        "\n",
        "# ============================================================================\n",
        "# ESM-2 Handler\n",
        "# ============================================================================\n",
        "\n",
        "class ESM2Handler:\n",
        "    \"\"\"Optimized ESM-2 handler\"\"\"\n",
        "\n",
        "    def __init__(self, device='cuda'):\n",
        "        self.device = torch.device(device)\n",
        "        self.model = None\n",
        "        self.alphabet = None\n",
        "        self.available = False\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load ESM-2 model\"\"\"\n",
        "        if not ESM_AVAILABLE:\n",
        "            print(\"⚠️ ESM-2 not available\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            print(\"Loading ESM-2 model...\")\n",
        "            self.model, self.alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "            self.model = self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "\n",
        "            # Test the model\n",
        "            test_seq = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "            tokens = self.alphabet.encode(test_seq)\n",
        "            batch_tokens = torch.tensor([tokens]).to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                results = self.model(batch_tokens, repr_layers=[33])\n",
        "                embeddings = results[\"representations\"][33]\n",
        "\n",
        "            self.available = True\n",
        "            print(\"✅ ESM-2 loaded successfully!\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ ESM-2 loading failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_embeddings_batch(self, sequences):\n",
        "        \"\"\"Get ESM-2 embeddings for sequences\"\"\"\n",
        "        if not self.available:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            embeddings = []\n",
        "            amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "\n",
        "            for seq in sequences:\n",
        "                # Convert sequence indices to amino acids if needed\n",
        "                if isinstance(seq, torch.Tensor):\n",
        "                    seq_str = ''.join([amino_acids[i] if 0 <= i < 20 else 'X' for i in seq.cpu().numpy()])\n",
        "                else:\n",
        "                    seq_str = seq\n",
        "\n",
        "                # Truncate if too long\n",
        "                if len(seq_str) > 1000:\n",
        "                    seq_str = seq_str[:1000]\n",
        "\n",
        "                # Get embeddings\n",
        "                tokens = self.alphabet.encode(seq_str)\n",
        "                batch_tokens = torch.tensor([tokens]).to(self.device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    results = self.model(batch_tokens, repr_layers=[33])\n",
        "                    emb = results[\"representations\"][33][0, 1:-1, :]  # Remove special tokens\n",
        "                    embeddings.append(emb)\n",
        "\n",
        "            return embeddings\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ ESM-2 embedding failed: {e}\")\n",
        "            return None\n",
        "\n",
        "# ============================================================================\n",
        "# Enhanced Attention and Fusion Layers\n",
        "# ============================================================================\n",
        "\n",
        "class ElectrostaticAttention(nn.Module):\n",
        "    \"\"\"Electrostatic-guided multi-head attention\"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=1288, num_heads=8, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = feature_dim // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(feature_dim, feature_dim * 3)\n",
        "        self.electrostatic_gate = nn.Sequential(\n",
        "            nn.Linear(8, num_heads),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.out_proj = nn.Linear(feature_dim, feature_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, electrostatic_features):\n",
        "        B, N, C = x.shape\n",
        "\n",
        "        # Generate Q, K, V\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        # Attention scores\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "\n",
        "        # Apply electrostatic gating\n",
        "        elec_gates = self.electrostatic_gate(electrostatic_features)\n",
        "        elec_gates = elec_gates.unsqueeze(2).expand(-1, -1, N, -1)\n",
        "        attn = attn + elec_gates.permute(0, 3, 1, 2) * 0.1  # Small influence\n",
        "\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        # Apply attention\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.out_proj(x)\n",
        "\n",
        "        return x, attn\n",
        "\n",
        "class EnhancedFusionLayer(nn.Module):\n",
        "    \"\"\"Advanced fusion with learned weighting\"\"\"\n",
        "\n",
        "    def __init__(self, esm2_dim=1280, electrostatic_dim=8, hidden_dim=128):\n",
        "        super().__init__()\n",
        "\n",
        "        self.esm2_proj = nn.Linear(esm2_dim, hidden_dim)\n",
        "        self.elec_proj = nn.Linear(electrostatic_dim, hidden_dim // 4)\n",
        "\n",
        "        self.fusion_attention = ElectrostaticAttention(\n",
        "            feature_dim=hidden_dim + hidden_dim // 4,\n",
        "            num_heads=4\n",
        "        )\n",
        "\n",
        "        self.output_proj = nn.Sequential(\n",
        "            nn.Linear(hidden_dim + hidden_dim // 4, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "\n",
        "        # Learnable fusion weights\n",
        "        self.esm2_weight = nn.Parameter(torch.tensor(0.7))\n",
        "        self.elec_weight = nn.Parameter(torch.tensor(0.3))\n",
        "\n",
        "    def forward(self, esm2_features, electrostatic_features):\n",
        "        # Project features\n",
        "        esm2_proj = self.esm2_proj(esm2_features)\n",
        "        elec_proj = self.elec_proj(electrostatic_features)\n",
        "\n",
        "        # Concatenate\n",
        "        combined = torch.cat([esm2_proj, elec_proj], dim=-1)\n",
        "\n",
        "        # Apply attention fusion\n",
        "        fused, attn_weights = self.fusion_attention(combined, electrostatic_features)\n",
        "\n",
        "        # Output projection\n",
        "        output = self.output_proj(fused)\n",
        "\n",
        "        # Weighted combination\n",
        "        w_esm2 = torch.sigmoid(self.esm2_weight)\n",
        "        w_elec = torch.sigmoid(self.elec_weight)\n",
        "        total_weight = w_esm2 + w_elec\n",
        "        w_esm2 = w_esm2 / total_weight\n",
        "        w_elec = w_elec / total_weight\n",
        "\n",
        "        output = w_esm2 * esm2_proj + w_elec * output\n",
        "\n",
        "        return output\n",
        "\n",
        "# ============================================================================\n",
        "# Electrostatic Loss Function\n",
        "# ============================================================================\n",
        "\n",
        "class ElectrostaticAwareLoss(nn.Module):\n",
        "    \"\"\"Electrostatic-aware loss function\"\"\"\n",
        "\n",
        "    def __init__(self, alpha=0.2, beta=0.15, gamma=0.1):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha  # Electrostatic correlation weight\n",
        "        self.beta = beta    # Charge placement weight\n",
        "        self.gamma = gamma  # Charge conservation weight\n",
        "\n",
        "    def forward(self, log_probs, targets, mask, electrostatic_features=None):\n",
        "        \"\"\"\n",
        "        Enhanced loss with electrostatic awareness\n",
        "\n",
        "        Args:\n",
        "            log_probs: Model predictions [batch, seq_len, vocab_size]\n",
        "            targets: Ground truth sequences [batch, seq_len]\n",
        "            mask: Sequence mask [batch, seq_len]\n",
        "            electrostatic_features: Electrostatic features [batch, seq_len, 8]\n",
        "        \"\"\"\n",
        "        # Standard cross-entropy loss\n",
        "        ce_loss = F.nll_loss(\n",
        "            log_probs.view(-1, log_probs.size(-1)),\n",
        "            targets.view(-1),\n",
        "            reduction='none'\n",
        "        )\n",
        "        ce_loss = ce_loss.view(targets.shape)\n",
        "        ce_loss = (ce_loss * mask).sum() / (mask.sum() + 1e-8)\n",
        "\n",
        "        loss_dict = {'ce_loss': ce_loss.item()}\n",
        "\n",
        "        if electrostatic_features is not None:\n",
        "            batch_size, seq_len = targets.shape\n",
        "\n",
        "            # Amino acid indices (ProteinMPNN alphabet)\n",
        "            charged_aa_indices = torch.tensor([3, 4, 11, 15], device=log_probs.device)  # D, E, K, R\n",
        "            negative_aa_indices = torch.tensor([3, 4], device=log_probs.device)  # D, E\n",
        "            positive_aa_indices = torch.tensor([11, 15], device=log_probs.device)  # K, R\n",
        "\n",
        "            # Get probabilities for charged amino acids\n",
        "            charged_probs = torch.exp(log_probs[:, :, charged_aa_indices]).sum(dim=-1)\n",
        "            neg_probs = torch.exp(log_probs[:, :, negative_aa_indices]).sum(dim=-1)\n",
        "            pos_probs = torch.exp(log_probs[:, :, positive_aa_indices]).sum(dim=-1)\n",
        "\n",
        "            # Electrostatic features\n",
        "            potential = electrostatic_features[:, :, 0]  # Electrostatic potential\n",
        "            charge = electrostatic_features[:, :, 1]     # Current charge\n",
        "            local_charge_density = electrostatic_features[:, :, 2]  # Local charge density\n",
        "\n",
        "            # Loss 1: Charged residues should correlate with potential magnitude\n",
        "            potential_magnitude = torch.abs(potential)\n",
        "            target_charged_prob = torch.sigmoid(potential_magnitude * 2)  # Scale potential\n",
        "            elec_correlation_loss = F.mse_loss(\n",
        "                charged_probs * mask,\n",
        "                target_charged_prob * mask\n",
        "            )\n",
        "\n",
        "            # Loss 2: Encourage opposite charges at high potential sites\n",
        "            pos_potential_mask = (potential > 0.5) * mask\n",
        "            neg_potential_mask = (potential < -0.5) * mask\n",
        "\n",
        "            charge_placement_loss = torch.tensor(0.0, device=log_probs.device)\n",
        "            if pos_potential_mask.sum() > 0:\n",
        "                charge_placement_loss += F.mse_loss(\n",
        "                    neg_probs * pos_potential_mask,\n",
        "                    pos_potential_mask.float()\n",
        "                ) * 0.5\n",
        "\n",
        "            if neg_potential_mask.sum() > 0:\n",
        "                charge_placement_loss += F.mse_loss(\n",
        "                    pos_probs * neg_potential_mask,\n",
        "                    neg_potential_mask.float()\n",
        "                ) * 0.5\n",
        "\n",
        "            # Loss 3: Charge conservation - maintain local electroneutrality\n",
        "            charge_conservation_loss = torch.tensor(0.0, device=log_probs.device)\n",
        "            for b in range(batch_size):\n",
        "                # Calculate predicted net charge\n",
        "                pred_charges = (\n",
        "                    pos_probs[b] * 1.0 +  # Positive charges\n",
        "                    neg_probs[b] * (-1.0)  # Negative charges\n",
        "                )\n",
        "\n",
        "                # Target: balanced charge distribution\n",
        "                ideal_charge = torch.zeros_like(pred_charges)\n",
        "                charge_conservation_loss += F.mse_loss(\n",
        "                    pred_charges * mask[b],\n",
        "                    ideal_charge * mask[b]\n",
        "                ) / batch_size\n",
        "\n",
        "            # Total loss\n",
        "            total_loss = (ce_loss +\n",
        "                         self.alpha * elec_correlation_loss +\n",
        "                         self.beta * charge_placement_loss +\n",
        "                         self.gamma * charge_conservation_loss)\n",
        "\n",
        "            loss_dict.update({\n",
        "                'elec_correlation': elec_correlation_loss.item(),\n",
        "                'charge_placement': charge_placement_loss.item(),\n",
        "                'charge_conservation': charge_conservation_loss.item()\n",
        "            })\n",
        "\n",
        "            return total_loss, loss_dict\n",
        "\n",
        "        return ce_loss, loss_dict\n",
        "\n",
        "# ============================================================================\n",
        "# Perplexity Calculator\n",
        "# ============================================================================\n",
        "\n",
        "class PerplexityCalculator:\n",
        "    \"\"\"Calculate perplexity scores for sequences\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_perplexity(log_probs, targets, mask):\n",
        "        \"\"\"\n",
        "        Calculate perplexity from log probabilities\n",
        "\n",
        "        Args:\n",
        "            log_probs: Log probabilities [batch, seq_len, vocab_size]\n",
        "            targets: Target sequences [batch, seq_len]\n",
        "            mask: Sequence mask [batch, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            perplexity: Average perplexity score\n",
        "        \"\"\"\n",
        "        # Get log probabilities of actual targets\n",
        "        target_log_probs = torch.gather(log_probs, -1, targets.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        # Apply mask and calculate average\n",
        "        masked_log_probs = target_log_probs * mask\n",
        "        avg_log_prob = masked_log_probs.sum() / (mask.sum() + 1e-8)\n",
        "\n",
        "        # Calculate perplexity\n",
        "        perplexity = torch.exp(-avg_log_prob)\n",
        "\n",
        "        return perplexity.item()\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_conditional_perplexity(log_probs, targets, mask, electrostatic_features):\n",
        "        \"\"\"\n",
        "        Calculate perplexity conditioned on electrostatic environment\n",
        "\n",
        "        Returns perplexity for charged vs uncharged positions\n",
        "        \"\"\"\n",
        "        # Get target log probabilities\n",
        "        target_log_probs = torch.gather(log_probs, -1, targets.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        # Separate charged and uncharged positions\n",
        "        charge = electrostatic_features[:, :, 1]\n",
        "        charged_mask = (torch.abs(charge) > 0.1) * mask\n",
        "        uncharged_mask = (torch.abs(charge) <= 0.1) * mask\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        # Charged positions perplexity\n",
        "        if charged_mask.sum() > 0:\n",
        "            charged_log_probs = target_log_probs * charged_mask\n",
        "            avg_charged_log_prob = charged_log_probs.sum() / (charged_mask.sum() + 1e-8)\n",
        "            results['charged_perplexity'] = torch.exp(-avg_charged_log_prob).item()\n",
        "        else:\n",
        "            results['charged_perplexity'] = float('nan')\n",
        "\n",
        "        # Uncharged positions perplexity\n",
        "        if uncharged_mask.sum() > 0:\n",
        "            uncharged_log_probs = target_log_probs * uncharged_mask\n",
        "            avg_uncharged_log_prob = uncharged_log_probs.sum() / (uncharged_mask.sum() + 1e-8)\n",
        "            results['uncharged_perplexity'] = torch.exp(-avg_uncharged_log_prob).item()\n",
        "        else:\n",
        "            results['uncharged_perplexity'] = float('nan')\n",
        "\n",
        "        return results\n",
        "\n",
        "# ============================================================================\n",
        "# Enhanced ProteinMPNN\n",
        "# ============================================================================\n",
        "\n",
        "class EnhancedProteinMPNN(ProteinMPNN):\n",
        "    \"\"\"Enhanced ProteinMPNN with ESM-2 and APBS integration\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 esm2_handler,\n",
        "                 apbs_handler,\n",
        "                 num_letters=21,\n",
        "                 node_features=128,\n",
        "                 edge_features=128,\n",
        "                 hidden_dim=128,\n",
        "                 num_encoder_layers=3,\n",
        "                 num_decoder_layers=3,\n",
        "                 k_neighbors=30,\n",
        "                 augment_eps=0.0,\n",
        "                 device='cuda'):\n",
        "\n",
        "        super().__init__(\n",
        "            num_letters=num_letters,\n",
        "            node_features=node_features,\n",
        "            edge_features=edge_features,\n",
        "            hidden_dim=hidden_dim,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            augment_eps=augment_eps,\n",
        "            k_neighbors=k_neighbors\n",
        "        )\n",
        "\n",
        "        self.esm2_handler = esm2_handler\n",
        "        self.apbs_handler = apbs_handler\n",
        "        self.device = torch.device(device)\n",
        "\n",
        "        # Enhanced components\n",
        "        self.fusion_layer = EnhancedFusionLayer(\n",
        "            esm2_dim=1280,\n",
        "            electrostatic_dim=8,\n",
        "            hidden_dim=hidden_dim\n",
        "        ).to(device)\n",
        "\n",
        "        # Electrostatic-aware output layer\n",
        "        self.electrostatic_out = nn.Sequential(\n",
        "            nn.Linear(hidden_dim + 8, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, num_letters)\n",
        "        ).to(device)\n",
        "\n",
        "        # Integration weights\n",
        "        self.esm2_integration = nn.Parameter(torch.tensor(0.3))\n",
        "        self.elec_integration = nn.Parameter(torch.tensor(0.2))\n",
        "\n",
        "        # Structure context\n",
        "        self.pdb_path = None\n",
        "        self.chain_ids = []\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    def set_structure_context(self, pdb_path, chain_ids):\n",
        "        \"\"\"Set structure context for processing\"\"\"\n",
        "        self.pdb_path = pdb_path\n",
        "        self.chain_ids = chain_ids\n",
        "\n",
        "    def get_enhanced_features(self, sequences, seq_len):\n",
        "        \"\"\"Get ESM-2 and APBS features\"\"\"\n",
        "        esm2_embeddings = None\n",
        "        electrostatic_features = None\n",
        "\n",
        "        # Get ESM-2 embeddings\n",
        "        if self.esm2_handler.available and sequences is not None:\n",
        "            try:\n",
        "                embeddings_list = self.esm2_handler.get_embeddings_batch(sequences)\n",
        "                if embeddings_list:\n",
        "                    # Pad embeddings to sequence length\n",
        "                    padded_embeddings = []\n",
        "                    for emb in embeddings_list:\n",
        "                        if emb.shape[0] < seq_len:\n",
        "                            padding = torch.zeros(seq_len - emb.shape[0], 1280,\n",
        "                                                device=self.device, dtype=torch.float32)\n",
        "                            emb = torch.cat([emb, padding], dim=0)\n",
        "                        elif emb.shape[0] > seq_len:\n",
        "                            emb = emb[:seq_len]\n",
        "                        padded_embeddings.append(emb)\n",
        "                    esm2_embeddings = torch.stack(padded_embeddings)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ ESM-2 embedding failed: {e}\")\n",
        "\n",
        "        # Get electrostatic features\n",
        "        if self.pdb_path and self.chain_ids:\n",
        "            try:\n",
        "                electrostatic_features = self.apbs_handler.get_electrostatic_features(\n",
        "                    self.pdb_path, self.chain_ids, seq_len\n",
        "                )\n",
        "                # Expand for batch\n",
        "                if esm2_embeddings is not None:\n",
        "                    batch_size = esm2_embeddings.shape[0]\n",
        "                    electrostatic_features = electrostatic_features.unsqueeze(0).expand(batch_size, -1, -1)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Electrostatic features failed: {e}\")\n",
        "\n",
        "        return esm2_embeddings, electrostatic_features\n",
        "\n",
        "    def forward_enhanced(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn,\n",
        "                        use_input_decoding_order=False, decoding_order=None, return_features=False):\n",
        "        \"\"\"Enhanced forward pass with robust dtype handling\"\"\"\n",
        "\n",
        "        # CRITICAL: Ensure ALL index tensors are int64 before ANY operations\n",
        "        device = X.device\n",
        "\n",
        "        # Convert all index tensors\n",
        "        residue_idx = residue_idx.long()\n",
        "        S = S.long()\n",
        "        if isinstance(chain_encoding_all, torch.Tensor):\n",
        "            chain_encoding_all = chain_encoding_all.long()\n",
        "        if decoding_order is not None:\n",
        "            decoding_order = decoding_order.long()\n",
        "\n",
        "        # Ensure float tensors\n",
        "        X = X.float()\n",
        "        mask = mask.float()\n",
        "        chain_M = chain_M.float()\n",
        "\n",
        "        batch_size, seq_len = S.shape\n",
        "\n",
        "        try:\n",
        "            # Use standard ProteinMPNN forward but with enhanced features integration\n",
        "            # This avoids custom tensor operations that might have dtype issues\n",
        "\n",
        "            # Get standard ProteinMPNN output first\n",
        "            with torch.no_grad():\n",
        "                standard_log_probs = super(EnhancedProteinMPNN, self).forward(\n",
        "                    X, S, mask, chain_M, residue_idx, chain_encoding_all, randn,\n",
        "                    use_input_decoding_order, decoding_order\n",
        "                )\n",
        "\n",
        "            # Get enhanced features for post-processing\n",
        "            if self.pdb_path and self.chain_ids:\n",
        "                try:\n",
        "                    electrostatic_features = self.apbs_handler.get_electrostatic_features(\n",
        "                        self.pdb_path, self.chain_ids, seq_len\n",
        "                    )\n",
        "                    if electrostatic_features.dim() == 2:\n",
        "                        electrostatic_features = electrostatic_features.unsqueeze(0).expand(batch_size, -1, -1)\n",
        "\n",
        "                    # Simple electrostatic bias (safe approach)\n",
        "                    potential = electrostatic_features[:, :, 0]  # First feature is potential\n",
        "                    charge = electrostatic_features[:, :, 1]     # Second feature is charge\n",
        "\n",
        "                    # Create amino acid bias based on electrostatic environment\n",
        "                    aa_bias = torch.zeros_like(standard_log_probs)\n",
        "\n",
        "                    # Charged amino acids: D(3), E(4), K(11), R(15) in ProteinMPNN alphabet\n",
        "                    for b in range(batch_size):\n",
        "                        for i in range(seq_len):\n",
        "                            pot_val = potential[b, i].item()\n",
        "                            if abs(pot_val) > 0.5:  # High potential sites\n",
        "                                if pot_val > 0:  # Positive potential, favor negative charges\n",
        "                                    aa_bias[b, i, 3] += 0.1  # D\n",
        "                                    aa_bias[b, i, 4] += 0.1  # E\n",
        "                                else:  # Negative potential, favor positive charges\n",
        "                                    aa_bias[b, i, 11] += 0.1  # K\n",
        "                                    aa_bias[b, i, 15] += 0.1  # R\n",
        "\n",
        "                    # Apply electrostatic enhancement\n",
        "                    elec_w = torch.sigmoid(self.elec_integration) * 0.5  # Conservative weight\n",
        "                    enhanced_log_probs = standard_log_probs + elec_w * aa_bias\n",
        "\n",
        "                    print(f\"Applied electrostatic enhancement with weight: {elec_w.item():.3f}\")\n",
        "\n",
        "                    if return_features:\n",
        "                        return enhanced_log_probs, electrostatic_features\n",
        "                    return enhanced_log_probs\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Electrostatic enhancement failed: {e}\")\n",
        "\n",
        "            # Fallback to standard output\n",
        "            if return_features:\n",
        "                return standard_log_probs, None\n",
        "            return standard_log_probs\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Enhanced forward completely failed: {e}\")\n",
        "            # Last resort: call parent forward with fixed tensors\n",
        "            return super(EnhancedProteinMPNN, self).forward(\n",
        "                X, S, mask, chain_M, residue_idx, chain_encoding_all, randn,\n",
        "                use_input_decoding_order, decoding_order\n",
        "            )\n",
        "\n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn,\n",
        "                use_input_decoding_order=False, decoding_order=None):\n",
        "        \"\"\"Main forward function with fallback\"\"\"\n",
        "        try:\n",
        "            return self.forward_enhanced(X, S, mask, chain_M, residue_idx, chain_encoding_all,\n",
        "                                       randn, use_input_decoding_order, decoding_order)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Enhanced forward failed: {e}, using standard\")\n",
        "\n",
        "            # Fix tensor types before calling parent\n",
        "            residue_idx = residue_idx.long()\n",
        "            S = S.long()\n",
        "            if isinstance(chain_encoding_all, torch.Tensor):\n",
        "                chain_encoding_all = chain_encoding_all.long()\n",
        "\n",
        "            return super().forward(X, S, mask, chain_M, residue_idx, chain_encoding_all,\n",
        "                                 randn, use_input_decoding_order, decoding_order)\n",
        "\n",
        "# ============================================================================\n",
        "# Utility Functions\n",
        "# ============================================================================\n",
        "\n",
        "def get_pdb_file(pdb_code, dest_dir=\".\", overwrite=False):\n",
        "    \"\"\"Download PDB file\"\"\"\n",
        "    if not pdb_code:\n",
        "        return None\n",
        "\n",
        "    pdb_path = f\"{dest_dir}/{pdb_code}.pdb\"\n",
        "    if os.path.exists(pdb_path) and not overwrite:\n",
        "        return pdb_path\n",
        "\n",
        "    url = f\"https://files.rcsb.org/download/{pdb_code.lower()}.pdb\"\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url, pdb_path)\n",
        "        return pdb_path\n",
        "    except:\n",
        "        print(f\"❌ Failed to download {pdb_code}\")\n",
        "        return None\n",
        "\n",
        "def calculate_enhanced_metrics(native_seq, designed_seqs, scores, perplexities=None):\n",
        "    \"\"\"Calculate comprehensive metrics\"\"\"\n",
        "    metrics = {\n",
        "        'sequence_recovery': [],\n",
        "        'score': [],\n",
        "        'perplexity': [],\n",
        "        'charged_recovery': [],\n",
        "        'electrostatic_score': []\n",
        "    }\n",
        "\n",
        "    charged_residues = set('DEKR')\n",
        "\n",
        "    for i, (designed_seq, score) in enumerate(zip(designed_seqs, scores)):\n",
        "        # Recovery\n",
        "        length = min(len(native_seq), len(designed_seq))\n",
        "        if length == 0:\n",
        "            continue\n",
        "\n",
        "        identical = sum(1 for a, b in zip(native_seq[:length], designed_seq[:length]) if a == b)\n",
        "        recovery = (identical / length) * 100\n",
        "\n",
        "        metrics['sequence_recovery'].append(recovery)\n",
        "        metrics['score'].append(float(score))\n",
        "\n",
        "        # Perplexity\n",
        "        if perplexities and i < len(perplexities):\n",
        "            metrics['perplexity'].append(perplexities[i])\n",
        "        else:\n",
        "            metrics['perplexity'].append(0)\n",
        "\n",
        "        # Charged residue recovery\n",
        "        native_charged = [i for i, aa in enumerate(native_seq[:length]) if aa in charged_residues]\n",
        "        if native_charged:\n",
        "            charged_recovery = sum(1 for pos in native_charged\n",
        "                                 if pos < len(designed_seq) and designed_seq[pos] in charged_residues)\n",
        "            charged_recovery_rate = (charged_recovery / len(native_charged)) * 100\n",
        "        else:\n",
        "            charged_recovery_rate = 100  # No charged residues to recover\n",
        "        metrics['charged_recovery'].append(charged_recovery_rate)\n",
        "\n",
        "        # Electrostatic score (charge conservation)\n",
        "        native_charge = sum(1 if aa in 'KR' else -1 if aa in 'DE' else 0 for aa in native_seq[:length])\n",
        "        designed_charge = sum(1 if aa in 'KR' else -1 if aa in 'DE' else 0 for aa in designed_seq[:length])\n",
        "        charge_conservation = 1.0 - abs(native_charge - designed_charge) / max(abs(native_charge) + 1, 1)\n",
        "        metrics['electrostatic_score'].append(charge_conservation)\n",
        "\n",
        "    return pd.DataFrame(metrics)\n",
        "\n",
        "# ============================================================================\n",
        "# Main Processing Function\n",
        "# ============================================================================\n",
        "\n",
        "def process_protein_enhanced(pdb_code, designed_chains, fixed_chains,\n",
        "                           standard_model, enhanced_model,\n",
        "                           num_sequences=4, temperature=0.1):\n",
        "    \"\"\"Process protein with both standard and enhanced models\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"PROCESSING {pdb_code}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    results = {\n",
        "        'pdb_code': pdb_code,\n",
        "        'standard': {'sequences': [], 'scores': [], 'recovery_rates': [], 'perplexities': []},\n",
        "        'enhanced': {'sequences': [], 'scores': [], 'recovery_rates': [], 'perplexities': []}\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Download and parse PDB\n",
        "        pdb_path = get_pdb_file(pdb_code)\n",
        "        if not pdb_path:\n",
        "            return None\n",
        "\n",
        "        chain_list = designed_chains + fixed_chains\n",
        "        pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "        if not pdb_dict_list:\n",
        "            print(f\"❌ Failed to parse PDB for {pdb_code}\")\n",
        "            return None\n",
        "\n",
        "        dataset = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=20000)\n",
        "        chain_id_dict = {pdb_dict_list[0]['name']: (designed_chains, fixed_chains)}\n",
        "\n",
        "        print(f\"Chains: {chain_id_dict}\")\n",
        "\n",
        "        # Set context for enhanced model\n",
        "        enhanced_model.set_structure_context(pdb_path, chain_list)\n",
        "\n",
        "        # Test both models\n",
        "        models = [('standard', standard_model), ('enhanced', enhanced_model)]\n",
        "\n",
        "        for model_name, model in models:\n",
        "            print(f\"\\n🔥 Processing with {model_name} model...\")\n",
        "\n",
        "            try:\n",
        "                for protein in dataset:\n",
        "                    batch = [copy.deepcopy(protein)]\n",
        "\n",
        "                    # Setup featurization\n",
        "                    features = tied_featurize(\n",
        "                        batch, device, chain_id_dict, None, None, None, None, None\n",
        "                    )\n",
        "\n",
        "                    (X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list,\n",
        "                     visible_list_list, masked_list_list, masked_chain_length_list_list,\n",
        "                     chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask,\n",
        "                     tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all,\n",
        "                     bias_by_res_all, tied_beta) = features\n",
        "\n",
        "                    # Native scoring\n",
        "                    randn = torch.randn(chain_M.shape, device=device)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        if model_name == 'enhanced':\n",
        "                            log_probs, elec_features = model.forward_enhanced(\n",
        "                                X, S, mask, chain_M*chain_M_pos, residue_idx,\n",
        "                                chain_encoding_all, randn, return_features=True\n",
        "                            )\n",
        "                        else:\n",
        "                            log_probs = model(\n",
        "                                X, S, mask, chain_M*chain_M_pos, residue_idx,\n",
        "                                chain_encoding_all, randn\n",
        "                            )\n",
        "                            elec_features = None\n",
        "\n",
        "                        mask_for_loss = mask * chain_M * chain_M_pos\n",
        "                        scores = _scores(S, log_probs, mask_for_loss)\n",
        "                        native_score = scores.cpu().data.numpy().mean()\n",
        "\n",
        "                    results[model_name]['native_score'] = float(native_score)\n",
        "                    print(f\"✅ {model_name} native score: {native_score:.4f}\")\n",
        "\n",
        "                    # Generate sequences\n",
        "                    for seq_num in range(num_sequences):\n",
        "                        print(f\"🔥 Generating sequence {seq_num+1}/{num_sequences}...\")\n",
        "\n",
        "                        randn = torch.randn(chain_M.shape, device=device)\n",
        "\n",
        "                        with torch.no_grad():\n",
        "                            # Sample sequence\n",
        "                            sample_dict = model.sample(\n",
        "                                X, randn, S, chain_M, chain_encoding_all, residue_idx,\n",
        "                                mask=mask, temperature=temperature,\n",
        "                                omit_AAs_np=np.array([False]*20 + [True]),\n",
        "                                bias_AAs_np=np.zeros(21),\n",
        "                                chain_M_pos=chain_M_pos, omit_AA_mask=omit_AA_mask,\n",
        "                                pssm_coef=pssm_coef, pssm_bias=pssm_bias,\n",
        "                                pssm_multi=0.0, pssm_log_odds_flag=False,\n",
        "                                pssm_log_odds_mask=(pssm_log_odds_all > 0.0).float(),\n",
        "                                pssm_bias_flag=False, bias_by_res=bias_by_res_all\n",
        "                            )\n",
        "\n",
        "                            S_sample = sample_dict[\"S\"]\n",
        "\n",
        "                            # Score sampled sequence\n",
        "                            if model_name == 'enhanced':\n",
        "                                log_probs_sample, elec_features = model.forward_enhanced(\n",
        "                                    X, S_sample, mask, chain_M*chain_M_pos, residue_idx,\n",
        "                                    chain_encoding_all, randn,\n",
        "                                    use_input_decoding_order=True,\n",
        "                                    decoding_order=sample_dict[\"decoding_order\"],\n",
        "                                    return_features=True\n",
        "                                )\n",
        "                            else:\n",
        "                                log_probs_sample = model(\n",
        "                                    X, S_sample, mask, chain_M*chain_M_pos, residue_idx,\n",
        "                                    chain_encoding_all, randn,\n",
        "                                    use_input_decoding_order=True,\n",
        "                                    decoding_order=sample_dict[\"decoding_order\"]\n",
        "                                )\n",
        "\n",
        "                            scores = _scores(S_sample, log_probs_sample, mask_for_loss)\n",
        "                            score_value = scores.cpu().data.numpy()[0]\n",
        "\n",
        "                            # Calculate perplexity\n",
        "                            perplexity_calc = PerplexityCalculator()\n",
        "                            perplexity = perplexity_calc.calculate_perplexity(\n",
        "                                log_probs_sample, S_sample, mask_for_loss\n",
        "                            )\n",
        "\n",
        "                            # Recovery calculation\n",
        "                            seq_recovery_rate = torch.sum(\n",
        "                                torch.sum(torch.nn.functional.one_hot(S[0], 21) *\n",
        "                                         torch.nn.functional.one_hot(S_sample[0], 21), axis=-1) *\n",
        "                                mask_for_loss[0]\n",
        "                            ) / torch.sum(mask_for_loss[0])\n",
        "\n",
        "                            # Convert sequences\n",
        "                            seq = _S_to_seq(S_sample[0], chain_M[0])\n",
        "                            native_seq = _S_to_seq(S[0], chain_M[0])\n",
        "\n",
        "                            # Store results\n",
        "                            results[model_name]['sequences'].append(seq)\n",
        "                            results[model_name]['scores'].append(float(score_value))\n",
        "                            results[model_name]['recovery_rates'].append(float(seq_recovery_rate.detach().cpu().numpy()))\n",
        "                            results[model_name]['perplexities'].append(float(perplexity))\n",
        "\n",
        "                            if 'native_sequence' not in results[model_name]:\n",
        "                                results[model_name]['native_sequence'] = native_seq\n",
        "\n",
        "                            print(f\"✅ {model_name} seq {seq_num+1}: Recovery={seq_recovery_rate:.3f}, \"\n",
        "                                  f\"Score={score_value:.4f}, Perplexity={perplexity:.2f}\")\n",
        "\n",
        "                    break  # Only process first protein in dataset\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ {model_name} model failed: {e}\")\n",
        "                continue\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Complete failure for {pdb_code}: {e}\")\n",
        "        return None\n",
        "\n",
        "# ============================================================================\n",
        "# Main Execution\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    print(\"🚀 ENHANCED PROTEINMPNN WITH ESM-2 AND APBS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Initialize handlers\n",
        "    print(\"\\n📦 Initializing components...\")\n",
        "    apbs_handler = APBSElectrostaticHandler(device=device)\n",
        "    esm2_handler = ESM2Handler(device=device)\n",
        "\n",
        "    # Load ESM-2\n",
        "    esm2_loaded = esm2_handler.load_model()\n",
        "    if not esm2_loaded:\n",
        "        print(\"⚠️ ESM-2 not available, enhanced features will be limited\")\n",
        "\n",
        "    # Load ProteinMPNN weights\n",
        "    print(\"\\n📥 Loading ProteinMPNN weights...\")\n",
        "    model_name = \"v_48_020\"\n",
        "    path_to_weights = '/content/ProteinMPNN/vanilla_model_weights'\n",
        "    checkpoint_path = f'{path_to_weights}/{model_name}.pt'\n",
        "\n",
        "    # Download weights if needed\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        os.makedirs(path_to_weights, exist_ok=True)\n",
        "        urllib.request.urlretrieve(\n",
        "            f\"https://github.com/dauparas/ProteinMPNN/raw/main/vanilla_model_weights/{model_name}.pt\",\n",
        "            checkpoint_path\n",
        "        )\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    print(f'Number of edges: {checkpoint[\"num_edges\"]}')\n",
        "\n",
        "    # Create standard model\n",
        "    standard_model = ProteinMPNN(\n",
        "        num_letters=21, node_features=128, edge_features=128, hidden_dim=128,\n",
        "        num_encoder_layers=3, num_decoder_layers=3, augment_eps=0.0,\n",
        "        k_neighbors=checkpoint['num_edges']\n",
        "    ).to(device)\n",
        "\n",
        "    standard_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    standard_model.eval()\n",
        "    print(\"✅ Standard ProteinMPNN loaded\")\n",
        "\n",
        "    # Create enhanced model\n",
        "    enhanced_model = EnhancedProteinMPNN(\n",
        "        esm2_handler=esm2_handler, apbs_handler=apbs_handler,\n",
        "        num_letters=21, node_features=128, edge_features=128, hidden_dim=128,\n",
        "        num_encoder_layers=3, num_decoder_layers=3, augment_eps=0.0,\n",
        "        k_neighbors=checkpoint['num_edges'], device=device\n",
        "    ).to(device)\n",
        "\n",
        "    enhanced_model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "    enhanced_model.eval()\n",
        "    print(\"✅ Enhanced ProteinMPNN created\")\n",
        "\n",
        "    # Test proteins\n",
        "    test_proteins = { '5MUX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5MX5': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N']},\n",
        "                      '5MY0': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5MY2': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5MZ2': {'designed_chains': ['A'], 'fixed_chains': ['C', 'H', 'F', 'D', 'B', 'E', 'G', 'I', 'O', 'L', 'N', 'M', 'P', 'J', 'K']},\n",
        "                      '5MZ5': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5MZ8': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5MZQ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E']},\n",
        "                      '5MZR': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E']},\n",
        "                      '5MZT': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E']},\n",
        "                      '5N2K': {'designed_chains': ['B'], 'fixed_chains': ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'O']},\n",
        "                      '5N2U': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N4B': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N4C': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5N4D': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N5E': {'designed_chains': ['e'], 'fixed_chains': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd']},\n",
        "                      '5N5S': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N5V': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5N69': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N6Y': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5N8R': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N8S': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N8U': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N94': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N96': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N98': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N9D': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N9F': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5N9Z': {'designed_chains': ['A'], 'fixed_chains': ['I', 'H', 'O', 'F', 'N', 'D', 'M', 'B', 'P', 'C', 'J', 'E', 'K', 'G', 'L']},\n",
        "                      '5NB3': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X']},\n",
        "                      '5NB4': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X']},\n",
        "                      '5NBL': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5NDF': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5NDY': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5NFR': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']},\n",
        "                      '5NFZ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5NG1': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5NH4': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NH5': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NH6': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NH7': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NH8': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NH9': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NHA': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NHB': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NHC': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NHD': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NHE': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NHG': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5NHM': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NI4': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C']},\n",
        "                      '5NIE': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C']},\n",
        "                      '5NIJ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NJ5': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NJ9': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5NJA': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5NJB': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NJC': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5NJF': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5NME': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']},\n",
        "                      '5NMF': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']},\n",
        "                      '5NMG': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']},\n",
        "                      '5NMP': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']},\n",
        "                      '5NMW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NMX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NQD': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5NSW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C']},\n",
        "                      '5NUP': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5NUX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NV4': {'designed_chains': ['A'], 'fixed_chains': ['B']},\n",
        "                      '5NVV': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5NVW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5NVX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5NVY': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5NVZ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5NW0': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5NW1': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5NW2': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5NX8': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NX9': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5NXA': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5NZ1': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5NZ7': {'designed_chains': ['A'], 'fixed_chains': ['B']},\n",
        "                      '5NZZ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5O0O': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5O0W': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5O2K': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5O30': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']},\n",
        "                      '5O3K': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5O3M': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5O3U': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'L', 'M', 'N', 'O']},\n",
        "                      '5O3V': {'designed_chains': ['A'], 'fixed_chains': ['B', 'D', 'C']},\n",
        "                      '5O3W': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'W', 'X', 'Y', 'Z']},\n",
        "                      '5O3X': {'designed_chains': ['A'], 'fixed_chains': ['B']},\n",
        "                      '5O3Z': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5O4I': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5O4Q': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5O5C': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5O5L': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K']},\n",
        "                      '5O6K': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5O6M': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5O74': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5O7O': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5O7Z': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5O80': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5O81': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5O82': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5O87': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']},\n",
        "                      '5O8Q': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5O96': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5OAJ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']},\n",
        "                      '5OAT': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5OBA': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X']},\n",
        "                      '5OBB': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X']},\n",
        "                      '5OCS': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OD2': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C']},\n",
        "                      '5ODC': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5ODH': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5ODI': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5ODQ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5ODR': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']},\n",
        "                      '5ODW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OE3': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OE6': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OEE': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5OES': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5OEV': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OEX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OF3': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5OFA': {'designed_chains': ['B'], 'fixed_chains': ['A']},\n",
        "                      '5OFQ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OGT': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OHE': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5OHF': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5OHG': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5OHL': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']},\n",
        "                      '5OHS': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5OHY': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OHZ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OIU': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5OK7': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OKA': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OKB': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OKE': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5OKG': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                      '5OKM': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5OKN': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5OLC': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                      '5OLK': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                      '5OMW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']}, }\n",
        "\n",
        "\n",
        "\n",
        "    # Process proteins\n",
        "    all_results = {}\n",
        "    for pdb_code, config in test_proteins.items():\n",
        "        print(f\"\\n🧬 Processing {pdb_code}...\")\n",
        "\n",
        "        result = process_protein_enhanced(\n",
        "            pdb_code, config['designed_chains'], config['fixed_chains'],\n",
        "            standard_model, enhanced_model, num_sequences=3, temperature=0.1\n",
        "        )\n",
        "\n",
        "        if result:\n",
        "            all_results[pdb_code] = result\n",
        "\n",
        "            # Print comparison\n",
        "            if result['standard']['sequences'] and result['enhanced']['sequences']:\n",
        "                std_recovery = np.mean(result['standard']['recovery_rates'])\n",
        "                enh_recovery = np.mean(result['enhanced']['recovery_rates'])\n",
        "                std_perplexity = np.mean(result['standard']['perplexities'])\n",
        "                enh_perplexity = np.mean(result['enhanced']['perplexities'])\n",
        "\n",
        "                improvement = enh_recovery - std_recovery\n",
        "\n",
        "                print(f\"\\n📊 {pdb_code} Results:\")\n",
        "                print(f\"   Recovery: {std_recovery:.3f} → {enh_recovery:.3f} ({improvement:+.3f})\")\n",
        "                print(f\"   Perplexity: {std_perplexity:.2f} → {enh_perplexity:.2f}\")\n",
        "\n",
        "    # Final summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"📊 ENHANCED PROTEINMPNN BENCHMARK COMPLETE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    improvements = []\n",
        "    for pdb_code, result in all_results.items():\n",
        "        if result['standard']['sequences'] and result['enhanced']['sequences']:\n",
        "            std = np.mean(result['standard']['recovery_rates'])\n",
        "            enh = np.mean(result['enhanced']['recovery_rates'])\n",
        "            imp = enh - std\n",
        "            improvements.append(imp)\n",
        "\n",
        "            status = \"✅ Improved\" if imp > 0 else \"⚠️ Decreased\"\n",
        "            print(f\"{pdb_code}: {std:.3f} → {enh:.3f} ({imp:+.3f}) {status}\")\n",
        "\n",
        "    if improvements:\n",
        "        avg_improvement = np.mean(improvements)\n",
        "        print(f\"\\n🎯 Average Recovery Improvement: {avg_improvement:+.3f}\")\n",
        "\n",
        "        if avg_improvement > 0.01:\n",
        "            print(\"🏆 SUCCESS: Enhanced model shows improvement!\")\n",
        "        elif avg_improvement > -0.01:\n",
        "            print(\"✅ Comparable performance with enhanced features\")\n",
        "        else:\n",
        "            print(\"⚠️ Further optimization needed\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# Execute\n",
        "if __name__ == \"__main__\":\n",
        "    results = main()\n",
        "    print(\"\\n🎉 Enhanced ProteinMPNN pipeline complete!\")"
      ],
      "metadata": {
        "id": "8Vfbc-y-C34t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "4b3f57f0-af19-480e-8af6-a2e439cdb62b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Installed biopython\n",
            "✅ Installed matplotlib\n",
            "✅ Installed pandas\n",
            "✅ Installed scipy\n",
            "✅ Installed fair-esm\n",
            "✅ Installed tqdm\n",
            "✅ APBS installed\n",
            "Using device: cpu\n",
            "🚀 ENHANCED PROTEINMPNN WITH ESM-2 AND APBS\n",
            "============================================================\n",
            "\n",
            "📦 Initializing components...\n",
            "Loading ESM-2 model...\n",
            "✅ ESM-2 loaded successfully!\n",
            "\n",
            "📥 Loading ProteinMPNN weights...\n",
            "Number of edges: 48\n",
            "✅ Standard ProteinMPNN loaded\n",
            "✅ Enhanced ProteinMPNN created\n",
            "\n",
            "🧬 Processing 5MUX...\n",
            "\n",
            "============================================================\n",
            "PROCESSING 5MUX\n",
            "============================================================\n",
            "Chains: {'5MUX': (['A'], ['B', 'C', 'D', 'E', 'F'])}\n",
            "\n",
            "🔥 Processing with standard model...\n",
            "✅ standard native score: 1.3013\n",
            "🔥 Generating sequence 1/3...\n",
            "✅ standard seq 1: Recovery=0.542, Score=0.7220, Perplexity=2.06\n",
            "🔥 Generating sequence 2/3...\n",
            "✅ standard seq 2: Recovery=0.533, Score=0.7209, Perplexity=2.06\n",
            "🔥 Generating sequence 3/3...\n",
            "✅ standard seq 3: Recovery=0.563, Score=0.7041, Perplexity=2.02\n",
            "\n",
            "🔥 Processing with enhanced model...\n",
            "Applied electrostatic enhancement with weight: 0.275\n",
            "✅ enhanced native score: 1.3109\n",
            "🔥 Generating sequence 1/3...\n",
            "Applied electrostatic enhancement with weight: 0.275\n",
            "✅ enhanced seq 1: Recovery=0.552, Score=0.7141, Perplexity=2.04\n",
            "🔥 Generating sequence 2/3...\n",
            "Applied electrostatic enhancement with weight: 0.275\n",
            "✅ enhanced seq 2: Recovery=0.550, Score=0.7244, Perplexity=2.06\n",
            "🔥 Generating sequence 3/3...\n",
            "Applied electrostatic enhancement with weight: 0.275\n",
            "✅ enhanced seq 3: Recovery=0.546, Score=0.7314, Perplexity=2.08\n",
            "\n",
            "📊 5MUX Results:\n",
            "   Recovery: 0.546 → 0.549 (+0.004)\n",
            "   Perplexity: 2.05 → 2.06\n",
            "\n",
            "🧬 Processing 5MX5...\n",
            "\n",
            "============================================================\n",
            "PROCESSING 5MX5\n",
            "============================================================\n",
            "Chains: {'5MX5': (['A'], ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N'])}\n",
            "\n",
            "🔥 Processing with standard model...\n",
            "✅ standard native score: 1.4606\n",
            "🔥 Generating sequence 1/3...\n",
            "✅ standard seq 1: Recovery=0.481, Score=0.9331, Perplexity=2.54\n",
            "🔥 Generating sequence 2/3...\n",
            "✅ standard seq 2: Recovery=0.466, Score=0.9374, Perplexity=2.55\n",
            "🔥 Generating sequence 3/3...\n",
            "✅ standard seq 3: Recovery=0.510, Score=0.9055, Perplexity=2.47\n",
            "\n",
            "🔥 Processing with enhanced model...\n",
            "Applied electrostatic enhancement with weight: 0.275\n",
            "✅ enhanced native score: 1.4477\n",
            "🔥 Generating sequence 1/3...\n",
            "Applied electrostatic enhancement with weight: 0.275\n",
            "✅ enhanced seq 1: Recovery=0.476, Score=0.9135, Perplexity=2.49\n",
            "🔥 Generating sequence 2/3...\n",
            "Applied electrostatic enhancement with weight: 0.275\n",
            "✅ enhanced seq 2: Recovery=0.519, Score=0.9037, Perplexity=2.47\n",
            "🔥 Generating sequence 3/3...\n",
            "Applied electrostatic enhancement with weight: 0.275\n",
            "✅ enhanced seq 3: Recovery=0.452, Score=0.9111, Perplexity=2.49\n",
            "\n",
            "📊 5MX5 Results:\n",
            "   Recovery: 0.486 → 0.482 (-0.003)\n",
            "   Perplexity: 2.52 → 2.48\n",
            "\n",
            "🧬 Processing 5MY0...\n",
            "\n",
            "============================================================\n",
            "PROCESSING 5MY0\n",
            "============================================================\n",
            "Chains: {'5MY0': (['A'], ['B', 'C', 'D'])}\n",
            "\n",
            "🔥 Processing with standard model...\n",
            "✅ standard native score: 1.2506\n",
            "🔥 Generating sequence 1/3...\n",
            "✅ standard seq 1: Recovery=0.550, Score=0.6820, Perplexity=1.98\n",
            "🔥 Generating sequence 2/3...\n",
            "✅ standard seq 2: Recovery=0.583, Score=0.6662, Perplexity=1.95\n",
            "🔥 Generating sequence 3/3...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enhanced Integration"
      ],
      "metadata": {
        "id": "wU4sjKgds3pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Enhanced ProteinMPNN - Production Version\n",
        "Focus on robust evaluation with comprehensive charged protein dataset\n",
        "\"\"\"\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def install_dependencies():\n",
        "    \"\"\"Install required packages\"\"\"\n",
        "    packages = ['biopython', 'matplotlib', 'pandas', 'scipy', 'fair-esm', 'tqdm', 'seaborn']\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "            print(f\"✅ Installed {package}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Failed to install {package}: {e}\")\n",
        "\n",
        "install_dependencies()\n",
        "\n",
        "# Clone ProteinMPNN if needed\n",
        "if not os.path.isdir(\"ProteinMPNN\"):\n",
        "    os.system(\"git clone -q https://github.com/dauparas/ProteinMPNN.git\")\n",
        "sys.path.append('/content/ProteinMPNN')\n",
        "\n",
        "import json, time, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import copy\n",
        "from scipy import stats\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "\n",
        "# Bio imports\n",
        "try:\n",
        "    from Bio import PDB\n",
        "    from Bio.PDB import PDBParser\n",
        "    BIO_AVAILABLE = True\n",
        "except:\n",
        "    BIO_AVAILABLE = False\n",
        "    print(\"⚠️ BioPython not available\")\n",
        "\n",
        "# ESM imports\n",
        "try:\n",
        "    import esm\n",
        "    ESM_AVAILABLE = True\n",
        "except:\n",
        "    ESM_AVAILABLE = False\n",
        "    print(\"⚠️ ESM-2 not available\")\n",
        "\n",
        "# ProteinMPNN imports\n",
        "from protein_mpnn_utils import (\n",
        "    loss_nll, loss_smoothed, gather_edges, gather_nodes,\n",
        "    gather_nodes_t, cat_neighbors_nodes, _scores, _S_to_seq,\n",
        "    tied_featurize, parse_PDB, StructureDataset,\n",
        "    StructureDatasetPDB, ProteinMPNN\n",
        ")\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Charged Protein Dataset\n",
        "# ============================================================================\n",
        "\n",
        "CHARGED_PROTEINS = {\n",
        "    '5MUX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 822},\n",
        "    '5MX5': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N'], 'charged_residues': 873},\n",
        "    '5MY0': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 722},\n",
        "    '5MY2': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 723},\n",
        "    '5MZ2': {'designed_chains': ['A'], 'fixed_chains': ['C', 'H', 'F', 'D', 'B', 'E', 'G', 'I', 'O', 'L', 'N', 'M', 'P', 'J', 'K'], 'charged_residues': 1125},\n",
        "    '5MZ5': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 532},\n",
        "    '5MZ8': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 532},\n",
        "    '5MZQ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E'], 'charged_residues': 325},\n",
        "    '5MZR': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E'], 'charged_residues': 320},\n",
        "    '5MZT': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E'], 'charged_residues': 320},\n",
        "    '5N2K': {'designed_chains': ['B'], 'fixed_chains': ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'O'], 'charged_residues': 578},\n",
        "    '5N2U': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 459},\n",
        "    '5N4B': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 382},\n",
        "    '5N4C': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 768},\n",
        "    '5N4D': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 379},\n",
        "    '5N5E': {'designed_chains': ['e'], 'fixed_chains': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd'], 'charged_residues': 990},\n",
        "    '5N5S': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 532},\n",
        "    '5N5V': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 829},\n",
        "    '5N69': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 537},\n",
        "    '5N6Y': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 604},\n",
        "    '5N8R': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 472},\n",
        "    '5N8S': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 475},\n",
        "    '5N8U': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 472},\n",
        "    '5N94': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 472},\n",
        "    '5N96': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 472},\n",
        "    '5N98': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 472},\n",
        "    '5N9D': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 484},\n",
        "    '5N9F': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 478},\n",
        "    '5N9Z': {'designed_chains': ['A'], 'fixed_chains': ['I', 'H', 'O', 'F', 'N', 'D', 'M', 'B', 'P', 'C', 'J', 'E', 'K', 'G', 'L'], 'charged_residues': 1128},\n",
        "    '5NB3': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X'], 'charged_residues': 876},\n",
        "    '5NB4': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X'], 'charged_residues': 876},\n",
        "    '5NBL': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 430},\n",
        "    '5NDF': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 852},\n",
        "    '5NDY': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 358},\n",
        "    '5NFR': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'], 'charged_residues': 1102},\n",
        "    '5NFZ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 570},\n",
        "    '5NG1': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 570},\n",
        "    '5NH4': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 524},\n",
        "    '5NH5': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 524},\n",
        "    '5NH6': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 524},\n",
        "    '5NH7': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 524},\n",
        "    '5NH8': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 524},\n",
        "    '5NH9': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 524},\n",
        "    '5NHA': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 524},\n",
        "    '5NHB': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 524},\n",
        "    '5NHC': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 524},\n",
        "    '5NHD': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 524},\n",
        "    '5NHE': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 524},\n",
        "    '5NHG': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 912},\n",
        "    '5NHM': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 524},\n",
        "    '5NI4': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C'], 'charged_residues': 455},\n",
        "    '5NIE': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C'], 'charged_residues': 453},\n",
        "    '5NIJ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 403},\n",
        "    '5NJ5': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 438},\n",
        "    '5NJ9': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 442},\n",
        "    '5NJA': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 440},\n",
        "    '5NJB': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 440},\n",
        "    '5NJC': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 442},\n",
        "    '5NJF': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 436},\n",
        "    '5NME': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], 'charged_residues': 437},\n",
        "    '5NMF': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], 'charged_residues': 434},\n",
        "    '5NMG': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], 'charged_residues': 437},\n",
        "    '5NMP': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], 'charged_residues': 520},\n",
        "    '5NMW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 440},\n",
        "    '5NMX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 440},\n",
        "    '5NQD': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 984},\n",
        "    '5NSW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C'], 'charged_residues': 373},\n",
        "    '5NUP': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 340},\n",
        "    '5NUX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 328},\n",
        "    '5NV4': {'designed_chains': ['A'], 'fixed_chains': ['B'], 'charged_residues': 394},\n",
        "    '5NVV': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 365},\n",
        "    '5NVW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 365},\n",
        "    '5NVX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 365},\n",
        "    '5NVY': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 365},\n",
        "    '5NVZ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 365},\n",
        "    '5NW0': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 365},\n",
        "    '5NW1': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 365},\n",
        "    '5NW2': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 366},\n",
        "    '5NX8': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 515},\n",
        "    '5NX9': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 521},\n",
        "    '5NXA': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 1014},\n",
        "    '5NZ1': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 377},\n",
        "    '5NZ7': {'designed_chains': ['A'], 'fixed_chains': ['B'], 'charged_residues': 492},\n",
        "    '5NZZ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 750},\n",
        "    '5O0O': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 550},\n",
        "    '5O0W': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 469},\n",
        "    '5O2K': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 420},\n",
        "    '5O30': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], 'charged_residues': 552},\n",
        "    '5O3K': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 907},\n",
        "    '5O3M': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 660},\n",
        "    '5O3U': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'L', 'M', 'N', 'O'], 'charged_residues': 810},\n",
        "    '5O3V': {'designed_chains': ['A'], 'fixed_chains': ['B', 'D', 'C'], 'charged_residues': 412},\n",
        "    '5O3W': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'W', 'X', 'Y', 'Z'], 'charged_residues': 824},\n",
        "    '5O3X': {'designed_chains': ['A'], 'fixed_chains': ['B'], 'charged_residues': 411},\n",
        "    '5O3Z': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 622},\n",
        "    '5O4I': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 903},\n",
        "    '5O4Q': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 899},\n",
        "    '5O5C': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 684},\n",
        "    '5O5L': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K'], 'charged_residues': 715},\n",
        "    '5O6K': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 347},\n",
        "    '5O6M': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 350},\n",
        "    '5O74': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 585},\n",
        "    '5O7O': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 347},\n",
        "    '5O7Z': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 900},\n",
        "    '5O80': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 900},\n",
        "    '5O81': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 893},\n",
        "    '5O82': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 891},\n",
        "    '5O87': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], 'charged_residues': 469},\n",
        "    '5O8Q': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 536},\n",
        "    '5O96': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 520},\n",
        "    '5OAJ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], 'charged_residues': 496},\n",
        "    '5OAT': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 444},\n",
        "    '5OBA': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X'], 'charged_residues': 1392},\n",
        "    '5OBB': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X'], 'charged_residues': 1392},\n",
        "    '5OCS': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 350},\n",
        "    '5OD2': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C'], 'charged_residues': 471},\n",
        "    '5ODC': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 1151},\n",
        "    '5ODH': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 1154},\n",
        "    '5ODI': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 1151},\n",
        "    '5ODQ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 1154},\n",
        "    '5ODR': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L'], 'charged_residues': 1152},\n",
        "    '5ODW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 480},\n",
        "    '5OE3': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 348},\n",
        "    '5OE6': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 346},\n",
        "    '5OEE': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 705},\n",
        "    '5OES': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 748},\n",
        "    '5OEV': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 441},\n",
        "    '5OEX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 456},\n",
        "    '5OF3': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 418},\n",
        "    '5OFA': {'designed_chains': ['B'], 'fixed_chains': ['A'], 'charged_residues': 343},\n",
        "    '5OFQ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 452},\n",
        "    '5OGT': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 332},\n",
        "    '5OHE': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 403},\n",
        "    '5OHF': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 399},\n",
        "    '5OHG': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 473},\n",
        "    '5OHL': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'], 'charged_residues': 446},\n",
        "    '5OHS': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 1320},\n",
        "    '5OHY': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 656},\n",
        "    '5OHZ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 463},\n",
        "    '5OIU': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 670},\n",
        "    '5OK7': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 488},\n",
        "    '5OKA': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 488},\n",
        "    '5OKB': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 497},\n",
        "    '5OKE': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 487},\n",
        "    '5OKG': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F'], 'charged_residues': 488},\n",
        "    '5OKM': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 896},\n",
        "    '5OKN': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 866},\n",
        "    '5OLC': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H'], 'charged_residues': 816},\n",
        "    '5OLK': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 530},\n",
        "    '5OMW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D'], 'charged_residues': 470}\n",
        "}\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Simple APBS Handler (Conservative)\n",
        "# ============================================================================\n",
        "\n",
        "class SimpleAPBSHandler:\n",
        "    \"\"\"Simple electrostatic analysis for charged residue identification\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.charge_map = {\n",
        "            'ARG': 1.0, 'LYS': 1.0, 'HIS': 0.5,  # Positive\n",
        "            'ASP': -1.0, 'GLU': -1.0,              # Negative\n",
        "        }\n",
        "        self.cache = {}\n",
        "\n",
        "    def analyze_charged_positions(self, pdb_path, chain_ids):\n",
        "        \"\"\"Simple analysis of charged positions in structure\"\"\"\n",
        "        cache_key = f\"{pdb_path}_{'-'.join(sorted(chain_ids))}\"\n",
        "\n",
        "        if cache_key in self.cache:\n",
        "            return self.cache[cache_key]\n",
        "\n",
        "        if not BIO_AVAILABLE:\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            parser = PDBParser(QUIET=True)\n",
        "            structure = parser.get_structure('protein', pdb_path)\n",
        "\n",
        "            charged_positions = {}\n",
        "            all_positions = {}\n",
        "\n",
        "            position_idx = 0\n",
        "            for model in structure:\n",
        "                for chain in model:\n",
        "                    if chain.id in chain_ids:\n",
        "                        for residue in chain:\n",
        "                            if residue.get_id()[0] == ' ':\n",
        "                                resname = residue.get_resname()\n",
        "                                charge = self.charge_map.get(resname, 0)\n",
        "\n",
        "                                position_info = {\n",
        "                                    'chain': chain.id,\n",
        "                                    'resnum': residue.get_id()[1],\n",
        "                                    'resname': resname,\n",
        "                                    'charge': charge,\n",
        "                                    'position_idx': position_idx\n",
        "                                }\n",
        "\n",
        "                                all_positions[position_idx] = position_info\n",
        "                                if charge != 0:\n",
        "                                    charged_positions[position_idx] = position_info\n",
        "\n",
        "                                position_idx += 1\n",
        "\n",
        "            result = {\n",
        "                'charged_positions': charged_positions,\n",
        "                'all_positions': all_positions,\n",
        "                'total_charged': len(charged_positions),\n",
        "                'total_residues': len(all_positions)\n",
        "            }\n",
        "\n",
        "            self.cache[cache_key] = result\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ APBS analysis failed: {e}\")\n",
        "            return {}\n",
        "\n",
        "# ============================================================================\n",
        "# Enhanced ProteinMPNN (Minimal Enhancement)\n",
        "# ============================================================================\n",
        "\n",
        "class ConservativeEnhancedProteinMPNN(ProteinMPNN):\n",
        "    \"\"\"Very conservative enhanced ProteinMPNN - focuses on charged residue recovery\"\"\"\n",
        "\n",
        "    def __init__(self, apbs_handler=None, enhancement_weight=0.05, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.apbs_handler = apbs_handler\n",
        "        self.enhancement_weight = enhancement_weight\n",
        "        self.pdb_path = None\n",
        "        self.chain_ids = []\n",
        "        self.use_enhancement = False\n",
        "\n",
        "    def set_structure_context(self, pdb_path, chain_ids):\n",
        "        \"\"\"Set structure context\"\"\"\n",
        "        self.pdb_path = pdb_path\n",
        "        self.chain_ids = chain_ids\n",
        "        self.use_enhancement = self.apbs_handler is not None\n",
        "\n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn,\n",
        "                use_input_decoding_order=False, decoding_order=None):\n",
        "        \"\"\"Enhanced forward with minimal conservative bias\"\"\"\n",
        "\n",
        "        # Fix tensor dtypes\n",
        "        residue_idx = residue_idx.long()\n",
        "        S = S.long()\n",
        "        if isinstance(chain_encoding_all, torch.Tensor):\n",
        "            chain_encoding_all = chain_encoding_all.long()\n",
        "        if decoding_order is not None:\n",
        "            decoding_order = decoding_order.long()\n",
        "\n",
        "        # Get standard ProteinMPNN output\n",
        "        log_probs = super().forward(X, S, mask, chain_M, residue_idx,\n",
        "                                   chain_encoding_all, randn,\n",
        "                                   use_input_decoding_order, decoding_order)\n",
        "\n",
        "        # Apply very conservative enhancement\n",
        "        if self.use_enhancement and self.pdb_path and self.enhancement_weight > 0:\n",
        "            try:\n",
        "                analysis = self.apbs_handler.analyze_charged_positions(self.pdb_path, self.chain_ids)\n",
        "                charged_positions = analysis.get('charged_positions', {})\n",
        "\n",
        "                if charged_positions:\n",
        "                    # Very small bias toward maintaining charged residues at charged positions\n",
        "                    aa_bias = torch.zeros_like(log_probs)\n",
        "                    batch_size, seq_len = log_probs.shape[:2]\n",
        "\n",
        "                    for pos_idx, pos_info in charged_positions.items():\n",
        "                        if pos_idx < seq_len:\n",
        "                            charge = pos_info['charge']\n",
        "                            # Small bias to maintain similar charges\n",
        "                            if charge > 0:  # Positive position, slightly favor K, R\n",
        "                                aa_bias[:, pos_idx, 11] += 0.02  # K\n",
        "                                aa_bias[:, pos_idx, 15] += 0.02  # R\n",
        "                            elif charge < 0:  # Negative position, slightly favor D, E\n",
        "                                aa_bias[:, pos_idx, 3] += 0.02   # D\n",
        "                                aa_bias[:, pos_idx, 4] += 0.02   # E\n",
        "\n",
        "                    # Apply with very small weight\n",
        "                    log_probs = log_probs + self.enhancement_weight * aa_bias\n",
        "\n",
        "            except Exception as e:\n",
        "                # Silently fall back to standard output\n",
        "                pass\n",
        "\n",
        "        return log_probs\n",
        "\n",
        "# ============================================================================\n",
        "# Evaluation and Metrics\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_comprehensive_metrics(native_seq, designed_seqs, scores, perplexities=None):\n",
        "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
        "\n",
        "    metrics = []\n",
        "    charged_residues = set('DEKR')\n",
        "    positive_residues = set('KR')\n",
        "    negative_residues = set('DE')\n",
        "\n",
        "    for i, (designed_seq, score) in enumerate(zip(designed_seqs, scores)):\n",
        "        # Clean sequences\n",
        "        native_clean = native_seq.replace('/', '').replace('X', '')\n",
        "        designed_clean = designed_seq.replace('/', '').replace('X', '')\n",
        "        length = min(len(native_clean), len(designed_clean))\n",
        "\n",
        "        if length == 0:\n",
        "            continue\n",
        "\n",
        "        # Basic recovery\n",
        "        identical = sum(1 for a, b in zip(native_clean[:length], designed_clean[:length]) if a == b)\n",
        "        recovery = identical / length\n",
        "\n",
        "        # Charged residue analysis\n",
        "        native_charged_pos = [j for j, aa in enumerate(native_clean[:length]) if aa in charged_residues]\n",
        "        designed_charged_pos = [j for j, aa in enumerate(designed_clean[:length]) if aa in charged_residues]\n",
        "\n",
        "        # Charged recovery (how many originally charged positions remain charged)\n",
        "        charged_recovery = 0\n",
        "        if native_charged_pos:\n",
        "            charged_recovery = sum(1 for pos in native_charged_pos\n",
        "                                 if pos < len(designed_clean) and designed_clean[pos] in charged_residues)\n",
        "            charged_recovery = charged_recovery / len(native_charged_pos)\n",
        "\n",
        "        # Charge conservation\n",
        "        native_charge = sum(1 if aa in positive_residues else -1 if aa in negative_residues else 0\n",
        "                           for aa in native_clean[:length])\n",
        "        designed_charge = sum(1 if aa in positive_residues else -1 if aa in negative_residues else 0\n",
        "                             for aa in designed_clean[:length])\n",
        "\n",
        "        charge_conservation = 1.0 - abs(native_charge - designed_charge) / max(abs(native_charge) + 1, 1)\n",
        "\n",
        "        # Electrostatic compatibility score\n",
        "        electrostatic_score = 0.5 * charged_recovery + 0.5 * charge_conservation\n",
        "\n",
        "        metric_dict = {\n",
        "            'sequence_recovery': recovery,\n",
        "            'score': float(score),\n",
        "            'charged_recovery': charged_recovery,\n",
        "            'charge_conservation': charge_conservation,\n",
        "            'electrostatic_score': electrostatic_score,\n",
        "            'native_charge': native_charge,\n",
        "            'designed_charge': designed_charge,\n",
        "            'perplexity': perplexities[i] if perplexities and i < len(perplexities) else 0\n",
        "        }\n",
        "\n",
        "        metrics.append(metric_dict)\n",
        "\n",
        "    return pd.DataFrame(metrics) if metrics else pd.DataFrame()\n",
        "\n",
        "# ============================================================================\n",
        "# Visualization Dashboard\n",
        "# ============================================================================\n",
        "\n",
        "def create_comprehensive_dashboard(all_results):\n",
        "    \"\"\"Create comprehensive visualization dashboard\"\"\"\n",
        "\n",
        "    if not all_results:\n",
        "        print(\"No results to visualize\")\n",
        "        return\n",
        "\n",
        "    # Prepare data for visualization\n",
        "    data_for_viz = []\n",
        "    for pdb_code, result in all_results.items():\n",
        "        if result.get('standard', {}).get('sequences') and result.get('enhanced', {}).get('sequences'):\n",
        "            # Calculate metrics for both models\n",
        "            std_metrics = calculate_comprehensive_metrics(\n",
        "                result['standard'].get('native_sequence', ''),\n",
        "                result['standard']['sequences'],\n",
        "                result['standard']['scores'],\n",
        "                result['standard'].get('perplexities', [])\n",
        "            )\n",
        "\n",
        "            enh_metrics = calculate_comprehensive_metrics(\n",
        "                result['enhanced'].get('native_sequence', ''),\n",
        "                result['enhanced']['sequences'],\n",
        "                result['enhanced']['scores'],\n",
        "                result['enhanced'].get('perplexities', [])\n",
        "            )\n",
        "\n",
        "            if not std_metrics.empty and not enh_metrics.empty:\n",
        "                # Average metrics\n",
        "                std_avg = std_metrics.mean()\n",
        "                enh_avg = enh_metrics.mean()\n",
        "\n",
        "                config = CHARGED_PROTEINS.get(pdb_code, {})\n",
        "\n",
        "                data_for_viz.append({\n",
        "                    'pdb_code': pdb_code,\n",
        "                    'charged_residues': config.get('charged_residues', 0),\n",
        "                    'num_chains': len(config.get('designed_chains', [])) + len(config.get('fixed_chains', [])),\n",
        "                    'std_recovery': std_avg['sequence_recovery'],\n",
        "                    'enh_recovery': enh_avg['sequence_recovery'],\n",
        "                    'std_charged_recovery': std_avg['charged_recovery'],\n",
        "                    'enh_charged_recovery': enh_avg['charged_recovery'],\n",
        "                    'std_electrostatic': std_avg['electrostatic_score'],\n",
        "                    'enh_electrostatic': enh_avg['electrostatic_score'],\n",
        "                    'std_score': std_avg['score'],\n",
        "                    'enh_score': enh_avg['score'],\n",
        "                    'std_perplexity': std_avg['perplexity'],\n",
        "                    'enh_perplexity': enh_avg['perplexity'],\n",
        "                    'recovery_improvement': enh_avg['sequence_recovery'] - std_avg['sequence_recovery'],\n",
        "                    'charged_improvement': enh_avg['charged_recovery'] - std_avg['charged_recovery'],\n",
        "                    'electrostatic_improvement': enh_avg['electrostatic_score'] - std_avg['electrostatic_score']\n",
        "                })\n",
        "\n",
        "    if not data_for_viz:\n",
        "        print(\"No valid data for visualization\")\n",
        "        return\n",
        "\n",
        "    df = pd.DataFrame(data_for_viz)\n",
        "\n",
        "    # Create comprehensive dashboard\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
        "    fig.suptitle('Enhanced ProteinMPNN Comprehensive Evaluation Dashboard', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Overall Recovery Comparison\n",
        "    x_pos = np.arange(len(df))\n",
        "    width = 0.35\n",
        "\n",
        "    axes[0,0].bar(x_pos - width/2, df['std_recovery'], width, label='Standard', alpha=0.8, color='#3498DB')\n",
        "    axes[0,0].bar(x_pos + width/2, df['enh_recovery'], width, label='Enhanced', alpha=0.8, color='#E74C3C')\n",
        "    axes[0,0].set_title('Sequence Recovery Comparison')\n",
        "    axes[0,0].set_ylabel('Recovery Rate')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].tick_params(axis='x', rotation=90, labelsize=8)\n",
        "    axes[0,0].set_xticks(x_pos)\n",
        "    axes[0,0].set_xticklabels(df['pdb_code'])\n",
        "\n",
        "    # 2. Recovery Improvements\n",
        "    colors = ['#27AE60' if x > 0 else '#E74C3C' if x < -0.01 else '#F39C12' for x in df['recovery_improvement']]\n",
        "    bars = axes[0,1].bar(df['pdb_code'], df['recovery_improvement'], color=colors, alpha=0.8)\n",
        "    axes[0,1].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
        "    axes[0,1].set_title('Recovery Improvement per Protein')\n",
        "    axes[0,1].set_ylabel('Recovery Δ')\n",
        "    axes[0,1].tick_params(axis='x', rotation=90, labelsize=8)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, val in zip(bars, df['recovery_improvement']):\n",
        "        height = bar.get_height()\n",
        "        axes[0,1].text(bar.get_x() + bar.get_width()/2., height + (0.002 if height >= 0 else -0.005),\n",
        "                       f'{val:.3f}', ha='center', va='bottom' if height >= 0 else 'top', fontsize=7)\n",
        "\n",
        "    # 3. Charged Residue Recovery\n",
        "    axes[0,2].bar(x_pos - width/2, df['std_charged_recovery'], width, label='Standard', alpha=0.8, color='#3498DB')\n",
        "    axes[0,2].bar(x_pos + width/2, df['enh_charged_recovery'], width, label='Enhanced', alpha=0.8, color='#E74C3C')\n",
        "    axes[0,2].set_title('Charged Residue Recovery')\n",
        "    axes[0,2].set_ylabel('Charged Recovery Rate')\n",
        "    axes[0,2].legend()\n",
        "    axes[0,2].tick_params(axis='x', rotation=90, labelsize=8)\n",
        "    axes[0,2].set_xticks(x_pos)\n",
        "    axes[0,2].set_xticklabels(df['pdb_code'])\n",
        "\n",
        "    # 4. Electrostatic Score\n",
        "    axes[1,0].bar(x_pos - width/2, df['std_electrostatic'], width, label='Standard', alpha=0.8, color='#3498DB')\n",
        "    axes[1,0].bar(x_pos + width/2, df['enh_electrostatic'], width, label='Enhanced', alpha=0.8, color='#E74C3C')\n",
        "    axes[1,0].set_title('Electrostatic Compatibility Score')\n",
        "    axes[1,0].set_ylabel('Electrostatic Score')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].tick_params(axis='x', rotation=90, labelsize=8)\n",
        "    axes[1,0].set_xticks(x_pos)\n",
        "    axes[1,0].set_xticklabels(df['pdb_code'])\n",
        "\n",
        "    # 5. Charged Improvement vs Protein Complexity\n",
        "    scatter = axes[1,1].scatter(df['charged_residues'], df['charged_improvement'],\n",
        "                               c=df['recovery_improvement'], cmap='RdYlGn', alpha=0.7, s=60)\n",
        "    axes[1,1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "    axes[1,1].set_title('Charged Recovery Improvement vs Complexity')\n",
        "    axes[1,1].set_xlabel('Number of Charged Residues')\n",
        "    axes[1,1].set_ylabel('Charged Recovery Δ')\n",
        "    plt.colorbar(scatter, ax=axes[1,1], label='Recovery Improvement')\n",
        "\n",
        "    # 6. Score Comparison\n",
        "    axes[1,2].bar(x_pos - width/2, df['std_score'], width, label='Standard', alpha=0.8, color='#3498DB')\n",
        "    axes[1,2].bar(x_pos + width/2, df['enh_score'], width, label='Enhanced', alpha=0.8, color='#E74C3C')\n",
        "    axes[1,2].set_title('Model Score Comparison')\n",
        "    axes[1,2].set_ylabel('Average Score')\n",
        "    axes[1,2].legend()\n",
        "    axes[1,2].tick_params(axis='x', rotation=90, labelsize=8)\n",
        "    axes[1,2].set_xticks(x_pos)\n",
        "    axes[1,2].set_xticklabels(df['pdb_code'])\n",
        "\n",
        "    # 7. Perplexity Comparison\n",
        "    if df['std_perplexity'].sum() > 0:\n",
        "        axes[2,0].bar(x_pos - width/2, df['std_perplexity'], width, label='Standard', alpha=0.8, color='#3498DB')\n",
        "        axes[2,0].bar(x_pos + width/2, df['enh_perplexity'], width, label='Enhanced', alpha=0.8, color='#E74C3C')\n",
        "        axes[2,0].set_title('Perplexity Comparison')\n",
        "        axes[2,0].set_ylabel('Perplexity (Lower is Better)')\n",
        "        axes[2,0].legend()\n",
        "        axes[2,0].tick_params(axis='x', rotation=90, labelsize=8)\n",
        "        axes[2,0].set_xticks(x_pos)\n",
        "        axes[2,0].set_xticklabels(df['pdb_code'])\n",
        "\n",
        "    # 8. Overall Performance Heatmap\n",
        "    heatmap_data = df[['std_recovery', 'enh_recovery', 'std_charged_recovery',\n",
        "                       'enh_charged_recovery', 'recovery_improvement']].T\n",
        "    heatmap_data.columns = df['pdb_code']\n",
        "\n",
        "    im = axes[2,1].imshow(heatmap_data.values, aspect='auto', cmap='RdYlGn')\n",
        "    axes[2,1].set_title('Performance Heatmap')\n",
        "    axes[2,1].set_yticks(range(len(heatmap_data.index)))\n",
        "    axes[2,1].set_yticklabels(['Std Rec', 'Enh Rec', 'Std Charged', 'Enh Charged', 'Improvement'])\n",
        "    axes[2,1].set_xticks(range(len(df)))\n",
        "    axes[2,1].set_xticklabels(df['pdb_code'], rotation=90, fontsize=8)\n",
        "    plt.colorbar(im, ax=axes[2,1])\n",
        "\n",
        "    # 9. Summary Statistics\n",
        "    axes[2,2].axis('off')\n",
        "    summary_stats = f\"\"\"\n",
        "    SUMMARY STATISTICS\n",
        "    ==================\n",
        "    Total Proteins: {len(df)}\n",
        "\n",
        "    Average Recovery Improvement: {df['recovery_improvement'].mean():.4f}\n",
        "    Std Dev: {df['recovery_improvement'].std():.4f}\n",
        "\n",
        "    Proteins Improved: {(df['recovery_improvement'] > 0).sum()}/{len(df)}\n",
        "    Proteins Degraded: {(df['recovery_improvement'] < -0.01).sum()}/{len(df)}\n",
        "\n",
        "    Charged Recovery Improvement: {df['charged_improvement'].mean():.4f}\n",
        "    Electrostatic Improvement: {df['electrostatic_improvement'].mean():.4f}\n",
        "\n",
        "    Best Improvement: {df.loc[df['recovery_improvement'].idxmax(), 'pdb_code']}\n",
        "    ({df['recovery_improvement'].max():.4f})\n",
        "\n",
        "    Worst Performance: {df.loc[df['recovery_improvement'].idxmin(), 'pdb_code']}\n",
        "    ({df['recovery_improvement'].min():.4f})\n",
        "    \"\"\"\n",
        "    axes[2,2].text(0.1, 0.9, summary_stats, transform=axes[2,2].transAxes,\n",
        "                   verticalalignment='top', fontfamily='monospace', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return df\n",
        "\n",
        "# ============================================================================\n",
        "# Main Processing Functions\n",
        "# ============================================================================\n",
        "\n",
        "def get_pdb_file(pdb_code, dest_dir=\".\", overwrite=False):\n",
        "    \"\"\"Download PDB file with error handling\"\"\"\n",
        "    if not pdb_code:\n",
        "        return None\n",
        "\n",
        "    pdb_path = f\"{dest_dir}/{pdb_code}.pdb\"\n",
        "    if os.path.exists(pdb_path) and not overwrite:\n",
        "        return pdb_path\n",
        "\n",
        "    # Try multiple URLs\n",
        "    urls = [\n",
        "        f\"https://files.rcsb.org/download/{pdb_code.lower()}.pdb\",\n",
        "        f\"https://files.rcsb.org/view/{pdb_code}.pdb\"\n",
        "    ]\n",
        "\n",
        "    for url in urls:\n",
        "        try:\n",
        "            urllib.request.urlretrieve(url, pdb_path)\n",
        "            return pdb_path\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    print(f\"❌ Failed to download {pdb_code}\")\n",
        "    return None\n",
        "\n",
        "def process_protein_pair(pdb_code, config, standard_model, enhanced_model, num_sequences=4):\n",
        "    \"\"\"Process single protein with both models\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"PROCESSING {pdb_code} - {config['charged_residues']} charged residues\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    results = {\n",
        "        'pdb_code': pdb_code,\n",
        "        'standard': {'sequences': [], 'scores': [], 'recovery_rates': [], 'perplexities': []},\n",
        "        'enhanced': {'sequences': [], 'scores': [], 'recovery_rates': [], 'perplexities': []}\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Download and parse PDB\n",
        "        pdb_path = get_pdb_file(pdb_code)\n",
        "        if not pdb_path:\n",
        "            print(f\"❌ Could not download {pdb_code}\")\n",
        "            return None\n",
        "\n",
        "        chain_list = config['designed_chains'] + config['fixed_chains']\n",
        "        pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "\n",
        "        if not pdb_dict_list:\n",
        "            print(f\"❌ Failed to parse PDB for {pdb_code}\")\n",
        "            return None\n",
        "\n",
        "        dataset = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=20000)\n",
        "        chain_id_dict = {pdb_dict_list[0]['name']: (config['designed_chains'], config['fixed_chains'])}\n",
        "\n",
        "        print(f\"Chains: designed={config['designed_chains']}, fixed={config['fixed_chains']}\")\n",
        "\n",
        "        # Set context for enhanced model\n",
        "        enhanced_model.set_structure_context(pdb_path, chain_list)\n",
        "\n",
        "        # Process with both models\n",
        "        models = [('standard', standard_model), ('enhanced', enhanced_model)]\n",
        "\n",
        "        for model_name, model in models:\n",
        "            print(f\"\\n🔥 Processing with {model_name} model...\")\n",
        "\n",
        "            try:\n",
        "                for protein in dataset:\n",
        "                    batch = [copy.deepcopy(protein)]\n",
        "\n",
        "                    # Setup featurization\n",
        "                    features = tied_featurize(\n",
        "                        batch, device, chain_id_dict, None, None, None, None, None\n",
        "                    )\n",
        "\n",
        "                    (X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list,\n",
        "                     visible_list_list, masked_list_list, masked_chain_length_list_list,\n",
        "                     chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask,\n",
        "                     tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all,\n",
        "                     bias_by_res_all, tied_beta) = features\n",
        "\n",
        "                    # Native scoring\n",
        "                    randn = torch.randn(chain_M.shape, device=device)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        log_probs = model(X, S, mask, chain_M*chain_M_pos, residue_idx,\n",
        "                                        chain_encoding_all, randn)\n",
        "\n",
        "                        mask_for_loss = mask * chain_M * chain_M_pos\n",
        "                        scores = _scores(S, log_probs, mask_for_loss)\n",
        "                        native_score = scores.cpu().data.numpy().mean()\n",
        "\n",
        "                    results[model_name]['native_score'] = float(native_score)\n",
        "                    print(f\"✅ {model_name} native score: {native_score:.4f}\")\n",
        "\n",
        "                    # Generate sequences\n",
        "                    for seq_num in range(num_sequences):\n",
        "                        randn = torch.randn(chain_M.shape, device=device)\n",
        "\n",
        "                        with torch.no_grad():\n",
        "                            # Sample sequence\n",
        "                            sample_dict = model.sample(\n",
        "                                X, randn, S, chain_M, chain_encoding_all, residue_idx,\n",
        "                                mask=mask, temperature=0.1,\n",
        "                                omit_AAs_np=np.array([False]*20 + [True]),\n",
        "                                bias_AAs_np=np.zeros(21),\n",
        "                                chain_M_pos=chain_M_pos, omit_AA_mask=omit_AA_mask,\n",
        "                                pssm_coef=pssm_coef, pssm_bias=pssm_bias,\n",
        "                                pssm_multi=0.0, pssm_log_odds_flag=False,\n",
        "                                pssm_log_odds_mask=(pssm_log_odds_all > 0.0).float(),\n",
        "                                pssm_bias_flag=False, bias_by_res=bias_by_res_all\n",
        "                            )\n",
        "\n",
        "                            S_sample = sample_dict[\"S\"]\n",
        "\n",
        "                            # Score sampled sequence\n",
        "                            log_probs_sample = model(\n",
        "                                X, S_sample, mask, chain_M*chain_M_pos, residue_idx,\n",
        "                                chain_encoding_all, randn,\n",
        "                                use_input_decoding_order=True,\n",
        "                                decoding_order=sample_dict[\"decoding_order\"]\n",
        "                            )\n",
        "\n",
        "                            scores = _scores(S_sample, log_probs_sample, mask_for_loss)\n",
        "                            score_value = scores.cpu().data.numpy()[0]\n",
        "\n",
        "                            # Calculate perplexity\n",
        "                            target_log_probs = torch.gather(log_probs_sample, -1, S_sample.unsqueeze(-1)).squeeze(-1)\n",
        "                            masked_log_probs = target_log_probs * mask_for_loss[0]\n",
        "                            avg_log_prob = masked_log_probs.sum() / (mask_for_loss[0].sum() + 1e-8)\n",
        "                            perplexity = torch.exp(-avg_log_prob).item()\n",
        "\n",
        "                            # Recovery calculation\n",
        "                            seq_recovery_rate = torch.sum(\n",
        "                                torch.sum(torch.nn.functional.one_hot(S[0], 21) *\n",
        "                                         torch.nn.functional.one_hot(S_sample[0], 21), axis=-1) *\n",
        "                                mask_for_loss[0]\n",
        "                            ) / torch.sum(mask_for_loss[0])\n",
        "\n",
        "                            # Convert sequences\n",
        "                            seq = _S_to_seq(S_sample[0], chain_M[0])\n",
        "                            native_seq = _S_to_seq(S[0], chain_M[0])\n",
        "\n",
        "                            # Store results\n",
        "                            results[model_name]['sequences'].append(seq)\n",
        "                            results[model_name]['scores'].append(float(score_value))\n",
        "                            results[model_name]['recovery_rates'].append(float(seq_recovery_rate.detach().cpu().numpy()))\n",
        "                            results[model_name]['perplexities'].append(float(perplexity))\n",
        "\n",
        "                            if 'native_sequence' not in results[model_name]:\n",
        "                                results[model_name]['native_sequence'] = native_seq\n",
        "\n",
        "                            print(f\"✅ {model_name} seq {seq_num+1}: Recovery={seq_recovery_rate:.3f}, \"\n",
        "                                  f\"Score={score_value:.4f}, Perplexity={perplexity:.2f}\")\n",
        "\n",
        "                    break  # Only process first protein in dataset\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ {model_name} model failed: {e}\")\n",
        "                continue\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Complete failure for {pdb_code}: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    print(\"🚀 ENHANCED PROTEINMPNN - COMPREHENSIVE CHARGED PROTEIN EVALUATION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Initialize components\n",
        "    apbs_handler = SimpleAPBSHandler()\n",
        "\n",
        "    print(\"\\n📥 Loading ProteinMPNN weights...\")\n",
        "    model_name = \"v_48_020\"\n",
        "    path_to_weights = '/content/ProteinMPNN/vanilla_model_weights'\n",
        "    checkpoint_path = f'{path_to_weights}/{model_name}.pt'\n",
        "\n",
        "    # Download weights if needed\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        os.makedirs(path_to_weights, exist_ok=True)\n",
        "        urllib.request.urlretrieve(\n",
        "            f\"https://github.com/dauparas/ProteinMPNN/raw/main/vanilla_model_weights/{model_name}.pt\",\n",
        "            checkpoint_path\n",
        "        )\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    # Create models\n",
        "    standard_model = ProteinMPNN(\n",
        "        num_letters=21, node_features=128, edge_features=128, hidden_dim=128,\n",
        "        num_encoder_layers=3, num_decoder_layers=3, augment_eps=0.0,\n",
        "        k_neighbors=checkpoint['num_edges']\n",
        "    ).to(device)\n",
        "\n",
        "    standard_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    standard_model.eval()\n",
        "    print(\"✅ Standard ProteinMPNN loaded\")\n",
        "\n",
        "    # Create enhanced model with conservative enhancement\n",
        "    enhanced_model = ConservativeEnhancedProteinMPNN(\n",
        "        apbs_handler=apbs_handler, enhancement_weight=0.02,  # Very small enhancement\n",
        "        num_letters=21, node_features=128, edge_features=128, hidden_dim=128,\n",
        "        num_encoder_layers=3, num_decoder_layers=3, augment_eps=0.0,\n",
        "        k_neighbors=checkpoint['num_edges']\n",
        "    ).to(device)\n",
        "\n",
        "    enhanced_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    enhanced_model.eval()\n",
        "    print(\"✅ Conservative Enhanced ProteinMPNN loaded\")\n",
        "\n",
        "    # Process charged proteins\n",
        "    print(f\"\\n🧬 Processing {len(CHARGED_PROTEINS)} charged protein complexes...\")\n",
        "\n",
        "    all_results = {}\n",
        "    processed = 0\n",
        "    failed = 0\n",
        "\n",
        "    for pdb_code, config in tqdm(list(CHARGED_PROTEINS.items())[:10], desc=\"Processing proteins\"):  # Start with first 10\n",
        "        try:\n",
        "            result = process_protein_pair(pdb_code, config, standard_model, enhanced_model, num_sequences=3)\n",
        "\n",
        "            if result and result['standard']['sequences'] and result['enhanced']['sequences']:\n",
        "                all_results[pdb_code] = result\n",
        "                processed += 1\n",
        "\n",
        "                # Quick comparison\n",
        "                std_recovery = np.mean(result['standard']['recovery_rates'])\n",
        "                enh_recovery = np.mean(result['enhanced']['recovery_rates'])\n",
        "                improvement = enh_recovery - std_recovery\n",
        "\n",
        "                status = \"✅\" if improvement > 0 else \"⚠️\" if improvement > -0.01 else \"❌\"\n",
        "                print(f\"{status} {pdb_code}: {std_recovery:.3f} → {enh_recovery:.3f} ({improvement:+.3f})\")\n",
        "            else:\n",
        "                failed += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to process {pdb_code}: {e}\")\n",
        "            failed += 1\n",
        "\n",
        "        # Progress update every 5 proteins\n",
        "        if (processed + failed) % 5 == 0:\n",
        "            print(f\"\\n📊 Progress: {processed} processed, {failed} failed\")\n",
        "\n",
        "    # Create comprehensive dashboard\n",
        "    if all_results:\n",
        "        print(f\"\\n📊 Creating comprehensive dashboard...\")\n",
        "        results_df = create_comprehensive_dashboard(all_results)\n",
        "\n",
        "        # Final summary\n",
        "        print(f\"\\n\" + \"=\"*80)\n",
        "        print(\"📊 FINAL EVALUATION SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if results_df is not None and not results_df.empty:\n",
        "            avg_improvement = results_df['recovery_improvement'].mean()\n",
        "            std_improvement = results_df['recovery_improvement'].std()\n",
        "            improved_count = (results_df['recovery_improvement'] > 0).sum()\n",
        "            total_count = len(results_df)\n",
        "\n",
        "            print(f\"Total proteins evaluated: {total_count}\")\n",
        "            print(f\"Average recovery improvement: {avg_improvement:+.4f} ± {std_improvement:.4f}\")\n",
        "            print(f\"Proteins with improvement: {improved_count}/{total_count} ({improved_count/total_count*100:.1f}%)\")\n",
        "\n",
        "            # Statistical test\n",
        "            if total_count >= 5:\n",
        "                from scipy.stats import ttest_1samp\n",
        "                t_stat, p_value = ttest_1samp(results_df['recovery_improvement'], 0)\n",
        "                print(f\"Statistical significance (t-test): p = {p_value:.4f}\")\n",
        "\n",
        "                if p_value < 0.05:\n",
        "                    print(\"🎯 STATISTICALLY SIGNIFICANT improvement!\")\n",
        "                else:\n",
        "                    print(\"⚠️ No statistically significant improvement\")\n",
        "\n",
        "            # Recommendations\n",
        "            if avg_improvement > 0.01:\n",
        "                print(\"🏆 SUCCESS: Enhanced model shows meaningful improvement!\")\n",
        "            elif avg_improvement > 0:\n",
        "                print(\"✅ MODEST: Small but consistent improvement\")\n",
        "            else:\n",
        "                print(\"❌ NEEDS WORK: Enhancement is not effective\")\n",
        "\n",
        "    else:\n",
        "        print(\"❌ No successful results to analyze\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# Execute\n",
        "if __name__ == \"__main__\":\n",
        "    results = main()\n",
        "    print(\"\\n🎉 Comprehensive evaluation complete!\")"
      ],
      "metadata": {
        "id": "qLDajPwM4pf0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}