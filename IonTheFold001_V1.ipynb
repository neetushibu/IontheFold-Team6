{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neetushibu/IontheFold-Team6/blob/main/IonTheFold001_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ProteinMPNN Baseline Evaluation for Ion the Fold Project"
      ],
      "metadata": {
        "id": "ek2oyWrRgFfK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8VjC23Az1_B",
        "outputId": "d8209c4b-906f-4a73-a47a-2a268c48a207",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Aug 22 15:21:26 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0             48W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 1: Install Dependencies and Setup\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    packages = [\n",
        "        'plotly', 'seaborn', 'biopython', 'matplotlib', 'pandas', 'numpy', 'scipy'\n",
        "    ]\n",
        "    for package in packages:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "\n",
        "install_packages()\n",
        "print(\"✅ All packages installed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqL_u6EtbSP2",
        "outputId": "97ca8d50-095e-41a4-d531-97d7c82f4a97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All packages installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 2: Clone Repository and Import Libraries\n",
        "import json, time, os, sys, glob\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import subprocess # Import subprocess\n",
        "\n",
        "proteinmpnn_path = '/content/ProteinMPNN'\n",
        "\n",
        "if not os.path.isdir(proteinmpnn_path):\n",
        "    print(f\"Cloning ProteinMPNN repository into {proteinmpnn_path}...\")\n",
        "    # Use subprocess for better control and error handling\n",
        "    try:\n",
        "        subprocess.run([\"git\", \"clone\", \"-q\", \"https://github.com/dauparas/ProteinMPNN.git\", proteinmpnn_path], check=True)\n",
        "        print(\"✅ ProteinMPNN repository cloned successfully!\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"❌ Error cloning repository: {e}\")\n",
        "        # Exit or raise an error if cloning fails critically\n",
        "        # sys.exit(\"Failed to clone ProteinMPNN repository.\") # Or just print error and continue if possible\n",
        "else:\n",
        "    print(f\"ProteinMPNN directory already exists at {proteinmpnn_path}. Skipping cloning.\")\n",
        "\n",
        "\n",
        "# Ensure the cloned directory is in the system path\n",
        "if proteinmpnn_path not in sys.path:\n",
        "    sys.path.append(proteinmpnn_path)\n",
        "    print(f\"Added {proteinmpnn_path} to sys.path\")\n",
        "\n",
        "# Verify if the module can be imported\n",
        "try:\n",
        "    import protein_mpnn_utils\n",
        "    print(\"✅ Successfully imported protein_mpnn_utils!\")\n",
        "except ModuleNotFoundError as e:\n",
        "    print(f\"❌ ModuleNotFoundError after cloning and path update: {e}\")\n",
        "    print(\"Please check if the /content/ProteinMPNN directory exists and contains protein_mpnn_utils.py\")\n",
        "    # You might want to add steps here to help the user diagnose further\n",
        "    # For example, list directory contents: !ls /content/ProteinMPNN\n",
        "\n",
        "# Import remaining libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from scipy import stats\n",
        "from collections import defaultdict, Counter\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "# Re-import the necessary functions from protein_mpnn_utils after confirming it's available\n",
        "# This ensures these functions are available in the global scope of this cell\n",
        "try:\n",
        "    from protein_mpnn_utils import (\n",
        "        loss_nll, loss_smoothed, gather_edges, gather_nodes,\n",
        "        gather_nodes_t, cat_neighbors_nodes, _scores, _S_to_seq,\n",
        "        tied_featurize, parse_PDB, StructureDataset,\n",
        "        StructureDatasetPDB, ProteinMPNN\n",
        "    )\n",
        "    print(\"✅ protein_mpnn_utils functions imported!\")\n",
        "except ModuleNotFoundError as e:\n",
        "     print(f\"❌ Failed to import protein_mpnn_utils functions: {e}\")\n",
        "     print(\"This indicates a persistent issue with finding the module.\")\n",
        "\n",
        "\n",
        "print(\"✅ Repository setup and libraries imported!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7uZNj7jbVw8",
        "outputId": "152d561a-668d-4a45-d462-bea50b2c9a0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning ProteinMPNN repository into /content/ProteinMPNN...\n",
            "✅ ProteinMPNN repository cloned successfully!\n",
            "Added /content/ProteinMPNN to sys.path\n",
            "✅ Successfully imported protein_mpnn_utils!\n",
            "✅ protein_mpnn_utils functions imported!\n",
            "✅ Repository setup and libraries imported!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 3: Setup Model and Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Model configuration\n",
        "model_name = \"v_48_020\"  # Options: v_48_002, v_48_010, v_48_020, v_48_030\n",
        "backbone_noise = 0.00\n",
        "\n",
        "# Load model\n",
        "path_to_model_weights = '/content/ProteinMPNN/vanilla_model_weights'\n",
        "hidden_dim = 128\n",
        "num_layers = 3\n",
        "model_folder_path = path_to_model_weights\n",
        "if model_folder_path[-1] != '/':\n",
        "    model_folder_path = model_folder_path + '/'\n",
        "checkpoint_path = model_folder_path + f'{model_name}.pt'\n",
        "\n",
        "try:\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    print('Number of edges:', checkpoint['num_edges'])\n",
        "    print(f'Training noise level: {checkpoint[\"noise_level\"]}A')\n",
        "\n",
        "    model = ProteinMPNN(\n",
        "        num_letters=21,\n",
        "        node_features=hidden_dim,\n",
        "        edge_features=hidden_dim,\n",
        "        hidden_dim=hidden_dim,\n",
        "        num_encoder_layers=num_layers,\n",
        "        num_decoder_layers=num_layers,\n",
        "        augment_eps=backbone_noise,\n",
        "        k_neighbors=checkpoint['num_edges']\n",
        "    )\n",
        "    model.to(device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    print(\"✅ Model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading model: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "CZ7UXLZBbYOo",
        "outputId": "41221658-eca0-4637-8edd-a5da2208b968"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Number of edges: 48\n",
            "Training noise level: 0.2A\n",
            "✅ Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 4: Helper Functions\n",
        "def make_tied_positions_for_homomers(pdb_dict_list):\n",
        "    \"\"\"Create tied positions for homomer proteins\"\"\"\n",
        "    my_dict = {}\n",
        "    for result in pdb_dict_list:\n",
        "        all_chain_list = sorted([item[-1:] for item in list(result) if item[:9]=='seq_chain'])\n",
        "        tied_positions_list = []\n",
        "        chain_length = len(result[f\"seq_chain_{all_chain_list[0]}\"])\n",
        "        for i in range(1, chain_length+1):\n",
        "            temp_dict = {}\n",
        "            for j, chain in enumerate(all_chain_list):\n",
        "                temp_dict[chain] = [i]\n",
        "            tied_positions_list.append(temp_dict)\n",
        "        my_dict[result['name']] = tied_positions_list\n",
        "    return my_dict\n",
        "\n",
        "\n",
        "def get_pdb_file(pdb_code, dest_dir=\".\", overwrite=False, allow_upload=True):\n",
        "    \"\"\"\n",
        "    Returns a local path to a plain .pdb file.\n",
        "    Tries:\n",
        "      1) https://files.rcsb.org/download/<code>.pdb\n",
        "      2) https://files.rcsb.org/pub/pdb/data/structures/divided/pdb/<code[1:3]>/pdb<code>.ent.gz (then gunzip)\n",
        "    If pdb_code is empty and allow_upload=True, prompts for upload in Google Colab.\n",
        "    \"\"\"\n",
        "    import os, urllib.request, gzip, shutil\n",
        "    from urllib.error import HTTPError, URLError\n",
        "\n",
        "    code = (pdb_code or \"\").strip()\n",
        "    if not code:\n",
        "        if not allow_upload:\n",
        "            raise ValueError(\"pdb_code is empty and uploads are disabled.\")\n",
        "        # Colab upload path\n",
        "        try:\n",
        "            from google.colab import files\n",
        "        except Exception:\n",
        "            raise RuntimeError(\"Upload only works in Google Colab. Provide a pdb_code or run in Colab.\")\n",
        "        print(\"Please upload a PDB file:\")\n",
        "        upload_dict = files.upload()\n",
        "        name, data = next(iter(upload_dict.items()))\n",
        "        out_path = os.path.join(dest_dir, name if name.lower().endswith(\".pdb\") else \"tmp.pdb\")\n",
        "        with open(out_path, \"wb\") as f:\n",
        "            f.write(data)\n",
        "        return out_path\n",
        "\n",
        "    code_l = code.lower()\n",
        "    code_u = code.upper()\n",
        "    out_path = os.path.join(dest_dir, f\"{code_u}.pdb\")\n",
        "\n",
        "    if os.path.exists(out_path) and not overwrite:\n",
        "        print(f\"✔ Using existing file: {out_path}\")\n",
        "        return out_path\n",
        "\n",
        "    # 1) Try direct .pdb\n",
        "    url1 = f\"https://files.rcsb.org/download/{code_l}.pdb\"\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url1, out_path)\n",
        "        print(f\"✅ Downloaded {code_u} from {url1}\")\n",
        "        return out_path\n",
        "    except (HTTPError, URLError) as e1:\n",
        "        # 2) Fallback: divided gz path (need to compute subfolder and gunzip)\n",
        "        subdir = code_l[1:3]  # 2nd–3rd characters\n",
        "        url2 = f\"https://files.rcsb.org/pub/pdb/data/structures/divided/pdb/{subdir}/pdb{code_l}.ent.gz\"\n",
        "        gz_path = os.path.join(dest_dir, f\"pdb{code_l}.ent.gz\")\n",
        "        try:\n",
        "            urllib.request.urlretrieve(url2, gz_path)\n",
        "            with gzip.open(gz_path, \"rb\") as f_in, open(out_path, \"wb\") as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "            os.remove(gz_path)\n",
        "            print(f\"✅ Downloaded and decompressed {code_u} from {url2}\")\n",
        "            return out_path\n",
        "        except (HTTPError, URLError, OSError) as e2:\n",
        "            if os.path.exists(gz_path):\n",
        "                try: os.remove(gz_path)\n",
        "                except: pass\n",
        "            print(f\"❌ Could not download {code_u}.\\n - {url1} error: {e1}\\n - {url2} error: {e2}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "\n",
        "def analyze_amino_acid_composition(sequences, labels=None):\n",
        "    \"\"\"Analyze amino acid composition of sequences\"\"\"\n",
        "    if labels is None:\n",
        "        labels = [f\"Seq_{i}\" for i in range(len(sequences))]\n",
        "\n",
        "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "    composition_data = []\n",
        "\n",
        "    for seq, label in zip(sequences, labels):\n",
        "        clean_seq = seq.replace('/', '').replace('X', '')  # Remove separators and unknown\n",
        "        total_length = len(clean_seq)\n",
        "\n",
        "        for aa in amino_acids:\n",
        "            count = clean_seq.count(aa)\n",
        "            percentage = (count / total_length) * 100 if total_length > 0 else 0\n",
        "            composition_data.append({\n",
        "                'Sequence': label,\n",
        "                'Amino_Acid': aa,\n",
        "                'Count': count,\n",
        "                'Percentage': percentage\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(composition_data)\n",
        "\n",
        "def calculate_sequence_metrics(native_seq, designed_seqs, scores):\n",
        "    \"\"\"Calculate comprehensive sequence metrics\"\"\"\n",
        "    metrics = {\n",
        "        'sequence_recovery': [],\n",
        "        'identity': [],\n",
        "        'score': [],\n",
        "        'length': [],\n",
        "        'charged_residue_recovery': [],\n",
        "        'hydrophobic_recovery': []\n",
        "    }\n",
        "\n",
        "    native_clean = native_seq.replace('/', '').replace('X', '')\n",
        "    charged_residues = set('DEKR')\n",
        "    hydrophobic_residues = set('AILMFPWY')\n",
        "\n",
        "    for designed_seq, score in zip(designed_seqs, scores):\n",
        "        designed_clean = designed_seq.replace('/', '').replace('X', '')\n",
        "\n",
        "        # Basic metrics\n",
        "        length = min(len(native_clean), len(designed_clean))\n",
        "        if length == 0:\n",
        "            continue\n",
        "\n",
        "        identical = sum(1 for a, b in zip(native_clean[:length], designed_clean[:length]) if a == b)\n",
        "        identity = (identical / length) * 100\n",
        "\n",
        "        metrics['sequence_recovery'].append(identity)\n",
        "        metrics['identity'].append(identity)\n",
        "        metrics['score'].append(float(score))\n",
        "        metrics['length'].append(length)\n",
        "\n",
        "        # Charged residue recovery\n",
        "        native_charged_pos = [i for i, aa in enumerate(native_clean[:length]) if aa in charged_residues]\n",
        "        if native_charged_pos:\n",
        "            charged_recovery = sum(1 for pos in native_charged_pos\n",
        "                                 if pos < len(designed_clean) and designed_clean[pos] in charged_residues)\n",
        "            charged_recovery_rate = (charged_recovery / len(native_charged_pos)) * 100\n",
        "        else:\n",
        "            charged_recovery_rate = 0\n",
        "        metrics['charged_residue_recovery'].append(charged_recovery_rate)\n",
        "\n",
        "        # Hydrophobic recovery\n",
        "        native_hydrophobic_pos = [i for i, aa in enumerate(native_clean[:length]) if aa in hydrophobic_residues]\n",
        "        if native_hydrophobic_pos:\n",
        "            hydrophobic_recovery = sum(1 for pos in native_hydrophobic_pos\n",
        "                                     if pos < len(designed_clean) and designed_clean[pos] in hydrophobic_residues)\n",
        "            hydrophobic_recovery_rate = (hydrophobic_recovery / len(native_hydrophobic_pos)) * 100\n",
        "        else:\n",
        "            hydrophobic_recovery_rate = 0\n",
        "        metrics['hydrophobic_recovery'].append(hydrophobic_recovery_rate)\n",
        "\n",
        "    return pd.DataFrame(metrics)\n",
        "\n",
        "print(\"✅ Helper functions defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oyDxWwLbc71",
        "outputId": "789cf3c3-3c04-46e8-8c17-116fad4fbddc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Helper functions defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 5: Configuration and Input Setup\n",
        "\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "pdb_codes = ['3JAY', # 5 chains, 919 charged residues\n",
        "             '3JB0', # 5 chains, 919 charged residues\n",
        "             '5A1A', # 4 chains, 984 charged residues\n",
        "             '5FTJ', # 6 chains, 1326 charged residues\n",
        "             '5FTK', # 6 chains, 1326 charged residues\n",
        "             '5K12', # 6 chains, 474 charged residues\n",
        "             '5L35', # 7 chains, 511 charged residues\n",
        "             '5MDO', # 6 chains, 468 charged residues\n",
        "             '5MDR', # 12 chains, 468 charged residues\n",
        "             '5MF4', # 6 chains, 566 charged residues\n",
        "             '5MFM', # 8 chains, 362 charged residues\n",
        "             '5MH6', # 4 chains, 350 charged residues\n",
        "             '5MHF', # 8 chains, 626 charged residues\n",
        "             '5MIW', # 6 chains, 342 charged residues\n",
        "             '5MJY', # 6 chains, 396 charged residues\n",
        "             '5MK1', # 8 chains, 393 charged residues\n",
        "             '5MK3', # 8 chains, 395 charged residues\n",
        "             '5MKM', # 6 chains, 442 charged residues\n",
        "             '5MKN', # 28 chains, 595 charged residues\n",
        "             '5MLD', # 8 chains, 584 charged residues\n",
        "             '5MNS', # 6 chains, 671 charged residues\n",
        "             '5MNV', # 9 chains, 977 charged residues\n",
        "             '5MQZ', # 6 chains, 469 charged residues\n",
        "             '5MR0', # 6 chains, 474 charged residues\n",
        "             '5MUX', # 6 chains, 822 charged residues\n",
        "             '5MX5', # 14 chains, 873 charged residues\n",
        "             '5MY0', # 4 chains, 722 charged residues\n",
        "             '5MY2', # 4 chains, 723 charged residues\n",
        "             '5MZ2', # 16 chains, 1125 charged residues\n",
        "             '5MZ5', # 4 chains, 532 charged residues\n",
        "             ]\n",
        "\n",
        "design_config = {'3JAY': {'designed_chains': ['B'], 'fixed_chains': ['A', 'C', 'D', 'E']},\n",
        "                 '3JB0': {'designed_chains': ['B'], 'fixed_chains': ['A', 'C', 'D', 'E']},\n",
        "                 '5A1A': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                 '5FTJ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                 '5FTK': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                 '5K12': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                 '5L35': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G']},\n",
        "                 '5MDO': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                 '5MDR': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                 '5MF4': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                 '5MFM': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                 '5MH6': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                 '5MHF': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                 '5MIW': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                 '5MJY': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                 '5MK1': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                 '5MK3': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                 '5MKM': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                 '5MKN': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'd']},\n",
        "                 '5MLD': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
        "                 '5MNS': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                 '5MNV': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']},\n",
        "                 '5MQZ': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                 '5MR0': {'designed_chains': ['F'], 'fixed_chains': ['A', 'B', 'C', 'D', 'E']},\n",
        "                 '5MUX': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F']},\n",
        "                 '5MX5': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N']},\n",
        "                 '5MY0': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                 '5MY2': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']},\n",
        "                 '5MZ2': {'designed_chains': ['A'], 'fixed_chains': ['C', 'H', 'F', 'D', 'B', 'E', 'G', 'I', 'O', 'L', 'N', 'M', 'P', 'J', 'K']},\n",
        "                 '5MZ5': {'designed_chains': ['A'], 'fixed_chains': ['B', 'C', 'D']}}\n",
        "\n",
        "# Design parameters\n",
        "num_seqs = 6\n",
        "sampling_temp = \"0.1\"\n",
        "homomer = False\n",
        "\n",
        "# Advanced configuration options\n",
        "batch_size = 1\n",
        "max_length = 20000\n",
        "omit_AAs = 'X'  # Omit unknown amino acids\n",
        "alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "omit_AAs_np = np.array([AA in omit_AAs for AA in alphabet]).astype(np.float32)\n",
        "\n",
        "print(f\"✅ Configured to process {len(pdb_codes)} proteins\")\n",
        "print(f\"✅ Will generate {num_seqs} sequences per protein\")\n",
        "print(f\"✅ Using sampling temperature: {sampling_temp}\")\n",
        "print()\n",
        "\n",
        "print(\"PROTEIN CONFIGURATION SUMMARY:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'PDB':<6} {'Chains':<12} {'Designed':<10} {'Fixed':<15} {'Charged Res':<12}\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "protein_data = {'3JAY': {'chains': 5, 'charged': 919},\n",
        "                              '3JB0': {'chains': 5, 'charged': 919},\n",
        "                              '5A1A': {'chains': 4, 'charged': 984},\n",
        "                              '5FTJ': {'chains': 6, 'charged': 1326},\n",
        "                              '5FTK': {'chains': 6, 'charged': 1326},\n",
        "                              '5K12': {'chains': 6, 'charged': 474},\n",
        "                              '5L35': {'chains': 7, 'charged': 511},\n",
        "                              '5MDO': {'chains': 6, 'charged': 468},\n",
        "                              '5MDR': {'chains': 12, 'charged': 468},\n",
        "                              '5MF4': {'chains': 6, 'charged': 566},\n",
        "                              '5MFM': {'chains': 8, 'charged': 362},\n",
        "                              '5MH6': {'chains': 4, 'charged': 350},\n",
        "                              '5MHF': {'chains': 8, 'charged': 626},\n",
        "                              '5MIW': {'chains': 6, 'charged': 342},\n",
        "                              '5MJY': {'chains': 6, 'charged': 396},\n",
        "                              '5MK1': {'chains': 8, 'charged': 393},\n",
        "                              '5MK3': {'chains': 8, 'charged': 395},\n",
        "                              '5MKM': {'chains': 6, 'charged': 442},\n",
        "                              '5MKN': {'chains': 28, 'charged': 595},\n",
        "                              '5MLD': {'chains': 8, 'charged': 584},\n",
        "                              '5MNS': {'chains': 6, 'charged': 671},\n",
        "                              '5MNV': {'chains': 9, 'charged': 977},\n",
        "                              '5MQZ': {'chains': 6, 'charged': 469},\n",
        "                              '5MR0': {'chains': 6, 'charged': 474},\n",
        "                              '5MUX': {'chains': 6, 'charged': 822},\n",
        "                              '5MX5': {'chains': 14, 'charged': 873},\n",
        "                              '5MY0': {'chains': 4, 'charged': 722},\n",
        "                              '5MY2': {'chains': 4, 'charged': 723},\n",
        "                              '5MZ2': {'chains': 16, 'charged': 1125},\n",
        "                              '5MZ5': {'chains': 4, 'charged': 532}\n",
        "                              }\n",
        "\n",
        "for pdb_code in pdb_codes:\n",
        "    if pdb_code in design_config:\n",
        "        config = design_config[pdb_code]\n",
        "        data = protein_data.get(pdb_code, {'chains': '?', 'charged': '?'})\n",
        "        designed_str = ', '.join(config['designed_chains'])\n",
        "        fixed_str = ', '.join(config['fixed_chains']) if config['fixed_chains'] else 'None'\n",
        "        print(f\"{pdb_code:<6} {data['chains']:<12} {designed_str:<10} {fixed_str:<15} {data['charged']:<12}\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print()\n",
        "\n",
        "print(\"🧪 TESTING RECOMMENDATIONS:\")\n",
        "print(\"1. Start with 2-3 proteins first to test the pipeline\")\n",
        "print(\"2. Recommended testing order:\")\n",
        "print(\"   - 9CDF (2 chains, 316 charged residues)\")\n",
        "print(\"   - 9IR2 (1 chain, 63 charged residues)\")\n",
        "print(\"3. Once working, add more proteins gradually\")\n",
        "print(\"4. For 8W2U (20 chains), you may need to specify exact chains later\")\n",
        "print()\n",
        "\n",
        "\n",
        "print(\"⚠️  IMPORTANT NOTES:\")\n",
        "print(\"- If any chain IDs are wrong, the notebook will tell you what chains exist\")\n",
        "print(\"- You can modify the design_config above based on those error messages\")\n",
        "print(\"- For complex multi-chain proteins, you may want to check PDB files manually\")\n",
        "print(\"- Start with fewer proteins and increase batch size once everything works\")\n",
        "\n",
        "print()\n",
        "print(\"🔍 VALIDATION CHECKLIST:\")\n",
        "print(\"- All proteins have reasonable chain configurations\")\n",
        "print(\"- Single chains are designed entirely\")\n",
        "print(\"- Multi-chain proteins have one designed, others fixed\")\n",
        "print(\"- Ready to run Cell 7 after this configuration\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RnJDKMkJbnZ7",
        "outputId": "59e43f11-3e73-4cfc-ed13-af6006a8743e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configured to process 30 proteins\n",
            "✅ Will generate 6 sequences per protein\n",
            "✅ Using sampling temperature: 0.1\n",
            "\n",
            "PROTEIN CONFIGURATION SUMMARY:\n",
            "============================================================\n",
            "PDB    Chains       Designed   Fixed           Charged Res \n",
            "------------------------------------------------------------\n",
            "3JAY   5            B          A, C, D, E      919         \n",
            "3JB0   5            B          A, C, D, E      919         \n",
            "5A1A   4            A          B, C, D         984         \n",
            "5FTJ   6            A          B, C, D, E, F   1326        \n",
            "5FTK   6            A          B, C, D, E, F   1326        \n",
            "5K12   6            A          B, C, D, E, F   474         \n",
            "5L35   7            A          B, C, D, E, F, G 511         \n",
            "5MDO   6            A          B, C, D, E, F   468         \n",
            "5MDR   12           A          B, C, D, E, F   468         \n",
            "5MF4   6            A          B, C, D, E, F   566         \n",
            "5MFM   8            A          B, C, D, E, F, G, H 362         \n",
            "5MH6   4            A          B, C, D         350         \n",
            "5MHF   8            A          B, C, D         626         \n",
            "5MIW   6            A          B, C, D, E, F   342         \n",
            "5MJY   6            A          B, C, D, E, F   396         \n",
            "5MK1   8            A          B, C, D, E, F, G, H 393         \n",
            "5MK3   8            A          B, C, D, E, F, G, H 395         \n",
            "5MKM   6            A          B, C, D, E, F   442         \n",
            "5MKN   28           A          B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, T, U, V, W, X, Y, Z, a, b, d 595         \n",
            "5MLD   8            A          B, C, D, E, F, G, H 584         \n",
            "5MNS   6            A          B, C, D, E, F   671         \n",
            "5MNV   9            A          B, C, D, E, F, G, H, I 977         \n",
            "5MQZ   6            A          B, C, D, E, F   469         \n",
            "5MR0   6            F          A, B, C, D, E   474         \n",
            "5MUX   6            A          B, C, D, E, F   822         \n",
            "5MX5   14           A          B, C, D, E, F, G, H, I, J, K, L, M, N 873         \n",
            "5MY0   4            A          B, C, D         722         \n",
            "5MY2   4            A          B, C, D         723         \n",
            "5MZ2   16           A          C, H, F, D, B, E, G, I, O, L, N, M, P, J, K 1125        \n",
            "5MZ5   4            A          B, C, D         532         \n",
            "============================================================\n",
            "\n",
            "🧪 TESTING RECOMMENDATIONS:\n",
            "1. Start with 2-3 proteins first to test the pipeline\n",
            "2. Recommended testing order:\n",
            "   - 9CDF (2 chains, 316 charged residues)\n",
            "   - 9IR2 (1 chain, 63 charged residues)\n",
            "3. Once working, add more proteins gradually\n",
            "4. For 8W2U (20 chains), you may need to specify exact chains later\n",
            "\n",
            "⚠️  IMPORTANT NOTES:\n",
            "- If any chain IDs are wrong, the notebook will tell you what chains exist\n",
            "- You can modify the design_config above based on those error messages\n",
            "- For complex multi-chain proteins, you may want to check PDB files manually\n",
            "- Start with fewer proteins and increase batch size once everything works\n",
            "\n",
            "🔍 VALIDATION CHECKLIST:\n",
            "- All proteins have reasonable chain configurations\n",
            "- Single chains are designed entirely\n",
            "- Multi-chain proteins have one designed, others fixed\n",
            "- Ready to run Cell 7 after this configuration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 6: Process Single Protein Function\n",
        "def process_single_protein(pdb_code, designed_chains, fixed_chains, num_sequences=4, temperature=0.1):\n",
        "    \"\"\"Process a single protein and return results\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Processing {pdb_code}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # Import necessary libraries and functions within the function\n",
        "    import numpy as np\n",
        "    import copy\n",
        "    import torch\n",
        "    import sys\n",
        "    try:\n",
        "        from protein_mpnn_utils import parse_PDB, StructureDatasetPDB, tied_featurize, _scores, _S_to_seq, ProteinMPNN, StructureDataset # Added ProteinMPNN and StructureDataset\n",
        "    except ModuleNotFoundError:\n",
        "        # Fallback/Diagnostic: If direct import fails, try adding path and importing again\n",
        "        proteinmpnn_path = '/content/ProteinMPNN'\n",
        "        if proteinmpnn_path not in sys.path:\n",
        "             sys.path.insert(0, proteinmpnn_path)\n",
        "             print(f\"Attempting to add {proteinmpnn_path} to sys.path from within function.\")\n",
        "        try:\n",
        "             from protein_mpnn_utils import parse_PDB, StructureDatasetPDB, tied_featurize, _scores, _S_to_seq, ProteinMPNN, StructureDataset # Added ProteinMPNN and StructureDataset\n",
        "             print(\"Successfully imported protein_mpnn_utils after adding path within function.\")\n",
        "        except ModuleNotFoundError:\n",
        "             print(f\"❌ Still unable to import protein_mpnn_utils even after adding path within function.\")\n",
        "             return None # Cannot proceed without the module\n",
        "\n",
        "\n",
        "    pdb_path = get_pdb_file(pdb_code)\n",
        "    if pdb_path is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Parse chains\n",
        "        chain_list = list(set(designed_chains + fixed_chains))\n",
        "\n",
        "        # Parse PDB\n",
        "        pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "        dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=max_length)\n",
        "\n",
        "        # Setup chain configuration\n",
        "        chain_id_dict = {pdb_dict_list[0]['name']: (designed_chains, fixed_chains)}\n",
        "\n",
        "        print(f\"Chain configuration: {chain_id_dict}\")\n",
        "        for chain in chain_list:\n",
        "            # Check if the chain exists in the parsed PDB data before accessing its length\n",
        "            if f\"seq_chain_{chain}\" in pdb_dict_list[0]:\n",
        "                l = len(pdb_dict_list[0][f\"seq_chain_{chain}\"])\n",
        "                print(f\"Length of chain {chain}: {l}\")\n",
        "            else:\n",
        "                print(f\"Warning: Chain {chain} not found in PDB file {pdb_code}.\")\n",
        "\n",
        "\n",
        "        # Setup tied positions if homomer\n",
        "        tied_positions_dict = None\n",
        "        if homomer:\n",
        "            tied_positions_dict = make_tied_positions_for_homomers(pdb_dict_list)\n",
        "\n",
        "        # Initialize parameters\n",
        "        NUM_BATCHES = num_sequences // batch_size\n",
        "        BATCH_COPIES = batch_size\n",
        "        temperatures = [temperature]\n",
        "\n",
        "        # Initialize dictionaries\n",
        "        fixed_positions_dict = None\n",
        "        pssm_dict = None\n",
        "        omit_AA_dict = None\n",
        "        bias_by_res_dict = None\n",
        "        bias_AAs_np = np.zeros(len(alphabet))\n",
        "\n",
        "        # Storage for results\n",
        "        results = {\n",
        "            'pdb_code': pdb_code,\n",
        "            'sequences': [],\n",
        "            'scores': [],\n",
        "            'recovery_rates': [],\n",
        "            'temperatures': [],\n",
        "            'native_sequence': '',\n",
        "            'native_score': 0\n",
        "        }\n",
        "\n",
        "        # Process protein\n",
        "        with torch.no_grad():\n",
        "            for ix, protein in enumerate(dataset_valid):\n",
        "                batch_clones = [copy.deepcopy(protein) for i in range(BATCH_COPIES)]\n",
        "\n",
        "                # Featurize\n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta = tied_featurize(\n",
        "                    batch_clones, device, chain_id_dict, fixed_positions_dict,\n",
        "                    omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict\n",
        "                )\n",
        "\n",
        "                pssm_log_odds_mask = (pssm_log_odds_all > 0.0).float()\n",
        "                name_ = batch_clones[0]['name']\n",
        "\n",
        "                # Calculate native score\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "                log_probs = model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "                mask_for_loss = mask*chain_M*chain_M_pos\n",
        "                scores = _scores(S, log_probs, mask_for_loss)\n",
        "                native_score = scores.cpu().data.numpy().mean()\n",
        "                results['native_score'] = float(native_score)\n",
        "\n",
        "                # Generate sequences\n",
        "                for temp in temperatures:\n",
        "                    for j in range(NUM_BATCHES):\n",
        "                        randn_2 = torch.randn(chain_M.shape, device=X.device)\n",
        "\n",
        "                        # Sample sequences\n",
        "                        if tied_positions_dict is None:\n",
        "                            sample_dict = model.sample(\n",
        "                                X, randn_2, S, chain_M, chain_encoding_all, residue_idx,\n",
        "                                mask=mask, temperature=temp, omit_AAs_np=omit_AAs_np,\n",
        "                                bias_AAs_np=bias_AAs_np, chain_M_pos=chain_M_pos,\n",
        "                                omit_AA_mask=omit_AA_mask, pssm_coef=pssm_coef,\n",
        "                                pssm_bias=pssm_bias, pssm_multi=0.0,\n",
        "                                pssm_log_odds_flag=False, pssm_log_odds_mask=pssm_log_odds_mask,\n",
        "                                pssm_bias_flag=False, bias_by_res=bias_by_res_all\n",
        "                            )\n",
        "                        else:\n",
        "                            sample_dict = model.tied_sample(\n",
        "                                X, randn_2, S, chain_M, chain_encoding_all, residue_idx,\n",
        "                                mask=mask, temperature=temp, omit_AAs_np=omit_AAs_np,\n",
        "                                bias_AAs_np=bias_AAs_np, chain_M_pos=chain_M_pos,\n",
        "                                omit_AA_mask=omit_AA_mask, pssm_coef=pssm_coef,\n",
        "                                pssm_bias=pssm_bias, pssm_multi=0.0,\n",
        "                                pssm_log_odds_flag=False, pssm_log_odds_mask=pssm_log_odds_mask,\n",
        "                                pssm_bias_flag=False, tied_pos=tied_pos_list_of_lists_list[0],\n",
        "                                tied_beta=tied_beta, bias_by_res=bias_by_res_all\n",
        "                            )\n",
        "\n",
        "                        S_sample = sample_dict[\"S\"]\n",
        "\n",
        "                        # Score designed sequences\n",
        "                        log_probs = model(X, S_sample, mask, chain_M*chain_M_pos, residue_idx,\n",
        "                                        chain_encoding_all, randn_2, use_input_decoding_order=True,\n",
        "                                        decoding_order=sample_dict[\"decoding_order\"])\n",
        "                        scores = _scores(S_sample, log_probs, mask_for_loss)\n",
        "                        scores = scores.cpu().data.numpy()\n",
        "\n",
        "                        # Process results\n",
        "                        for b_ix in range(BATCH_COPIES):\n",
        "                            masked_chain_length_list = masked_chain_length_list_list[b_ix]\n",
        "                            masked_list = masked_list_list[b_ix]\n",
        "\n",
        "                            # Calculate recovery\n",
        "                            seq_recovery_rate = torch.sum(\n",
        "                                torch.sum(torch.nn.functional.one_hot(S[b_ix], 21) *\n",
        "                                         torch.nn.functional.one_hot(S_sample[b_ix], 21), axis=-1) *\n",
        "                                mask_for_loss[b_ix]\n",
        "                            ) / torch.sum(mask_for_loss[b_ix])\n",
        "\n",
        "                            # Convert sequences\n",
        "                            seq = _S_to_seq(S_sample[b_ix], chain_M[b_ix])\n",
        "                            native_seq = _S_to_seq(S[b_ix], chain_M[b_ix])\n",
        "\n",
        "                            # Format sequences\n",
        "                            if results['native_sequence'] == '':  # First time\n",
        "                                start, end = 0, 0\n",
        "                                list_of_AAs = []\n",
        "                                for mask_l in masked_chain_length_list:\n",
        "                                    end += mask_l\n",
        "                                    list_of_AAs.append(native_seq[start:end])\n",
        "                                    start = end\n",
        "                                native_formatted = \"\".join(list(np.array(list_of_AAs)[np.argsort(masked_list)]))\n",
        "                                l0 = 0\n",
        "                                for mc_length in list(np.array(masked_chain_length_list)[np.argsort(masked_list)])[:-1]:\n",
        "                                    l0 += mc_length\n",
        "                                    native_formatted = native_formatted[:l0] + '/' + native_formatted[l0:]\n",
        "                                    l0 += 1\n",
        "                                results['native_sequence'] = native_formatted\n",
        "\n",
        "                            # Format designed sequence\n",
        "                            start, end = 0, 0\n",
        "                            list_of_AAs = []\n",
        "                            for mask_l in masked_chain_length_list:\n",
        "                                end += mask_l\n",
        "                                list_of_AAs.append(seq[start:end])\n",
        "                                start = end\n",
        "                            seq_formatted = \"\".join(list(np.array(list_of_AAs)[np.argsort(masked_list)]))\n",
        "                            l0 = 0\n",
        "                            for mc_length in list(np.array(masked_chain_length_list)[np.argsort(masked_list)])[:-1]:\n",
        "                                l0 += mc_length\n",
        "                                seq_formatted = seq_formatted[:l0] + '/' + seq_formatted[l0:]\n",
        "                                l0 += 1\n",
        "\n",
        "                            # Store results\n",
        "                            results['sequences'].append(seq_formatted)\n",
        "                            results['scores'].append(float(scores[b_ix]))\n",
        "                            results['recovery_rates'].append(float(seq_recovery_rate.detach().cpu().numpy()))\n",
        "                            results['temperatures'].append(temp)\n",
        "\n",
        "                            print(f\"Generated sequence {len(results['sequences'])}: Recovery={seq_recovery_rate:.3f}, Score={scores[b_ix]:.4f}\")\n",
        "\n",
        "        print(f\"✅ Successfully processed {pdb_code}: {len(results['sequences'])} sequences generated\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing {pdb_code}: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "print(\"✅ Single protein processing function ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "nuem8McCbjLH",
        "outputId": "c5977c8b-f6b9-4287-c823-37446e2c7d14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Single protein processing function ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 7: Process All Proteins\n",
        "import sys\n",
        "# Ensure the ProteinMPNN directory is in the system path\n",
        "proteinmpnn_path = '/content/ProteinMPNN'\n",
        "if proteinmpnn_path not in sys.path:\n",
        "    sys.path.insert(0, proteinmpnn_path) # Use insert to prioritize this path\n",
        "\n",
        "all_protein_results = {}\n",
        "\n",
        "for pdb_code in pdb_codes:\n",
        "    if pdb_code in design_config:\n",
        "        config = design_config[pdb_code]\n",
        "        result = process_single_protein(\n",
        "            pdb_code,\n",
        "            config['designed_chains'],\n",
        "            config['fixed_chains'],\n",
        "            num_sequences=num_seqs,\n",
        "            temperature=float(sampling_temp)\n",
        "        )\n",
        "        if result is not None:\n",
        "            all_protein_results[pdb_code] = result\n",
        "    else:\n",
        "        print(f\"⚠️ No configuration found for {pdb_code}, skipping...\")\n",
        "\n",
        "print(f\"\\n✅ Processing complete! Successfully processed {len(all_protein_results)} proteins\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "edRnaMv0b0pc",
        "outputId": "1c20df28-f3ff-403b-ae79-7c887cdd2886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Processing 3JAY\n",
            "==================================================\n",
            "✅ Downloaded and decompressed 3JAY from https://files.rcsb.org/pub/pdb/data/structures/divided/pdb/ja/pdb3jay.ent.gz\n",
            "Chain configuration: {'3JAY': (['B'], ['A', 'C', 'D', 'E'])}\n",
            "Length of chain D: 292\n",
            "Length of chain E: 292\n",
            "Length of chain B: 1199\n",
            "Length of chain C: 1260\n",
            "Length of chain A: 1057\n",
            "Generated sequence 1: Recovery=0.417, Score=0.8800\n",
            "Generated sequence 2: Recovery=0.428, Score=0.8724\n",
            "Generated sequence 3: Recovery=0.400, Score=0.8763\n",
            "Generated sequence 4: Recovery=0.416, Score=0.8859\n",
            "Generated sequence 5: Recovery=0.412, Score=0.8781\n",
            "Generated sequence 6: Recovery=0.420, Score=0.8798\n",
            "✅ Successfully processed 3JAY: 6 sequences generated\n",
            "\n",
            "==================================================\n",
            "Processing 3JB0\n",
            "==================================================\n",
            "✅ Downloaded and decompressed 3JB0 from https://files.rcsb.org/pub/pdb/data/structures/divided/pdb/jb/pdb3jb0.ent.gz\n",
            "Chain configuration: {'3JB0': (['B'], ['A', 'C', 'D', 'E'])}\n",
            "Length of chain D: 292\n",
            "Length of chain E: 292\n",
            "Length of chain B: 1199\n",
            "Length of chain C: 1260\n",
            "Length of chain A: 1057\n",
            "Generated sequence 1: Recovery=0.448, Score=0.8587\n",
            "Generated sequence 2: Recovery=0.427, Score=0.8587\n",
            "Generated sequence 3: Recovery=0.442, Score=0.8616\n",
            "Generated sequence 4: Recovery=0.437, Score=0.8670\n",
            "Generated sequence 5: Recovery=0.423, Score=0.8553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell 8: Analyze Results and Create Visualizations\n",
        "if len(all_protein_results) == 0:\n",
        "    print(\"❌ No results to analyze. Please check the previous cells.\")\n",
        "else:\n",
        "    print(\"📊 Analyzing results...\")\n",
        "\n",
        "    # Combine all results\n",
        "    combined_metrics = []\n",
        "    summary_stats = []\n",
        "\n",
        "    for pdb_code, results in all_protein_results.items():\n",
        "        if len(results['sequences']) > 0:\n",
        "            # Calculate metrics for this protein\n",
        "            metrics_df = calculate_sequence_metrics(\n",
        "                results['native_sequence'],\n",
        "                results['sequences'],\n",
        "                results['scores']\n",
        "            )\n",
        "            metrics_df['pdb_code'] = pdb_code\n",
        "            metrics_df['temperature'] = results['temperatures']\n",
        "            metrics_df['native_score'] = results['native_score']\n",
        "\n",
        "            combined_metrics.append(metrics_df)\n",
        "\n",
        "            # Summary statistics\n",
        "            summary_stats.append({\n",
        "                'PDB': pdb_code,\n",
        "                'Sequences': len(results['sequences']),\n",
        "                'Mean_Recovery': metrics_df['sequence_recovery'].mean(),\n",
        "                'Std_Recovery': metrics_df['sequence_recovery'].std(),\n",
        "                'Mean_Score': metrics_df['score'].mean(),\n",
        "                'Best_Score': metrics_df['score'].min(),\n",
        "                'Native_Score': results['native_score'],\n",
        "                'Charged_Recovery': metrics_df['charged_residue_recovery'].mean(),\n",
        "                'Hydrophobic_Recovery': metrics_df['hydrophobic_recovery'].mean()\n",
        "            })\n",
        "\n",
        "    if combined_metrics:\n",
        "        # Combine all metrics\n",
        "        all_metrics_df = pd.concat(combined_metrics, ignore_index=True)\n",
        "        summary_df = pd.DataFrame(summary_stats)\n",
        "\n",
        "        print(\"📈 SUMMARY STATISTICS\")\n",
        "        print(\"=\"*60)\n",
        "        print(summary_df.round(2).to_string(index=False))\n",
        "\n",
        "        # Create visualizations\n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=3,\n",
        "            subplot_titles=(\n",
        "                'Sequence Recovery by Protein',\n",
        "                'Score Distribution by Protein',\n",
        "                'Recovery vs Score',\n",
        "                'Charged Residue Recovery',\n",
        "                'Overall Performance Summary',\n",
        "                'Score Comparison (Native vs Designed)'\n",
        "            ),\n",
        "            specs=[[{\"type\": \"box\"}, {\"type\": \"box\"}, {\"type\": \"scatter\"}],\n",
        "                   [{\"type\": \"box\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
        "        )\n",
        "\n",
        "        # Row 1\n",
        "        fig.add_trace(\n",
        "            go.Box(x=all_metrics_df['pdb_code'], y=all_metrics_df['sequence_recovery'], name='Recovery'),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Box(x=all_metrics_df['pdb_code'], y=all_metrics_df['score'], name='Scores'),\n",
        "            row=1, col=2\n",
        "        )\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=all_metrics_df['score'], y=all_metrics_df['sequence_recovery'],\n",
        "                      text=all_metrics_df['pdb_code'], mode='markers+text', name='Recovery vs Score'),\n",
        "            row=1, col=3\n",
        "        )\n",
        "\n",
        "        # Row 2\n",
        "        fig.add_trace(\n",
        "            go.Box(x=all_metrics_df['pdb_code'], y=all_metrics_df['charged_residue_recovery'], name='Charged Recovery'),\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=summary_df['PDB'], y=summary_df['Mean_Recovery'], name='Mean Recovery'),\n",
        "            row=2, col=2\n",
        "        )\n",
        "\n",
        "        # Score comparison\n",
        "        score_data = []\n",
        "        score_labels = []\n",
        "        score_colors = []\n",
        "        for _, row in summary_df.iterrows():\n",
        "            score_data.extend([row['Native_Score'], row['Mean_Score']])\n",
        "            score_labels.extend([f\"{row['PDB']}_Native\", f\"{row['PDB']}_Designed\"])\n",
        "            score_colors.extend(['blue', 'red'])\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=score_labels, y=score_data, name='Score Comparison',\n",
        "                  marker_color=score_colors),\n",
        "            row=2, col=3\n",
        "        )\n",
        "\n",
        "        fig.update_layout(height=800, showlegend=False,\n",
        "                         title_text=\"ProteinMPNN Baseline Performance Dashboard\")\n",
        "        fig.show()\n",
        "\n",
        "        # Export results\n",
        "        timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        # Save detailed metrics\n",
        "        all_metrics_df.to_csv(f'baseline_detailed_metrics_{timestamp}.csv', index=False)\n",
        "        summary_df.to_csv(f'baseline_summary_{timestamp}.csv', index=False)\n",
        "\n",
        "        # Save sequences\n",
        "        with open(f'baseline_sequences_{timestamp}.fasta', 'w') as f:\n",
        "            for pdb_code, results in all_protein_results.items():\n",
        "                f.write(f\">NATIVE_{pdb_code}_score_{results['native_score']:.4f}\\n\")\n",
        "                f.write(f\"{results['native_sequence']}\\n\")\n",
        "\n",
        "                for i, (seq, score, recovery) in enumerate(zip(\n",
        "                    results['sequences'], results['scores'], results['recovery_rates']\n",
        "                )):\n",
        "                    f.write(f\">DESIGNED_{pdb_code}_{i+1}_score_{score:.4f}_recovery_{recovery:.3f}\\n\")\n",
        "                    f.write(f\"{seq}\\n\")\n",
        "\n",
        "        # Final summary\n",
        "        print(f\"\\n🎯 BASELINE TARGETS FOR ESM-2 ENHANCEMENT:\")\n",
        "        print(f\"Overall Mean Recovery: {all_metrics_df['sequence_recovery'].mean():.2f}% → Target: >{all_metrics_df['sequence_recovery'].mean() + 10:.2f}%\")\n",
        "        print(f\"Charged Recovery: {all_metrics_df['charged_residue_recovery'].mean():.2f}% → Target: >{all_metrics_df['charged_residue_recovery'].mean() + 15:.2f}%\")\n",
        "        print(f\"Mean Score: {all_metrics_df['score'].mean():.4f} → Target: <{all_metrics_df['score'].mean() - 0.1:.4f}\")\n",
        "\n",
        "        print(f\"\\n💾 Results saved:\")\n",
        "        print(f\"- Detailed metrics: baseline_detailed_metrics_{timestamp}.csv\")\n",
        "        print(f\"- Summary: baseline_summary_{timestamp}.csv\")\n",
        "        print(f\"- Sequences: baseline_sequences_{timestamp}.fasta\")\n",
        "\n",
        "        print(f\"\\n🚀 Ready for ESM-2 integration!\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "gEq00W-_bNKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee064351-964e-4243-e926-b46903d5b607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ No results to analyze. Please check the previous cells.\n"
          ]
        }
      ]
    }
  ]
}